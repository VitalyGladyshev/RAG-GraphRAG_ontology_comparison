{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be5eb734-acc3-4259-b0f3-84a4f310bed1",
   "metadata": {},
   "source": [
    "# –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∏ –æ—Ü–µ–Ω–∫–∞ –∫–æ–Ω–≤–µ–π–µ—Ä–∞ RAG –Ω–∞ –¥–∞–Ω–Ω—ã—Ö CAD –¥–æ–º–µ–Ω–∞. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å GraphRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83d4c6b-464f-44b1-8640-c441dd9b6c9a",
   "metadata": {},
   "source": [
    "## –ò–º–ø–æ—Ä—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df7aeaef-a957-4253-b53d-cf9c1b4d5a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ nest_asyncio —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º –∫–æ–¥–æ–º –≤ Jupyter\n",
      "‚úÖ RAGAS 0.4+ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ (7 –º–µ—Ç—Ä–∏–∫)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple, Union\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, asdict, field\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\n",
    "import chromadb\n",
    "\n",
    "# LangChain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# –ú–æ–¥–µ–ª–∏ –∏ ML\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Jupyter\n",
    "from IPython.display import display, HTML\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# OpenAI –¥–ª—è custom endpoints\n",
    "import openai\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "print(\"‚úÖ nest_asyncio —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º –∫–æ–¥–æ–º –≤ Jupyter\")\n",
    "\n",
    "# RAGAS 0.4+\n",
    "try:\n",
    "    from ragas.llms import llm_factory\n",
    "    from ragas.embeddings.base import embedding_factory\n",
    "    from ragas.metrics.collections import (\n",
    "        Faithfulness,              # ‚úÖ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ—Ç–≤–µ—Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É\n",
    "        AnswerRelevancy,           # ‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –∑–∞–ø—Ä–æ—Å—É (—Ç—Ä–µ–±—É–µ—Ç embeddings)\n",
    "        ContextPrecision,          # ‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (—Ç—Ä–µ–±—É–µ—Ç reference)\n",
    "        ContextRecall,             # ‚úÖ –ü–æ–ª–Ω–æ—Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (—Ç—Ä–µ–±—É–µ—Ç reference)\n",
    "        ContextRelevance,          # ‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
    "        ResponseGroundedness,      # ‚úÖ –û–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞\n",
    "        AnswerAccuracy,            # ‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ (—Ç—Ä–µ–±—É–µ—Ç reference)\n",
    "    )\n",
    "    RAGAS_AVAILABLE = True\n",
    "    print(\"‚úÖ RAGAS 0.4+ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ (7 –º–µ—Ç—Ä–∏–∫)\")\n",
    "except ImportError as e:\n",
    "    RAGAS_AVAILABLE = False\n",
    "    print(f\"‚ö†Ô∏è RAGAS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {e}\")\n",
    "    print(\"–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install ragas --upgrade\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "484397a0-e7f1-44c0-a77f-cb0191b55faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b7c0c7-43e2-4b42-a811-ba9043cac655",
   "metadata": {},
   "source": [
    "## –ö–ª–∞—Å—Å—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ccf23a-eca9-48e8-a320-d9229b7af573",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JupyterConfig:\n",
    "    \"\"\"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ Jupyter Notebook\"\"\"\n",
    "    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "    DISPLAY_MAX_CHARS = 200\n",
    "    DISPLAY_TABLE_ROWS = 15\n",
    "    USE_INTERACTIVE_WIDGETS = True\n",
    "    \n",
    "    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n",
    "    AUTO_SAVE_RESULTS = True\n",
    "    RESULTS_DIR = \"notebook_results\"\n",
    "    \n",
    "    # –¶–≤–µ—Ç–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞\n",
    "    SUCCESS_COLOR = \"#4CAF50\"\n",
    "    WARNING_COLOR = \"#FFA726\"\n",
    "    ERROR_COLOR = \"#EF5350\"\n",
    "    INFO_COLOR = \"#2196F3\"\n",
    "    \n",
    "    @classmethod\n",
    "    def setup_directories(cls):\n",
    "        \"\"\"–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.\"\"\"\n",
    "        Path(cls.RESULTS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–æ–∑–¥–∞–Ω–∞: {cls.RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdf49ee8-1b97-422d-9afa-f22c461debc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è RAG-–ø–∞–π–ø–ª–∞–π–Ω–∞.\"\"\"\n",
    "    # –ü—É—Ç–∏\n",
    "    DEFAULT_DATA_DIR = \"data/chunks\"\n",
    "    DEFAULT_DB_DIR = \"vector_db\"\n",
    "    DEFAULT_MODEL_CACHE = \"models/cache\"\n",
    "    DEFAULT_LOGS_DIR = \"logs\"\n",
    "    RESULTS_DIR = \"notebook_results\"\n",
    "    \n",
    "    # –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "    EMBEDDING_MODEL = \"intfloat/multilingual-e5-large\"\n",
    "    EMBEDDING_DIMENSION = 1024\n",
    "    MAX_SEQUENCE_LENGTH = 512\n",
    "    \n",
    "    # –ß–∞–Ω–∫–∏–Ω–≥\n",
    "    CHUNK_SIZE = 500\n",
    "    CHUNK_OVERLAP = 50\n",
    "    \n",
    "    # –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞\n",
    "    COLLECTION_NAME = \"document_chunks\"\n",
    "    DISTANCE_METRIC = \"cosine\"\n",
    "    \n",
    "    # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
    "    BATCH_SIZE = 32\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    USE_FP16 = True if torch.cuda.is_available() else False\n",
    "    \n",
    "    # –ü–æ–∏—Å–∫\n",
    "    DEFAULT_TOP_K = 5\n",
    "    SIMILARITY_THRESHOLD = 0.7\n",
    "    \n",
    "    # LLM –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n",
    "    LLM_API_BASE = \"https://api.vsegpt.ru/v1\"\n",
    "    LLM_API_KEY = \"sk-or-vv-xx\"\n",
    "    \n",
    "    # –ú–æ–¥–µ–ª–∏\n",
    "    GENERATION_MODEL = \"google/gemma-3-27b-it\"\n",
    "    EVALUATION_MODEL = \"openai/gpt-5-mini\"\n",
    "    \n",
    "    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
    "    GENERATION_TEMPERATURE = 0.7\n",
    "    GENERATION_MAX_TOKENS = 1024\n",
    "    \n",
    "    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ü–µ–Ω–∫–∏\n",
    "    EVALUATION_TEMPERATURE = 0.0  # –î–ª—è –æ—Ü–µ–Ω–∫–∏ –Ω—É–∂–Ω–∞ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å\n",
    "    EVALUATION_MAX_TOKENS = 512\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "    LOG_LEVEL = \"INFO\"\n",
    "    \n",
    "    @classmethod\n",
    "    def setup_directories(cls):\n",
    "        \"\"\"–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.\"\"\"\n",
    "        for directory in [cls.DEFAULT_DATA_DIR, cls.DEFAULT_DB_DIR, \n",
    "                         cls.DEFAULT_MODEL_CACHE, cls.DEFAULT_LOGS_DIR,\n",
    "                         cls.RESULTS_DIR]:\n",
    "            Path(directory).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c9f3a1-ea8b-4819-8bb3-67f02a27150c",
   "metadata": {},
   "source": [
    "## –ö–ª–∞—Å—Å—ã –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0899fbc-4065-4e0d-a9b2-0930166dc1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SearchResult:\n",
    "    \"\"\"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ.\"\"\"\n",
    "    id: str\n",
    "    content: str\n",
    "    similarity_score: float\n",
    "    metadata: Dict[str, Any]\n",
    "    embedding: Optional[List[float]] = None\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return asdict(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff4bb704-e462-4d24-b91e-c0392b7011af",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RAGEvaluationResult:\n",
    "    \"\"\"–†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ü–µ–Ω–∫–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞.\"\"\"\n",
    "    query: str\n",
    "    answer: str\n",
    "    context: List[str]\n",
    "    ground_truth: Optional[str] = None\n",
    "    \n",
    "    # –ú–µ—Ç—Ä–∏–∫–∏\n",
    "    faithfulness: Optional[float] = None\n",
    "    answer_relevancy: Optional[float] = None\n",
    "    context_precision: Optional[float] = None\n",
    "    context_recall: Optional[float] = None\n",
    "    context_relevance: Optional[float] = None\n",
    "    response_groundedness: Optional[float] = None\n",
    "    answer_accuracy: Optional[float] = None\n",
    "    \n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "    \n",
    "    def get_average_score(self) -> float:\n",
    "        \"\"\"–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –ø–æ –≤—Å–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–º –º–µ—Ç—Ä–∏–∫–∞–º.\"\"\"\n",
    "        scores = [\n",
    "            self.faithfulness,\n",
    "            self.answer_relevancy,\n",
    "            self.context_precision,\n",
    "            self.context_recall,\n",
    "            self.context_relevance,\n",
    "            self.response_groundedness,\n",
    "            self.answer_accuracy,\n",
    "        ]\n",
    "        valid_scores = [s for s in scores if s is not None]\n",
    "        return float(np.mean(valid_scores)) if valid_scores else 0.0\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ª–æ–≤–∞—Ä—å.\"\"\"\n",
    "        return asdict(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa358bb6-3000-4861-8968-772536740eea",
   "metadata": {},
   "source": [
    "## LLM –∫–ª–∏–µ–Ω—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f745c1af-3569-42c0-ab8c-6ee85557eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniversalLLMClient:\n",
    "    \"\"\"\n",
    "    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LLM —á–µ—Ä–µ–∑ OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–µ API.\n",
    "    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç custom endpoints (–Ω–∞–ø—Ä–∏–º–µ—Ä, vsegpt.ru).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 model: str,\n",
    "                 api_key: str,\n",
    "                 api_base: str = \"https://api.openai.com/v1\",\n",
    "                 temperature: float = 0.7,\n",
    "                 max_tokens: int = 1024,\n",
    "                 timeout: int = 120):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, \"openai/gpt-4o-mini\")\n",
    "            api_key: API –∫–ª—é—á\n",
    "            api_base: Base URL API\n",
    "            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
    "            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤\n",
    "            timeout: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.api_key = api_key\n",
    "        self.api_base = api_base\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.timeout = timeout\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π OpenAI –∫–ª–∏–µ–Ω—Ç\n",
    "        self.client = openai.OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=api_base,\n",
    "            timeout=timeout,\n",
    "            max_retries=3\n",
    "        )\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π OpenAI –∫–ª–∏–µ–Ω—Ç –¥–ª—è RAGAS\n",
    "        self.async_client = AsyncOpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=api_base,\n",
    "            timeout=timeout,\n",
    "            max_retries=3,\n",
    "            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤\n",
    "            default_headers={\n",
    "                \"X-Max-Tokens\": str(max_tokens)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self.logger.info(f\"‚úÖ LLM –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {model} @ {api_base}\")\n",
    "        self.logger.info(f\"‚öôÔ∏è  max_tokens={max_tokens}, temperature={temperature}\")\n",
    "    \n",
    "    def generate(self,\n",
    "                prompt: str,\n",
    "                system_prompt: str = None,\n",
    "                temperature: float = None,\n",
    "                max_tokens: int = None) -> str:\n",
    "        \"\"\"\n",
    "        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–º–ø—Ç–∞.\n",
    "        \n",
    "        Args:\n",
    "            prompt: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç\n",
    "            system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç\n",
    "            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—É—é)\n",
    "            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π)\n",
    "        \n",
    "        Returns:\n",
    "            –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç\n",
    "        \"\"\"\n",
    "        messages = []\n",
    "        \n",
    "        if system_prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        \n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                temperature=temperature or self.temperature,\n",
    "                max_tokens=max_tokens or self.max_tokens\n",
    "            )\n",
    "            \n",
    "            generated_text = response.choices[0].message.content\n",
    "            \n",
    "            self.logger.debug(f\"‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ ({len(generated_text)} —Å–∏–º–≤–æ–ª–æ–≤)\")\n",
    "            return generated_text.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def get_ragas_llm(self):\n",
    "        \"\"\"\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç RAGAS-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π LLM –æ–±—ä–µ–∫—Ç.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # –°–æ–∑–¥–∞–µ–º –æ–±–µ—Ä—Ç–∫—É —Å –Ω—É–∂–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "            ragas_llm = llm_factory(\n",
    "                model=self.model,\n",
    "                client=self.async_client,\n",
    "                # –ü–µ—Ä–µ–¥–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=self.max_tokens,\n",
    "            )\n",
    "            \n",
    "            self.logger.info(f\"‚úÖ RAGAS LLM —Å–æ–∑–¥–∞–Ω —Å max_tokens={self.max_tokens}\")\n",
    "            return ragas_llm\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ RAGAS LLM: {e}\")\n",
    "            # Fallback –∫ –±–∞–∑–æ–≤–æ–º—É –≤–∞—Ä–∏–∞–Ω—Ç—É\n",
    "            return llm_factory(\n",
    "                model=self.model,\n",
    "                client=self.async_client\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "189b2747-97bb-4eb8-8833-ce86b882fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMGenerator:\n",
    "    \"\"\"\n",
    "    –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 llm_client: UniversalLLMClient,\n",
    "                 system_prompt: str = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            llm_client: –ö–ª–∏–µ–Ω—Ç LLM\n",
    "            system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
    "        \"\"\"\n",
    "        self.llm_client = llm_client\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        if system_prompt is None:\n",
    "            self.system_prompt = \"\"\"–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n",
    "\n",
    "–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:\n",
    "1. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
    "2. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º\n",
    "3. –ù–ï –¥–æ–±–∞–≤–ª—è–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–æ–π –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ\n",
    "4. –û—Ç–≤–µ—á–∞–π —á–µ—Ç–∫–æ, –ø–æ –¥–µ–ª—É –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ\n",
    "5. –ï—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ, —Ü–∏—Ç–∏—Ä—É–π —Ñ–∞–∫—Ç—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
    "6. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ç–æ–º –∂–µ —è–∑—ã–∫–µ, —á—Ç–æ –∏ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\"\"\"\n",
    "        else:\n",
    "            self.system_prompt = system_prompt\n",
    "    \n",
    "    def generate_answer(self,\n",
    "                       query: str,\n",
    "                       contexts: List[str],\n",
    "                       custom_system_prompt: str = None) -> str:\n",
    "        \"\"\"\n",
    "        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤.\n",
    "        \n",
    "        Args:\n",
    "            query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "            contexts: –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤\n",
    "            custom_system_prompt: –ö–∞—Å—Ç–æ–º–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç\n",
    "        \n",
    "        Returns:\n",
    "            –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç\n",
    "        \"\"\"\n",
    "        if not contexts:\n",
    "            return \"–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å.\"\n",
    "        \n",
    "        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã\n",
    "        combined_context = \"\\n\\n\".join([\n",
    "            f\"[–ö–æ–Ω—Ç–µ–∫—Å—Ç {i+1}]:\\n{ctx}\" \n",
    "            for i, ctx in enumerate(contexts[:5])  # –ë–µ—Ä–µ–º —Ç–æ–ø-5\n",
    "        ])\n",
    "        \n",
    "        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç\n",
    "        user_prompt = f\"\"\"–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞:\n",
    "{combined_context}\n",
    "\n",
    "–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n",
    "{query}\n",
    "\n",
    "–û—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞:\"\"\"\n",
    "\n",
    "        try:\n",
    "            answer = self.llm_client.generate(\n",
    "                prompt=user_prompt,\n",
    "                system_prompt=custom_system_prompt or self.system_prompt\n",
    "            )\n",
    "            \n",
    "            self.logger.info(f\"‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω ({len(answer)} —Å–∏–º–≤–æ–ª–æ–≤)\")\n",
    "            return answer\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}\")\n",
    "            return f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}\"\n",
    "    \n",
    "    def batch_generate(self,\n",
    "                      queries: List[str],\n",
    "                      contexts_list: List[List[str]]) -> List[str]:\n",
    "        \"\"\"\n",
    "        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç—ã –¥–ª—è –±–∞—Ç—á–∞ –∑–∞–ø—Ä–æ—Å–æ–≤.\n",
    "        \n",
    "        Args:\n",
    "            queries: –°–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤\n",
    "            contexts_list: –°–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤\n",
    "        \n",
    "        Returns:\n",
    "            –°–ø–∏—Å–æ–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤\n",
    "        \"\"\"\n",
    "        answers = []\n",
    "        for query, contexts in tqdm(zip(queries, contexts_list), \n",
    "                                    total=len(queries),\n",
    "                                    desc=\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤\"):\n",
    "            answer = self.generate_answer(query, contexts)\n",
    "            answers.append(answer)\n",
    "        \n",
    "        return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de15e267-62d9-4b4d-9c6a-97cf9c23e848",
   "metadata": {},
   "source": [
    "### –ö–ª–∞—Å—Å –º–µ—Ç—Ä–∏–∫ RAG (RAGAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f0cfda19-20b8-450f-866c-08a4d88c9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniversalRAGEvaluator:\n",
    "    \"\"\"\n",
    "    üéØ –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –æ—Ü–µ–Ω—â–∏–∫ RAG —Å–∏—Å—Ç–µ–º —Å RAGAS 0.4+\n",
    "    \n",
    "    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 7 –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫:\n",
    "    ‚úÖ faithfulness - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ—Ç–≤–µ—Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É\n",
    "    ‚úÖ answer_relevancy - –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –∑–∞–ø—Ä–æ—Å—É (—Ç—Ä–µ–±—É–µ—Ç embeddings)\n",
    "    ‚úÖ context_precision - –¢–æ—á–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (—Ç—Ä–µ–±—É–µ—Ç reference)\n",
    "    ‚úÖ context_recall - –ü–æ–ª–Ω–æ—Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (—Ç—Ä–µ–±—É–µ—Ç reference)\n",
    "    ‚úÖ context_relevance - –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
    "    ‚úÖ response_groundedness - –û–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞\n",
    "    ‚úÖ answer_accuracy - –¢–æ—á–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ (—Ç—Ä–µ–±—É–µ—Ç reference)\n",
    "    \"\"\"\n",
    "    \n",
    "    # ‚úÖ –ü–†–û–í–ï–†–ï–ù–ù–´–ï –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è RAGAS 0.4+\n",
    "    AVAILABLE_METRICS = [\n",
    "        \"faithfulness\",\n",
    "        \"answer_relevancy\",\n",
    "        \"context_precision\",\n",
    "        \"context_recall\",\n",
    "        \"context_relevance\",\n",
    "        \"response_groundedness\",\n",
    "        \"answer_accuracy\",\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, \n",
    "                 judge_llm_client: UniversalLLMClient,\n",
    "                 embedding_model: str = \"emb-openai/text-embedding-3-large\",\n",
    "                 metrics: List[str] = None,\n",
    "                 enable_timing: bool = True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            judge_llm_client: LLM –∫–ª–∏–µ–Ω—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ (Judge)\n",
    "            embedding_model: –ú–æ–¥–µ–ª—å –¥–ª—è embeddings (–¥–ª—è answer_relevancy)\n",
    "            metrics: –°–ø–∏—Å–æ–∫ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–∞–∑–æ–≤—ã–µ)\n",
    "        \"\"\"\n",
    "        self.judge_llm_client = judge_llm_client\n",
    "        self.embedding_model = embedding_model\n",
    "        self.evaluation_results: List[RAGEvaluationResult] = []\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        if not RAGAS_AVAILABLE:\n",
    "            raise ImportError(\"RAGAS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install ragas --upgrade\")\n",
    "        \n",
    "        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (—Ä–∞–±–æ—Ç–∞—é—Ç –±–µ–∑ ground truth)\n",
    "        self.basic_metrics = [\n",
    "            \"faithfulness\",\n",
    "            \"context_relevance\",\n",
    "            \"response_groundedness\",\n",
    "        ]\n",
    "        \n",
    "        # –ú–µ—Ç—Ä–∏–∫–∏, —Ç—Ä–µ–±—É—é—â–∏–µ embeddings\n",
    "        self.embedding_metrics = [\n",
    "            \"answer_relevancy\",\n",
    "        ]\n",
    "        \n",
    "        # –ú–µ—Ç—Ä–∏–∫–∏, —Ç—Ä–µ–±—É—é—â–∏–µ ground truth\n",
    "        self.ground_truth_metrics = [\n",
    "            \"context_precision\",\n",
    "            \"context_recall\",\n",
    "            \"answer_accuracy\",\n",
    "        ]\n",
    "        \n",
    "        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "        self.metrics_to_use = metrics or self.basic_metrics\n",
    "        self._validate_metrics()\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º RAGAS LLM –∏ embeddings\n",
    "        self.ragas_llm = self.judge_llm_client.get_ragas_llm()\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º embeddings —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω—ã\n",
    "        self.ragas_embeddings = None\n",
    "        if any(m in self.metrics_to_use for m in self.embedding_metrics):\n",
    "            try:\n",
    "                self.ragas_embeddings = embedding_factory(\n",
    "                    \"openai\",\n",
    "                    model=embedding_model,\n",
    "                    client=self.judge_llm_client.async_client\n",
    "                )\n",
    "                self.logger.info(f\"‚úÖ Embeddings –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã: {embedding_model}\")\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ embeddings: {e}\")\n",
    "                # –£–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏, —Ç—Ä–µ–±—É—é—â–∏–µ embeddings\n",
    "                self.metrics_to_use = [m for m in self.metrics_to_use if m not in self.embedding_metrics]\n",
    "        \n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "        self.metric_scorers = {}\n",
    "        self._initialize_metrics()\n",
    "\n",
    "        # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏\n",
    "        self.enable_timing = enable_timing\n",
    "        self.metric_timings = defaultdict(list)  # {metric_name: [time1, time2, ...]}\n",
    "        \n",
    "        self.logger.info(f\"‚úÖ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π RAG Evaluator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (RAGAS 0.4+)\")\n",
    "        self.logger.info(f\"üìä –ú–µ—Ç—Ä–∏–∫–∏: {', '.join(self.metrics_to_use)}\")\n",
    "\n",
    "        self._nest_asyncio_applied = False\n",
    "        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏–º–µ–Ω—è–µ–º nest_asyncio –¥–ª—è Jupyter\n",
    "        if self._is_running_in_jupyter():\n",
    "            self._apply_nest_asyncio()\n",
    "\n",
    "    def _is_running_in_jupyter(self) -> bool:\n",
    "        \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç Jupyter/IPython –æ–∫—Ä—É–∂–µ–Ω–∏–µ.\"\"\"\n",
    "        try:\n",
    "            from IPython import get_ipython\n",
    "            ipython = get_ipython()\n",
    "            return ipython is not None and 'IPKernelApp' in getattr(ipython, 'config', {})\n",
    "        except (ImportError, AttributeError):\n",
    "            return False\n",
    "    \n",
    "    def _apply_nest_asyncio(self):\n",
    "        \"\"\"–ü—Ä–∏–º–µ–Ω—è–µ—Ç nest_asyncio –æ–¥–∏–Ω —Ä–∞–∑.\"\"\"\n",
    "        if not self._nest_asyncio_applied:\n",
    "            try:\n",
    "                import nest_asyncio\n",
    "                nest_asyncio.apply()\n",
    "                self._nest_asyncio_applied = True\n",
    "                self.logger.info(\"‚úÖ nest_asyncio –ø—Ä–∏–º–µ–Ω–µ–Ω –¥–ª—è Jupyter\")\n",
    "            except ImportError:\n",
    "                self.logger.warning(\"‚ö†Ô∏è –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ nest_asyncio: pip install nest_asyncio\")\n",
    "    \n",
    "    def _validate_metrics(self):\n",
    "        \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫.\"\"\"\n",
    "        invalid_metrics = set(self.metrics_to_use) - set(self.AVAILABLE_METRICS)\n",
    "        if invalid_metrics:\n",
    "            raise ValueError(f\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏: {invalid_metrics}\")\n",
    "    \n",
    "    def _initialize_metrics(self):\n",
    "        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—ä–µ–∫—Ç—ã –º–µ—Ç—Ä–∏–∫ —Å LLM/Embeddings.\"\"\"\n",
    "        metric_classes = {\n",
    "            \"faithfulness\": Faithfulness,\n",
    "            \"answer_relevancy\": AnswerRelevancy,\n",
    "            \"context_precision\": ContextPrecision,\n",
    "            \"context_recall\": ContextRecall,\n",
    "            \"context_relevance\": ContextRelevance,\n",
    "            \"response_groundedness\": ResponseGroundedness,\n",
    "            \"answer_accuracy\": AnswerAccuracy,\n",
    "        }\n",
    "        \n",
    "        for metric_name in self.metrics_to_use:\n",
    "            if metric_name not in metric_classes:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                metric_class = metric_classes[metric_name]\n",
    "                \n",
    "                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫—É —Å –Ω—É–∂–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "                if metric_name in self.embedding_metrics:\n",
    "                    if self.ragas_embeddings is None:\n",
    "                        self.logger.warning(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞ {metric_name} (–Ω–µ—Ç embeddings)\")\n",
    "                        continue\n",
    "                    scorer = metric_class(llm=self.ragas_llm, embeddings=self.ragas_embeddings)\n",
    "                else:\n",
    "                    scorer = metric_class(llm=self.ragas_llm)\n",
    "                \n",
    "                self.metric_scorers[metric_name] = scorer\n",
    "                self.logger.info(f\"‚úÖ –ú–µ—Ç—Ä–∏–∫–∞ {metric_name} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–µ—Ç—Ä–∏–∫–∏ {metric_name}: {e}\")\n",
    "    \n",
    "    async def _evaluate_single_async(self, \n",
    "                                     query: str, \n",
    "                                     answer: str, \n",
    "                                     contexts: List[str],\n",
    "                                     ground_truth: str = None) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞.\n",
    "        \n",
    "        Args:\n",
    "            query: –í–æ–ø—Ä–æ—Å\n",
    "            answer: –û—Ç–≤–µ—Ç\n",
    "            contexts: –ö–æ–Ω—Ç–µ–∫—Å—Ç—ã\n",
    "            ground_truth: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "        \n",
    "        Returns:\n",
    "            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏\n",
    "        \"\"\"\n",
    "        scores = {}\n",
    "        \n",
    "        for metric_name, scorer in self.metric_scorers.items():\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–µ—Ç—Ä–∏–∫–∏\n",
    "                if metric_name == \"faithfulness\":\n",
    "                    result = await scorer.ascore(\n",
    "                        user_input=query,\n",
    "                        response=answer,\n",
    "                        retrieved_contexts=contexts\n",
    "                    )\n",
    "                \n",
    "                elif metric_name == \"answer_relevancy\":\n",
    "                    result = await scorer.ascore(\n",
    "                        user_input=query,\n",
    "                        response=answer\n",
    "                    )\n",
    "                \n",
    "                elif metric_name == \"context_precision\":\n",
    "                    if not ground_truth:\n",
    "                        continue\n",
    "                    result = await scorer.ascore(\n",
    "                        user_input=query,\n",
    "                        reference=ground_truth,\n",
    "                        retrieved_contexts=contexts\n",
    "                    )\n",
    "                \n",
    "                elif metric_name == \"context_recall\":\n",
    "                    if not ground_truth:\n",
    "                        continue\n",
    "                    result = await scorer.ascore(\n",
    "                        user_input=query,\n",
    "                        retrieved_contexts=contexts,\n",
    "                        reference=ground_truth\n",
    "                    )\n",
    "                \n",
    "                elif metric_name == \"context_relevance\":\n",
    "                    result = await scorer.ascore(\n",
    "                        user_input=query,\n",
    "                        retrieved_contexts=contexts\n",
    "                    )\n",
    "                \n",
    "                elif metric_name == \"response_groundedness\":\n",
    "                    result = await scorer.ascore(\n",
    "                        response=answer,\n",
    "                        retrieved_contexts=contexts\n",
    "                    )\n",
    "                \n",
    "                elif metric_name == \"answer_accuracy\":\n",
    "                    if not ground_truth:\n",
    "                        continue\n",
    "                    result = await scorer.ascore(\n",
    "                        user_input=query,\n",
    "                        response=answer,\n",
    "                        reference=ground_truth\n",
    "                    )\n",
    "                \n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                scores[metric_name] = float(result.value)\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ {metric_name}: {e}\")\n",
    "                scores[metric_name] = None\n",
    "\n",
    "            finally:\n",
    "                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n",
    "                if self.enable_timing:\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    self.metric_timings[metric_name].append(elapsed_time)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def _evaluate_single(self, query: str, answer: str, contexts: List[str],\n",
    "                        ground_truth: str = None) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # –ï—Å—Ç—å –∑–∞–ø—É—â–µ–Ω–Ω—ã–π loop - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ\n",
    "            loop = asyncio.get_running_loop()\n",
    "            if not self._nest_asyncio_applied:\n",
    "                self._apply_nest_asyncio()\n",
    "            return loop.run_until_complete(\n",
    "                self._evaluate_single_async(query, answer, contexts, ground_truth)\n",
    "            )\n",
    "        except RuntimeError:\n",
    "            # –ù–µ—Ç loop - —Å–æ–∑–¥–∞–µ–º —á–µ—Ä–µ–∑ asyncio.run()\n",
    "            return asyncio.run(\n",
    "                self._evaluate_single_async(query, answer, contexts, ground_truth)\n",
    "            )\n",
    "\n",
    "    def evaluate(self, \n",
    "                queries: List[str], \n",
    "                answers: List[str], \n",
    "                contexts: List[List[str]],\n",
    "                ground_truths: List[str] = None,\n",
    "                show_progress: bool = True) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ—Ü–µ–Ω–∫—É RAG —Å–∏—Å—Ç–µ–º—ã.\n",
    "        \n",
    "        Args:\n",
    "            queries: –°–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤\n",
    "            answers: –°–ø–∏—Å–æ–∫ –æ—Ç–≤–µ—Ç–æ–≤\n",
    "            contexts: –°–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤\n",
    "            ground_truths: –°–ø–∏—Å–æ–∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "            show_progress: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å\n",
    "        \n",
    "        Returns:\n",
    "            –°–ª–æ–≤–∞—Ä—å —Å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏\n",
    "        \"\"\"\n",
    "        if len(queries) != len(answers) or len(queries) != len(contexts):\n",
    "            raise ValueError(\"–î–ª–∏–Ω—ã queries, answers –∏ contexts –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å\")\n",
    "        \n",
    "        if ground_truths is None:\n",
    "            ground_truths = [None] * len(queries)\n",
    "        elif len(ground_truths) != len(queries):\n",
    "            raise ValueError(\"–î–ª–∏–Ω–∞ ground_truths –¥–æ–ª–∂–Ω–∞ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å queries\")\n",
    "        \n",
    "        has_ground_truth = any(gt and gt.strip() for gt in ground_truths if gt)\n",
    "        \n",
    "        self.logger.info(\"üöÄ –ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ RAGAS 0.4+...\")\n",
    "        self.logger.info(f\"‚öôÔ∏è  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å: {self.judge_llm_client.model}\")\n",
    "        self.logger.info(f\"üìä –ê–∫—Ç–∏–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫: {len(self.metric_scorers)}\")\n",
    "        self.logger.info(f\"üéØ Ground truth: {'–î–∞' if has_ground_truth else '–ù–µ—Ç'}\")\n",
    "        self.logger.info(f\"‚è≥ –û—Ü–µ–Ω–∫–∞ {len(queries)} –ø—Ä–∏–º–µ—Ä–æ–≤...\")\n",
    "        self.logger.info(\"‚ö†Ô∏è  –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç (LLM –≤—ã–∑–æ–≤—ã)\")\n",
    "        \n",
    "        # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "        self.evaluation_results.clear()\n",
    "        \n",
    "        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ø—Ä–∏–º–µ—Ä\n",
    "        iterator = tqdm(zip(queries, answers, contexts, ground_truths), \n",
    "                       total=len(queries),\n",
    "                       desc=\"–û—Ü–µ–Ω–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤\") if show_progress else zip(queries, answers, contexts, ground_truths)\n",
    "        \n",
    "        all_scores = {metric: [] for metric in self.metric_scorers.keys()}\n",
    "        \n",
    "        for query, answer, context, ground_truth in iterator:\n",
    "            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "            result = RAGEvaluationResult(\n",
    "                query=query,\n",
    "                answer=answer,\n",
    "                context=context,\n",
    "                ground_truth=ground_truth\n",
    "            )\n",
    "            \n",
    "            # –û—Ü–µ–Ω–∏–≤–∞–µ–º\n",
    "            try:\n",
    "                scores = self._evaluate_single(query, answer, context, ground_truth)\n",
    "                \n",
    "                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "                for metric_name, score in scores.items():\n",
    "                    setattr(result, metric_name, score)\n",
    "                    if score is not None:\n",
    "                        all_scores[metric_name].append(score)\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –ø—Ä–∏–º–µ—Ä–∞: {e}\")\n",
    "            \n",
    "            self.evaluation_results.append(result)\n",
    "        \n",
    "        # –í—ã—á–∏—Å–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "        aggregated = self._compute_aggregated_metrics(all_scores)\n",
    "        \n",
    "        self.logger.info(\"‚úÖ –û—Ü–µ–Ω–∫–∞ RAGAS –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!\")\n",
    "        return aggregated\n",
    "    \n",
    "    def _compute_aggregated_metrics(self, all_scores: Dict[str, List[float]]) -> Dict[str, float]:\n",
    "        \"\"\"–í—ã—á–∏—Å–ª—è–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏.\"\"\"\n",
    "        aggregated = {}\n",
    "        \n",
    "        for metric_name, scores in all_scores.items():\n",
    "            if scores:\n",
    "                aggregated[f\"{metric_name}_mean\"] = float(np.mean(scores))\n",
    "                aggregated[f\"{metric_name}_std\"] = float(np.std(scores))\n",
    "                aggregated[f\"{metric_name}_min\"] = float(np.min(scores))\n",
    "                aggregated[f\"{metric_name}_max\"] = float(np.max(scores))\n",
    "                aggregated[f\"{metric_name}_count\"] = len(scores)\n",
    "        \n",
    "        mean_values = [v for k, v in aggregated.items() if k.endswith('_mean')]\n",
    "        if mean_values:\n",
    "            aggregated['overall_mean'] = float(np.mean(mean_values))\n",
    "        \n",
    "        return aggregated\n",
    "    \n",
    "    def get_detailed_results(self) -> pd.DataFrame:\n",
    "        \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –≤–∏–¥–µ DataFrame.\"\"\"\n",
    "        data = []\n",
    "        for result in self.evaluation_results:\n",
    "            row = {\n",
    "                'query': result.query[:100] + '...' if len(result.query) > 100 else result.query,\n",
    "                'answer': result.answer[:100] + '...' if len(result.answer) > 100 else result.answer,\n",
    "            }\n",
    "            \n",
    "            for metric_name in self.AVAILABLE_METRICS:\n",
    "                value = getattr(result, metric_name, None)\n",
    "                row[metric_name] = value\n",
    "            \n",
    "            row['average_score'] = result.get_average_score()\n",
    "            data.append(row)\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def save_results(self, filepath: str = None) -> Path:\n",
    "        \"\"\"–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏.\"\"\"\n",
    "        if filepath is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filepath = Path(\"results\") / f\"ragas_evaluation_{timestamp}.json\"\n",
    "        else:\n",
    "            filepath = Path(filepath)\n",
    "        \n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        results_data = [result.to_dict() for result in self.evaluation_results]\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        self.logger.info(f\"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {filepath}\")\n",
    "        return filepath\n",
    "    \n",
    "    def display_results(self, max_examples: int = 5):\n",
    "        \"\"\"–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ –≤ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.\"\"\"\n",
    "        if not self.evaluation_results:\n",
    "            print(\"‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\")\n",
    "            return\n",
    "        \n",
    "        df = self.get_detailed_results()\n",
    "        \n",
    "        # –¶–≤–µ—Ç–∞ –¥–ª—è –º–µ—Ç—Ä–∏–∫\n",
    "        metric_colors = {\n",
    "            \"faithfulness\": \"#4CAF50\",\n",
    "            \"answer_relevancy\": \"#2196F3\",\n",
    "            \"context_precision\": \"#FFA726\",\n",
    "            \"context_recall\": \"#9C27B0\",\n",
    "            \"context_relevance\": \"#FF5722\",\n",
    "            \"response_groundedness\": \"#795548\",\n",
    "            \"answer_accuracy\": \"#F44336\",\n",
    "        }\n",
    "        \n",
    "        html = f\"\"\"\n",
    "        <div style=\"border: 2px solid #2196F3; border-radius: 12px; padding: 20px; margin: 15px 0; background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);\">\n",
    "            <h2 style=\"color: #1565C0; margin-top: 0;\">üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ RAGAS 0.4+</h2>\n",
    "            <p style=\"color: #666;\"><strong>–í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤:</strong> {len(self.evaluation_results)} | \n",
    "               <strong>–ú–µ—Ç—Ä–∏–∫:</strong> {len([m for m in self.AVAILABLE_METRICS if m in df.columns and df[m].notna().any()])}</p>\n",
    "        \"\"\"\n",
    "        \n",
    "        html += '<div style=\"display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 15px; margin: 20px 0;\">'\n",
    "        \n",
    "        for metric_name in self.AVAILABLE_METRICS:\n",
    "            if metric_name in df.columns:\n",
    "                values = df[metric_name].dropna()\n",
    "                if len(values) > 0:\n",
    "                    mean_val = values.mean()\n",
    "                    color = metric_colors.get(metric_name, \"#607D8B\")\n",
    "                    \n",
    "                    html += f\"\"\"\n",
    "                    <div style=\"text-align: center; padding: 15px; background: white; border-radius: 8px; border: 2px solid {color};\">\n",
    "                        <div style=\"font-weight: bold; color: {color}; margin-bottom: 8px; text-transform: capitalize;\">\n",
    "                            {metric_name.replace('_', ' ')}\n",
    "                        </div>\n",
    "                        <div style=\"font-size: 32px; font-weight: bold; color: {color};\">{mean_val:.3f}</div>\n",
    "                        <div style=\"background-color: {color}22; height: 10px; border-radius: 5px; margin-top: 8px;\">\n",
    "                            <div style=\"background-color: {color}; height: 100%; width: {min(mean_val*100, 100)}%; border-radius: 5px;\"></div>\n",
    "                        </div>\n",
    "                        <div style=\"font-size: 12px; color: #666; margin-top: 5px;\">\n",
    "                            Min: {values.min():.3f} | Max: {values.max():.3f}\n",
    "                        </div>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "        \n",
    "        html += '</div>'\n",
    "        \n",
    "        # –î–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã\n",
    "        html += f\"\"\"\n",
    "        <h3 style=\"color: #1565C0; margin-top: 25px;\">üìã –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (—Ç–æ–ø-{max_examples}):</h3>\n",
    "        \"\"\"\n",
    "        \n",
    "        for i, result in enumerate(self.evaluation_results[:max_examples]):\n",
    "            avg_score = result.get_average_score()\n",
    "            border_color = \"#4CAF50\" if avg_score > 0.7 else \"#FFA726\" if avg_score > 0.5 else \"#F44336\"\n",
    "            \n",
    "            html += f\"\"\"\n",
    "            <div style=\"background: white; padding: 15px; margin: 12px 0; border-radius: 8px; border-left: 5px solid {border_color};\">\n",
    "                <div style=\"display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;\">\n",
    "                    <strong style=\"color: #1a237e; font-size: 1.1em;\">–ü—Ä–∏–º–µ—Ä #{i+1}</strong>\n",
    "                    <span style=\"background: {border_color}; color: white; padding: 4px 12px; border-radius: 15px; font-weight: bold;\">\n",
    "                        –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª: {avg_score:.3f}\n",
    "                    </span>\n",
    "                </div>\n",
    "                \n",
    "                <div style=\"background: #f8f9fa; padding: 10px; border-radius: 5px; margin: 8px 0;\">\n",
    "                    <strong style=\"color: #666;\">‚ùì –í–æ–ø—Ä–æ—Å:</strong><br/>\n",
    "                    <span style=\"color: #1a237e;\">{result.query[:200]}{'...' if len(result.query) > 200 else ''}</span>\n",
    "                </div>\n",
    "                \n",
    "                <div style=\"background: #e8f5e9; padding: 10px; border-radius: 5px; margin: 8px 0;\">\n",
    "                    <strong style=\"color: #666;\">‚úÖ –û—Ç–≤–µ—Ç:</strong><br/>\n",
    "                    <span style=\"color: #2e7d32;\">{result.answer[:300]}{'...' if len(result.answer) > 300 else ''}</span>\n",
    "                </div>\n",
    "                \n",
    "                <div style=\"display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 8px; margin-top: 10px;\">\n",
    "            \"\"\"\n",
    "            \n",
    "            for metric_name in self.AVAILABLE_METRICS:\n",
    "                value = getattr(result, metric_name, None)\n",
    "                if value is not None:\n",
    "                    color = metric_colors.get(metric_name, \"#607D8B\")\n",
    "                    html += f\"\"\"\n",
    "                    <div style=\"background: {color}15; padding: 6px 10px; border-radius: 5px; text-align: center; border: 1px solid {color}50;\">\n",
    "                        <div style=\"font-size: 11px; color: #666; text-transform: uppercase;\">{metric_name.replace('_', ' ')}</div>\n",
    "                        <div style=\"font-size: 18px; font-weight: bold; color: {color};\">{value:.3f}</div>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "            \n",
    "            html += \"\"\"\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        html += \"</div>\"\n",
    "        \n",
    "        display(HTML(html))\n",
    "        \n",
    "        print(\"\\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Å–≤–æ–¥–∫–∞:\")\n",
    "        display(df.describe().style.background_gradient(cmap='viridis'))\n",
    "\n",
    "    def get_timing_statistics(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫.\n",
    "        \"\"\"\n",
    "        if not self.metric_timings:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        stats = []\n",
    "        for metric_name, times in self.metric_timings.items():\n",
    "            if times:\n",
    "                stats.append({\n",
    "                    'metric': metric_name,\n",
    "                    'count': len(times),\n",
    "                    'total_time_sec': sum(times),\n",
    "                    'avg_time_sec': np.mean(times),\n",
    "                    'min_time_sec': np.min(times),\n",
    "                    'max_time_sec': np.max(times),\n",
    "                    'std_time_sec': np.std(times),\n",
    "                })\n",
    "        \n",
    "        df = pd.DataFrame(stats)\n",
    "        if not df.empty:\n",
    "            df = df.sort_values('avg_time_sec', ascending=False)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def display_timing_analysis(self):\n",
    "        \"\"\"\n",
    "        –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫.\n",
    "        \"\"\"\n",
    "        df = self.get_timing_statistics()\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\")\n",
    "            return\n",
    "        \n",
    "        total_time = df['total_time_sec'].sum()\n",
    "        \n",
    "        html = f\"\"\"\n",
    "        <div style=\"border: 2px solid #FF9800; border-radius: 12px; padding: 20px; margin: 15px 0; \n",
    "                    background: linear-gradient(135deg, #FFF3E0 0%, #FFE0B2 100%);\">\n",
    "            <h2 style=\"color: #E65100; margin-top: 0;\">‚è±Ô∏è –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫</h2>\n",
    "            <p style=\"color: #666;\"><strong>–û–±—â–µ–µ –≤—Ä–µ–º—è:</strong> {total_time:.1f} —Å–µ–∫ ({total_time/60:.1f} –º–∏–Ω)</p>\n",
    "            \n",
    "            <table style=\"width: 100%; border-collapse: collapse; background: white; margin-top: 15px;\">\n",
    "                <thead>\n",
    "                    <tr style=\"background: #FF9800; color: white;\">\n",
    "                        <th style=\"padding: 10px; text-align: left;\">–ú–µ—Ç—Ä–∏–∫–∞</th>\n",
    "                        <th style=\"padding: 10px; text-align: center;\">–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ</th>\n",
    "                        <th style=\"padding: 10px; text-align: right;\">–°—Ä–µ–¥–Ω–µ–µ (—Å–µ–∫)</th>\n",
    "                        <th style=\"padding: 10px; text-align: right;\">–û–±—â–µ–µ (—Å–µ–∫)</th>\n",
    "                        <th style=\"padding: 10px; text-align: right;\">% –≤—Ä–µ–º–µ–Ω–∏</th>\n",
    "                    </tr>\n",
    "                </thead>\n",
    "                <tbody>\n",
    "        \"\"\"\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            percentage = (row['total_time_sec'] / total_time) * 100\n",
    "            avg_time = row['avg_time_sec']\n",
    "            \n",
    "            # –¶–≤–µ—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—Ä–µ–º–µ–Ω–∏\n",
    "            if avg_time > 10:\n",
    "                bg_color = \"#FFCDD2\"  # –ö—Ä–∞—Å–Ω—ã–π (–º–µ–¥–ª–µ–Ω–Ω–æ)\n",
    "            elif avg_time > 5:\n",
    "                bg_color = \"#FFE0B2\"  # –û—Ä–∞–Ω–∂–µ–≤—ã–π (—Å—Ä–µ–¥–Ω–µ)\n",
    "            else:\n",
    "                bg_color = \"#C8E6C9\"  # –ó–µ–ª–µ–Ω—ã–π (–±—ã—Å—Ç—Ä–æ)\n",
    "            \n",
    "            html += f\"\"\"\n",
    "                <tr style=\"background: {bg_color};\">\n",
    "                    <td style=\"padding: 8px; font-weight: bold;\">{row['metric']}</td>\n",
    "                    <td style=\"padding: 8px; text-align: center;\">{row['count']}</td>\n",
    "                    <td style=\"padding: 8px; text-align: right;\">{row['avg_time_sec']:.2f}</td>\n",
    "                    <td style=\"padding: 8px; text-align: right;\">{row['total_time_sec']:.1f}</td>\n",
    "                    <td style=\"padding: 8px; text-align: right;\">{percentage:.1f}%</td>\n",
    "                </tr>\n",
    "            \"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "                </tbody>\n",
    "            </table>\n",
    "            \n",
    "            <div style=\"margin-top: 15px; padding: 10px; background: #FFF9C4; border-radius: 5px;\">\n",
    "                <strong>üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:</strong>\n",
    "                <ul style=\"margin: 5px 0;\">\n",
    "        \"\"\"\n",
    "        \n",
    "        # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–µ –º–µ–¥–ª–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "        slow_metrics = df[df['avg_time_sec'] > df['avg_time_sec'].median()]['metric'].tolist()\n",
    "        \n",
    "        if slow_metrics:\n",
    "            html += f\"<li>üêå <strong>–ú–µ–¥–ª–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:</strong> {', '.join(slow_metrics)}</li>\"\n",
    "        \n",
    "        # –ú–µ—Ç—Ä–∏–∫–∏ —Å –Ω–∏–∑–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å—é\n",
    "        if 'faithfulness' in df['metric'].values and 'response_groundedness' in df['metric'].values:\n",
    "            html += \"\"\"\n",
    "                <li>‚ö†Ô∏è <strong>faithfulness</strong> –∏ <strong>response_groundedness</strong> \n",
    "                –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (1.0) - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –æ–¥–Ω–æ–π –∏–∑ –Ω–∏—Ö</li>\n",
    "            \"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "                </ul>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        display(HTML(html))\n",
    "        \n",
    "        # –¢–∞–∫–∂–µ –≤—ã–≤–æ–¥–∏–º DataFrame\n",
    "        print(\"\\nüìä –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞:\")\n",
    "        display(df.style.background_gradient(cmap='YlOrRd', subset=['avg_time_sec']))\n",
    "    \n",
    "    def get_recommended_metrics(self, \n",
    "                               max_avg_time: float = 10.0,\n",
    "                               exclude_redundant: bool = True) -> List[str]:\n",
    "        \"\"\"\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "        \n",
    "        Args:\n",
    "            max_avg_time: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (—Å–µ–∫)\n",
    "            exclude_redundant: –ò—Å–∫–ª—é—á–∏—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "        \n",
    "        Returns:\n",
    "            –°–ø–∏—Å–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã—Ö –º–µ—Ç—Ä–∏–∫\n",
    "        \"\"\"\n",
    "        df = self.get_timing_statistics()\n",
    "        \n",
    "        if df.empty:\n",
    "            return self.metrics_to_use\n",
    "        \n",
    "        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏\n",
    "        fast_metrics = df[df['avg_time_sec'] <= max_avg_time]['metric'].tolist()\n",
    "        \n",
    "        # –ò—Å–∫–ª—é—á–∞–µ–º –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ\n",
    "        if exclude_redundant:\n",
    "            # –ü—Ä–æ–≤–µ—Ä—è–µ–º faithfulness –∏ response_groundedness\n",
    "            results_df = self.get_detailed_results()\n",
    "            \n",
    "            if 'faithfulness' in results_df.columns and 'response_groundedness' in results_df.columns:\n",
    "                faith_vals = results_df['faithfulness'].dropna()\n",
    "                ground_vals = results_df['response_groundedness'].dropna()\n",
    "                \n",
    "                # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ—á—Ç–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ, –∏—Å–∫–ª—é—á–∞–µ–º –æ–¥–Ω—É\n",
    "                if len(faith_vals) > 0 and len(ground_vals) > 0:\n",
    "                    correlation = faith_vals.corr(ground_vals)\n",
    "                    \n",
    "                    if correlation > 0.95:  # –û—á–µ–Ω—å —Å–∏–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è\n",
    "                        # –û—Å—Ç–∞–≤–ª—è–µ–º –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—É—é –º–µ—Ç—Ä–∏–∫—É\n",
    "                        faith_time = df[df['metric'] == 'faithfulness']['avg_time_sec'].values\n",
    "                        ground_time = df[df['metric'] == 'response_groundedness']['avg_time_sec'].values\n",
    "                        \n",
    "                        if len(faith_time) > 0 and len(ground_time) > 0:\n",
    "                            if faith_time[0] > ground_time[0]:\n",
    "                                fast_metrics = [m for m in fast_metrics if m != 'faithfulness']\n",
    "                                self.logger.info(\"‚ÑπÔ∏è –ò—Å–∫–ª—é—á–µ–Ω–∞ faithfulness (–∏–∑–±—ã—Ç–æ—á–Ω–∞)\")\n",
    "                            else:\n",
    "                                fast_metrics = [m for m in fast_metrics if m != 'response_groundedness']\n",
    "                                self.logger.info(\"‚ÑπÔ∏è –ò—Å–∫–ª—é—á–µ–Ω–∞ response_groundedness (–∏–∑–±—ã—Ç–æ—á–Ω–∞)\")\n",
    "        \n",
    "        self.logger.info(f\"‚úÖ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏: {', '.join(fast_metrics)}\")\n",
    "        return fast_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "761f0c57-b007-4744-ac59-924b2c218890",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor:\n",
    "    \"\"\"–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —á–∞–Ω–∫–æ–≤.\"\"\"\n",
    "    \n",
    "    def __init__(self, chunk_size: int = 500, chunk_overlap: int = 50):\n",
    "        \"\"\"\n",
    "        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ —Ç–µ–∫—Å—Ç–∞.\n",
    "        \n",
    "        Args:\n",
    "            chunk_size: –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö\n",
    "            chunk_overlap: –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏\n",
    "        \"\"\"\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=len,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def split_text(self, text: str, metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        –†–∞–∑–¥–µ–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏.\n",
    "        \n",
    "        Args:\n",
    "            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç\n",
    "            meta –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤\n",
    "        \n",
    "        Returns:\n",
    "            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å —á–∞–Ω–∫–∞–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏\n",
    "        \"\"\"\n",
    "        if metadata is None:\n",
    "            metadata = {}\n",
    "        \n",
    "        # –†–∞–∑–¥–µ–ª—è–µ–º —Ç–µ–∫—Å—Ç\n",
    "        chunks = self.text_splitter.split_text(text)\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞\n",
    "        result = []\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk_meta = metadata.copy()\n",
    "            chunk_meta.update({\n",
    "                \"chunk_index\": i,\n",
    "                \"total_chunks\": len(chunks),\n",
    "                \"chunk_size\": len(chunk),\n",
    "                \"is_truncated\": len(chunk) >= self.chunk_size\n",
    "            })\n",
    "            result.append({\n",
    "                \"text\": chunk,\n",
    "                \"metadata\": chunk_meta\n",
    "            })\n",
    "        \n",
    "        self.logger.info(f\"–†–∞–∑–¥–µ–ª–µ–Ω–æ –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤\")\n",
    "        return result\n",
    "    \n",
    "    def process_file(self, file_path: Path) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª.\n",
    "        \n",
    "        Args:\n",
    "            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É\n",
    "        \n",
    "        Returns:\n",
    "            –°–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏\n",
    "            encodings = ['utf-8', 'cp1251', 'latin-1']\n",
    "            for encoding in encodings:\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding=encoding) as f:\n",
    "                        content = f.read().strip()\n",
    "                    break\n",
    "                except UnicodeDecodeError:\n",
    "                    continue\n",
    "            else:\n",
    "                self.logger.error(f\"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª {file_path}\")\n",
    "                return []\n",
    "            \n",
    "            if not content:\n",
    "                self.logger.warning(f\"–§–∞–π–ª {file_path} –ø—É—Å—Ç–æ–π\")\n",
    "                return []\n",
    "            \n",
    "            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n",
    "            base_metadata = {\n",
    "                \"source_file\": file_path.name,\n",
    "                \"file_path\": str(file_path),\n",
    "                \"file_size\": len(content),\n",
    "                \"encoding\": encoding\n",
    "            }\n",
    "            \n",
    "            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —á–∞–Ω–∫–∏\n",
    "            chunks = self.split_text(content, base_metadata)\n",
    "            return chunks\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "966ac037-e021-405e-bce8-382a525b1e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∑—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str = None):\n",
    "        \"\"\"\n",
    "        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö.\n",
    "        \n",
    "        Args:\n",
    "            data_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir or Config.DEFAULT_DATA_DIR)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        if not self.data_dir.exists():\n",
    "            self.logger.warning(f\"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {self.data_dir} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\")\n",
    "            self.data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def load_files_to_dataframe(self,\n",
    "                               file_pattern: str = \"*.txt\",\n",
    "                               max_files: int = None,\n",
    "                               process_chunks: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª—ã –≤ DataFrame.\n",
    "        \n",
    "        Args:\n",
    "            file_pattern: –®–∞–±–ª–æ–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤\n",
    "            max_files: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏\n",
    "            process_chunks: –†–∞–∑–¥–µ–ª—è—Ç—å –ª–∏ —Ñ–∞–π–ª—ã –Ω–∞ —á–∞–Ω–∫–∏\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame —Å —Ç–µ–∫—Å—Ç–∞–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏\n",
    "        \"\"\"\n",
    "        # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª—ã\n",
    "        files = list(self.data_dir.glob(file_pattern))\n",
    "        if max_files:\n",
    "            files = files[:max_files]\n",
    "        \n",
    "        if not files:\n",
    "            self.logger.warning(f\"–§–∞–π–ª—ã –ø–æ —à–∞–±–ª–æ–Ω—É {file_pattern} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        self.logger.info(f\"–ù–∞–π–¥–µ–Ω–æ {len(files)} —Ñ–∞–π–ª–æ–≤\")\n",
    "        \n",
    "        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã\n",
    "        processor = TextProcessor()\n",
    "        all_chunks = []\n",
    "        \n",
    "        for file_path in tqdm(files, desc=\"–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤\"):\n",
    "            if process_chunks:\n",
    "                chunks = processor.process_file(file_path)\n",
    "                all_chunks.extend(chunks)\n",
    "            else:\n",
    "                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª—ã –±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ —á–∞–Ω–∫–∏\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        content = f.read().strip()\n",
    "                    all_chunks.append({\n",
    "                        \"text\": content,\n",
    "                        \"metadata\": {\n",
    "                            \"source_file\": file_path.name,\n",
    "                            \"file_path\": str(file_path)\n",
    "                        }\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {file_path}: {e}\")\n",
    "        \n",
    "        if not all_chunks:\n",
    "            self.logger.error(\"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º DataFrame\n",
    "        data = []\n",
    "        for i, chunk in enumerate(all_chunks):\n",
    "            record = {\n",
    "                \"id\": self._generate_chunk_id(chunk[\"metadata\"], i),\n",
    "                \"text\": chunk[\"text\"],\n",
    "                **chunk[\"metadata\"]\n",
    "            }\n",
    "            data.append(record)\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        self.logger.info(f\"–°–æ–∑–¥–∞–Ω DataFrame —Å {len(df)} –∑–∞–ø–∏—Å—è–º–∏\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _generate_chunk_id(self, metadata: Dict, index: int) -> str:\n",
    "        \"\"\"\n",
    "        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è —á–∞–Ω–∫–∞.\n",
    "        \n",
    "        Args:\n",
    "            meta –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —á–∞–Ω–∫–∞\n",
    "            index: –ò–Ω–¥–µ–∫—Å —á–∞–Ω–∫–∞\n",
    "        \n",
    "        Returns:\n",
    "            –£–Ω–∏–∫–∞–ª—å–Ω—ã–π —Å—Ç—Ä–æ–∫–æ–≤—ã–π ID\n",
    "        \"\"\"\n",
    "        # –°–æ–∑–¥–∞–µ–º —Ö—ç—à –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö\n",
    "        source = metadata.get(\"source_file\", \"unknown\")\n",
    "        chunk_idx = metadata.get(\"chunk_index\", index)\n",
    "        \n",
    "        # –ò—Å–ø–æ–ª—å–∑—É–µ–º MD5 –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ ID\n",
    "        hash_input = f\"{source}_{chunk_idx}_{datetime.now().timestamp()}\"\n",
    "        hash_digest = hashlib.md5(hash_input.encode()).hexdigest()[:12]\n",
    "        return f\"chunk_{hash_digest}\"\n",
    "    \n",
    "    def save_dataframe(self, df: pd.DataFrame, output_path: str):\n",
    "        \"\"\"\n",
    "        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤ —Ñ–∞–π–ª.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n",
    "            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n",
    "        \"\"\"\n",
    "        try:\n",
    "            output_path = Path(output_path)\n",
    "            output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ Parquet (—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö)\n",
    "            if output_path.suffix == '.parquet':\n",
    "                df.to_parquet(output_path, index=False)\n",
    "            # –ò–ª–∏ –≤ CSV\n",
    "            elif output_path.suffix == '.csv':\n",
    "                df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "            # –ò–ª–∏ –≤ Pickle\n",
    "            elif output_path.suffix == '.pkl':\n",
    "                df.to_pickle(output_path)\n",
    "            else:\n",
    "                # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Parquet\n",
    "                output_path = output_path.with_suffix('.parquet')\n",
    "                df.to_parquet(output_path, index=False)\n",
    "            \n",
    "            self.logger.info(f\"DataFrame —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_path}\")\n",
    "            return output_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è DataFrame: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ddf9fd1-342f-4e4c-a1bf-1aaf34bc7dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilingualE5Embedder:\n",
    "    \"\"\"–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—å—é multilingual-e5-large.\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                model_name: str = Config.EMBEDDING_MODEL,\n",
    "                device: str = None,\n",
    "                cache_dir: str = None,\n",
    "                use_fp16: bool = None):\n",
    "        \"\"\"\n",
    "        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.\n",
    "        \n",
    "        Args:\n",
    "            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ Hugging Face\n",
    "            device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (cuda/cpu)\n",
    "            cache_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏\n",
    "            use_fp16: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ FP16 –¥–ª—è GPU\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.device = device or Config.DEVICE\n",
    "        self.cache_dir = cache_dir or Config.DEFAULT_MODEL_CACHE\n",
    "        self.use_fp16 = use_fp16 if use_fp16 is not None else Config.USE_FP16\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∫—ç—à–∞\n",
    "        Path(self.cache_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä.\"\"\"\n",
    "        try:\n",
    "            self.logger.info(f\"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {self.model_name} –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ {self.device}...\")\n",
    "            \n",
    "            # –ò—Å–ø–æ–ª—å–∑—É–µ–º sentence-transformers –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞\n",
    "            model_kwargs = {}\n",
    "            if self.device == \"cuda\" and self.use_fp16:\n",
    "                model_kwargs[\"torch_dtype\"] = torch.float16\n",
    "            \n",
    "            self.model = SentenceTransformer(\n",
    "                self.model_name,\n",
    "                device=self.device,\n",
    "                cache_folder=str(self.cache_dir),\n",
    "                **model_kwargs\n",
    "            )\n",
    "            \n",
    "            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                self.model_name,\n",
    "                cache_dir=str(self.cache_dir)\n",
    "            )\n",
    "            \n",
    "            self.logger.info(f\"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {self.device}\")\n",
    "            self.logger.info(f\"üìè –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {self.get_embedding_dimension()}\")\n",
    "            \n",
    "            # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–º—è—Ç–∏ GPU\n",
    "            if self.device == \"cuda\":\n",
    "                gpu_memory = torch.cuda.memory_allocated() / 1e9\n",
    "                self.logger.info(f\"üéÆ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø–∞–º—è—Ç–∏ GPU: {gpu_memory:.2f} GB\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def get_embedding_dimension(self) -> int:\n",
    "        \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –º–æ–¥–µ–ª–∏.\"\"\"\n",
    "        if self.model is None:\n",
    "            return Config.EMBEDDING_DIMENSION\n",
    "        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑ –º–æ–¥–µ–ª–∏\n",
    "        return self.model.get_sentence_embedding_dimension()\n",
    "    \n",
    "    def format_text(self, text: str, text_type: str = \"passage\") -> str:\n",
    "        \"\"\"\n",
    "        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º E5.\n",
    "        \n",
    "        Args:\n",
    "            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç\n",
    "            text_type: –¢–∏–ø —Ç–µ–∫—Å—Ç–∞ (query/passage)\n",
    "        \n",
    "        Returns:\n",
    "            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º\n",
    "        \"\"\"\n",
    "        if text_type not in [\"query\", \"passage\"]:\n",
    "            raise ValueError(\"text_type –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'query' –∏–ª–∏ 'passage'\")\n",
    "        \n",
    "        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –∏ –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å\n",
    "        cleaned_text = text.strip()\n",
    "        return f\"{text_type}: {cleaned_text}\"\n",
    "    \n",
    "    def embed_texts(self,\n",
    "                   texts: List[str],\n",
    "                   text_type: str = \"passage\",\n",
    "                   batch_size: int = 32,\n",
    "                   show_progress: bool = True) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        –°–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤.\n",
    "        \n",
    "        Args:\n",
    "            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤\n",
    "            text_type: –¢–∏–ø —Ç–µ–∫—Å—Ç–æ–≤ (query/passage)\n",
    "            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞\n",
    "            show_progress: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä\n",
    "        \n",
    "        Returns:\n",
    "            –ú–∞—Å—Å–∏–≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "        \"\"\"\n",
    "        if not texts:\n",
    "            return np.array([])\n",
    "        \n",
    "        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç—ã\n",
    "        formatted_texts = [self.format_text(text, text_type) for text in texts]\n",
    "        \n",
    "        self.logger.info(f\"üîç –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤...\")\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏\n",
    "        try:\n",
    "            embeddings = self.model.encode(\n",
    "                formatted_texts,\n",
    "                batch_size=batch_size,\n",
    "                show_progress_bar=show_progress,\n",
    "                convert_to_numpy=True,\n",
    "                normalize_embeddings=True,\n",
    "                device=self.device\n",
    "            )\n",
    "            \n",
    "            self.logger.info(f\"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(embeddings)} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\")\n",
    "            return embeddings\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def embed_query(self, query: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        –°–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.\n",
    "        \n",
    "        Args:\n",
    "            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞\n",
    "        \n",
    "        Returns:\n",
    "            –≠–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞\n",
    "        \"\"\"\n",
    "        return self.embed_texts([query], text_type=\"query\", show_progress=False)[0]\n",
    "    \n",
    "    def compute_similarity(self,\n",
    "                          query_embedding: np.ndarray,\n",
    "                          passage_embeddings: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        –í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–æ–º –∏ –ø–∞—Å—Å–∞–∂–∞–º–∏.\n",
    "        \n",
    "        Args:\n",
    "            query_embedding: –≠–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞\n",
    "            passage_embeddings: –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–∞—Å—Å–∞–∂–µ–π\n",
    "        \n",
    "        Returns:\n",
    "            –ú–∞—Å—Å–∏–≤ —Å—Ö–æ–¥—Å—Ç–≤\n",
    "        \"\"\"\n",
    "        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä—ã (–µ—Å–ª–∏ –µ—â–µ –Ω–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã)\n",
    "        query_norm = query_embedding / np.linalg.norm(query_embedding)\n",
    "        passages_norm = passage_embeddings / np.linalg.norm(passage_embeddings, axis=1, keepdims=True)\n",
    "        \n",
    "        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ\n",
    "        similarities = np.dot(passages_norm, query_norm)\n",
    "        return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b3de1bf-40e2-4469-b285-f27a9cc9041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChromaStorage:\n",
    "    \"\"\"\n",
    "    –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ–º ChromaDB.\n",
    "    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç multilingual-e5-large –º–æ–¥–µ–ª—å.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                db_path: str,\n",
    "                collection_name: str = Config.COLLECTION_NAME,\n",
    "                embedding_model: MultilingualE5Embedder = None,\n",
    "                create_if_missing: bool = True,\n",
    "                reset_db: bool = False):\n",
    "        \"\"\"\n",
    "        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ö—Ä–∞–Ω–∏–ª–∏—â–∞.\n",
    "        \n",
    "        Args:\n",
    "            db_path: –ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "            collection_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏\n",
    "            embedding_model: –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "            create_if_missing: –°–æ–∑–¥–∞–≤–∞—Ç—å –ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—é, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç\n",
    "            reset_db: –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –ª–∏ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö (–¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫)\n",
    "        \"\"\"\n",
    "        self.db_path = Path(db_path)\n",
    "        self.collection_name = collection_name\n",
    "        self.create_if_missing = create_if_missing\n",
    "        \n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "        if embedding_model is None:\n",
    "            self.embedding_model = MultilingualE5Embedder()\n",
    "        else:\n",
    "            self.embedding_model = embedding_model\n",
    "        \n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç–∞ ChromaDB\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self.vector_store = None\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –±–∞–∑—É, –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è\n",
    "        if reset_db and self.db_path.exists():\n",
    "            self.logger.warning(f\"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∏–µ –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {self.db_path}\")\n",
    "            try:\n",
    "                shutil.rmtree(self.db_path)\n",
    "                self.logger.info(\"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —É–¥–∞–ª–µ–Ω–∞\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –±–∞–∑—ã: {e}\")\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\n",
    "        self.db_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self._init_chroma()\n",
    "    \n",
    "    def _init_chroma(self):\n",
    "        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç ChromaDB.\"\"\"\n",
    "        try:\n",
    "            # ‚úÖ –ù–û–í–´–ô API ChromaDB (–≤–µ—Ä—Å–∏—è >= 1.0.0)\n",
    "            self.client = chromadb.PersistentClient(\n",
    "                path=str(self.db_path)\n",
    "            )\n",
    "            \n",
    "            self.logger.info(f\"‚úÖ ChromaDB –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.db_path}\")\n",
    "            \n",
    "            # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é\n",
    "            self._init_collection()\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ChromaDB: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _init_collection(self):\n",
    "        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–ª–ª–µ–∫—Ü–∏—é.\"\"\"\n",
    "        try:\n",
    "            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é\n",
    "            try:\n",
    "                self.collection = self.client.get_collection(self.collection_name)\n",
    "                self.logger.info(f\"üìÇ –ö–æ–ª–ª–µ–∫—Ü–∏—è '{self.collection_name}' –∑–∞–≥—Ä—É–∂–µ–Ω–∞\")\n",
    "            except Exception:\n",
    "                if self.create_if_missing:\n",
    "                    # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ù–æ–≤—ã–π —Å–ø–æ—Å–æ–± —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏\n",
    "                    self.collection = self.client.create_collection(\n",
    "                        name=self.collection_name,\n",
    "                        metadata={\"hnsw:space\": \"cosine\"}\n",
    "                    )\n",
    "                    self.logger.info(f\"üÜï –°–æ–∑–¥–∞–Ω–∞ –∫–æ–ª–ª–µ–∫—Ü–∏—è '{self.collection_name}'\")\n",
    "                else:\n",
    "                    raise ValueError(f\"–ö–æ–ª–ª–µ–∫—Ü–∏—è '{self.collection_name}' –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\")\n",
    "            \n",
    "            # –°–æ–∑–¥–∞–µ–º LangChain –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ\n",
    "            self.vector_store = Chroma(\n",
    "                client=self.client,\n",
    "                collection_name=self.collection_name,\n",
    "                embedding_function=self._get_langchain_embedding_function()\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _get_langchain_embedding_function(self):\n",
    "        \"\"\"–°–æ–∑–¥–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è LangChain.\"\"\"\n",
    "        # –°–æ–∑–¥–∞–µ–º –æ–±–µ—Ä—Ç–∫—É –¥–ª—è –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏\n",
    "        class E5EmbeddingFunction:\n",
    "            def __init__(self, embedder: MultilingualE5Embedder):\n",
    "                self.embedder = embedder\n",
    "            \n",
    "            def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "                embeddings = self.embedder.embed_texts(texts, text_type=\"passage\")\n",
    "                return embeddings.tolist()\n",
    "            \n",
    "            def embed_query(self, text: str) -> List[float]:\n",
    "                embedding = self.embedder.embed_query(text)\n",
    "                return embedding.tolist()\n",
    "        \n",
    "        return E5EmbeddingFunction(self.embedding_model)\n",
    "    \n",
    "    def add_texts(self,\n",
    "                 texts: List[str],\n",
    "                 metadatas: List[Dict] = None,\n",
    "                 ids: List[str] = None,\n",
    "                 batch_size: int = 32) -> List[str]:\n",
    "        \"\"\"\n",
    "        –î–æ–±–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç—ã –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.\n",
    "        \n",
    "        Args:\n",
    "            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤\n",
    "            metadatas: –°–ø–∏—Å–æ–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö\n",
    "            ids: –°–ø–∏—Å–æ–∫ ID (–≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã)\n",
    "            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞\n",
    "        \n",
    "        Returns:\n",
    "            –°–ø–∏—Å–æ–∫ ID –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π\n",
    "        \"\"\"\n",
    "        if not texts:\n",
    "            self.logger.warning(\"‚ö†Ô∏è –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –ø—É—Å—Ç\")\n",
    "            return []\n",
    "        \n",
    "        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã\n",
    "        if ids is None:\n",
    "            ids = [f\"doc_{hashlib.md5(text.encode()).hexdigest()[:12]}\" \n",
    "                  for text in texts]\n",
    "        \n",
    "        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n",
    "        if metadatas is None:\n",
    "            metadatas = [{} for _ in texts]\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É —Å–ø–∏—Å–∫–æ–≤\n",
    "        if len(texts) != len(ids) or len(texts) != len(metadatas):\n",
    "            raise ValueError(\"–î–ª–∏–Ω—ã texts, ids –∏ metadatas –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å\")\n",
    "        \n",
    "        self.logger.info(f\"‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∏–µ {len(texts)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...\")\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –±–∞—Ç—á–∞–º–∏\n",
    "        added_ids = []\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ ChromaDB\"):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            batch_ids = ids[i:i+batch_size]\n",
    "            batch_metadatas = metadatas[i:i+batch_size]\n",
    "            \n",
    "            # ‚úÖ –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏\n",
    "            batch_embeddings = self.embedding_model.embed_texts(\n",
    "                batch_texts, \n",
    "                text_type=\"passage\",\n",
    "                show_progress=False\n",
    "            )\n",
    "            \n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é\n",
    "            self.collection.add(\n",
    "                documents=batch_texts,\n",
    "                embeddings=batch_embeddings.tolist(),\n",
    "                metadatas=batch_metadatas,\n",
    "                ids=batch_ids\n",
    "            )\n",
    "            added_ids.extend(batch_ids)\n",
    "        \n",
    "        self.logger.info(f\"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(added_ids)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\")\n",
    "        return added_ids\n",
    "    \n",
    "    def search(self,\n",
    "              query: str,\n",
    "              top_k: int = Config.DEFAULT_TOP_K,\n",
    "              score_threshold: float = Config.SIMILARITY_THRESHOLD,\n",
    "              filter_meta: Dict[str, Any] = None) -> List[SearchResult]:\n",
    "        \"\"\"\n",
    "        –í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫.\n",
    "        \n",
    "        Args:\n",
    "            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å\n",
    "            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "            score_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞\n",
    "            filter_meta: –§–∏–ª—å—Ç—Ä –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º\n",
    "        \n",
    "        Returns:\n",
    "            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞\n",
    "        \"\"\"\n",
    "        if not query.strip():\n",
    "            raise ValueError(\"–ó–∞–ø—Ä–æ—Å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º\")\n",
    "        \n",
    "        self.logger.info(f\"üîç –ü–æ–∏—Å–∫: '{query[:50]}...'\")\n",
    "        \n",
    "        try:\n",
    "            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞\n",
    "            query_embedding = self.embedding_model.embed_query(query)\n",
    "            \n",
    "            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫\n",
    "            results = self.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k,\n",
    "                where=filter_meta\n",
    "            )\n",
    "            \n",
    "            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "            search_results = []\n",
    "            if results['ids'] and len(results['ids'][0]) > 0:\n",
    "                for i in range(len(results['ids'][0])):\n",
    "                    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ö–æ–¥—Å—Ç–≤–æ\n",
    "                    distance = results['distances'][0][i] if 'distances' in results else 0\n",
    "                    similarity = 1.0 / (1.0 + distance)  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ distance –≤ similarity\n",
    "                    \n",
    "                    if similarity >= score_threshold:\n",
    "                        result = SearchResult(\n",
    "                            id=results['ids'][0][i],\n",
    "                            content=results['documents'][0][i],\n",
    "                            similarity_score=similarity,\n",
    "                            metadata=results['metadatas'][0][i] if results['metadatas'] else {}\n",
    "                        )\n",
    "                        search_results.append(result)\n",
    "            \n",
    "            self.logger.info(f\"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(search_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\")\n",
    "            return search_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def delete_by_ids(self, ids: List[str]) -> int:\n",
    "        \"\"\"\n",
    "        –£–¥–∞–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ ID.\n",
    "        \n",
    "        Args:\n",
    "            ids: –°–ø–∏—Å–æ–∫ ID –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è\n",
    "        \n",
    "        Returns:\n",
    "            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
    "        \"\"\"\n",
    "        if not ids:\n",
    "            return 0\n",
    "        \n",
    "        try:\n",
    "            self.collection.delete(ids=ids)\n",
    "            self.logger.info(f\"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {len(ids)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\")\n",
    "            return len(ids)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def get_collection_info(self) -> Dict[str, Any]:\n",
    "        \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏.\"\"\"\n",
    "        try:\n",
    "            count = self.collection.count()\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏\n",
    "            collection_metadata = self.collection.metadata or {}\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
    "            sample = self.collection.peek() if count > 0 else {}\n",
    "            \n",
    "            return {\n",
    "                \"collection_name\": self.collection_name,\n",
    "                \"document_count\": count,\n",
    "                \"embedding_dimension\": self.embedding_model.get_embedding_dimension(),\n",
    "                \"db_path\": str(self.db_path),\n",
    "                \"metadata\": collection_metadata,\n",
    "                \"sample_size\": len(sample.get(\"documents\", [])),\n",
    "                \"model\": self.embedding_model.model_name\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def clear_collection(self) -> None:\n",
    "        \"\"\"–û—á–∏—â–∞–µ—Ç –∫–æ–ª–ª–µ–∫—Ü–∏—é.\"\"\"\n",
    "        try:\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ ID\n",
    "            all_data = self.collection.get()\n",
    "            if all_data['ids']:\n",
    "                self.delete_by_ids(all_data['ids'])\n",
    "            self.logger.info(f\"üßπ –ö–æ–ª–ª–µ–∫—Ü–∏—è '{self.collection_name}' –æ—á–∏—â–µ–Ω–∞\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a62d6a0-a74c-437f-b61d-86895248d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGPipeline:\n",
    "    \"\"\"\n",
    "    üöÄ –ü–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π RAG –ø–∞–π–ø–ª–∞–π–Ω —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:\n",
    "    - –í–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ ChromaDB (–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ ChromaStorage)\n",
    "    - LLM –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤\n",
    "    - RAGAS –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "    - –î–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 data_dir: str = None,\n",
    "                 db_path: str = None,\n",
    "                 config: Config = None,\n",
    "                 device: str = None,\n",
    "                 llm_generator: LLMGenerator = None):\n",
    "        \"\"\"\n",
    "        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞.\n",
    "        \n",
    "        Args:\n",
    "            data_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏\n",
    "            db_path: –ü—É—Ç—å –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ\n",
    "            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n",
    "            device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (cuda/cpu)\n",
    "            llm_generator: –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç–≤–µ—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "        \"\"\"\n",
    "        self.config = config or Config\n",
    "        self.data_dir = Path(data_dir or self.config.DEFAULT_DATA_DIR)\n",
    "        self.db_path = Path(db_path or self.config.DEFAULT_DB_DIR)\n",
    "        \n",
    "        # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ\n",
    "        if device:\n",
    "            self.config.DEVICE = device\n",
    "            self.config.USE_FP16 = True if device == \"cuda\" else False\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
    "        self.config.setup_directories()\n",
    "        JupyterConfig.setup_directories()\n",
    "        \n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã\n",
    "        self.data_loader = DataLoader(self.data_dir)\n",
    "        self.embedder = MultilingualE5Embedder(\n",
    "            device=self.config.DEVICE, \n",
    "            use_fp16=self.config.USE_FP16\n",
    "        )\n",
    "        \n",
    "        self.storage = None  \n",
    "        \n",
    "        self.llm_generator = llm_generator\n",
    "        \n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.setup_logging()\n",
    "        \n",
    "        self.logger.info(f\"üöÄ RAG Pipeline –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {self.config.DEVICE}\")\n",
    "    \n",
    "    def setup_logging(self):\n",
    "        \"\"\"–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ.\"\"\"\n",
    "        log_file = Path(self.config.DEFAULT_LOGS_DIR) / f\"rag_pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "        \n",
    "        # –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏\n",
    "        for handler in logging.root.handlers[:]:\n",
    "            logging.root.removeHandler(handler)\n",
    "        \n",
    "        logging.basicConfig(\n",
    "            level=getattr(logging, self.config.LOG_LEVEL),\n",
    "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(log_file, encoding='utf-8'),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    # ========== –ú–ï–¢–û–î–´ –†–ê–ë–û–¢–´ –° –î–ê–ù–ù–´–ú–ò ==========\n",
    "    \n",
    "    def load_and_process_data(self,\n",
    "                            file_pattern: str = \"*.txt\",\n",
    "                            max_files: int = None,\n",
    "                            save_intermediate: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ.\n",
    "        \n",
    "        Args:\n",
    "            file_pattern: –®–∞–±–ª–æ–Ω —Ñ–∞–π–ª–æ–≤\n",
    "            max_files: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤\n",
    "            save_intermediate: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "        \"\"\"\n",
    "        self.logger.info(\"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "        \n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "        df = self.data_loader.load_files_to_dataframe(\n",
    "            file_pattern=file_pattern,\n",
    "            max_files=max_files,\n",
    "            process_chunks=True\n",
    "        )\n",
    "        \n",
    "        if df.empty:\n",
    "            self.logger.error(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ\")\n",
    "            return df\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "        if save_intermediate:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_path = Path(JupyterConfig.RESULTS_DIR) / f\"processed_data_{timestamp}.parquet\"\n",
    "            self.data_loader.save_dataframe(df, output_path)\n",
    "            self.logger.info(f\"üíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_path}\")\n",
    "        \n",
    "        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö\n",
    "        display_df = df.head(JupyterConfig.DISPLAY_TABLE_ROWS).copy()\n",
    "        display_df['text_preview'] = display_df['text'].apply(\n",
    "            lambda x: x[:JupyterConfig.DISPLAY_MAX_CHARS] + '...' if len(x) > JupyterConfig.DISPLAY_MAX_CHARS else x\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —á–∞–Ω–∫–æ–≤ –∏–∑ {df['source_file'].nunique()} —Ñ–∞–π–ª–æ–≤\")\n",
    "        print(f\"üî§ –ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "        display(display_df[['id', 'source_file', 'chunk_index', 'total_chunks', 'text_preview']])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def initialize_storage(self, collection_name: str = None) -> ChromaStorage:\n",
    "        \"\"\"\n",
    "        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.\n",
    "        \n",
    "        Args:\n",
    "            collection_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏\n",
    "        \n",
    "        Returns:\n",
    "            –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ\n",
    "        \"\"\"\n",
    "        self.logger.info(\"üì¶ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞...\")\n",
    "        \n",
    "        # ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º ChromaStorage –∫–ª–∞—Å—Å –∏–∑ —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏\n",
    "        self.storage = ChromaStorage(\n",
    "            db_path=str(self.db_path),\n",
    "            collection_name=collection_name or self.config.COLLECTION_NAME,\n",
    "            embedding_model=self.embedder\n",
    "        )\n",
    "        \n",
    "        info = self.storage.get_collection_info()\n",
    "        self.logger.info(f\"‚úÖ –•—Ä–∞–Ω–∏–ª–∏—â–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {info}\")\n",
    "        \n",
    "        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏\n",
    "        html = f\"\"\"\n",
    "        <div style=\"border: 1px solid #ddd; border-radius: 8px; padding: 15px; margin: 10px 0; background-color: #f8f9fa;\">\n",
    "            <h3 style=\"color: #2196F3; margin-top: 0;\">üì¶ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ</h3>\n",
    "            <ul style=\"line-height: 1.6;\">\n",
    "                <li><strong>–ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏:</strong> {info['collection_name']}</li>\n",
    "                <li><strong>–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:</strong> {info['document_count']}</li>\n",
    "                <li><strong>–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:</strong> {info['embedding_dimension']}</li>\n",
    "                <li><strong>–ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:</strong> {info['model']}</li>\n",
    "                <li><strong>–ü—É—Ç—å –∫ –±–∞–∑–µ:</strong> {info['db_path']}</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(html))\n",
    "        \n",
    "        return self.storage\n",
    "    \n",
    "    def build_vector_store(self,\n",
    "                         df: pd.DataFrame,\n",
    "                         clear_existing: bool = False) -> List[str]:\n",
    "        \"\"\"\n",
    "        –°—Ç—Ä–æ–∏—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∏–∑ DataFrame.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏\n",
    "            clear_existing: –û—á–∏—Å—Ç–∏—Ç—å –ª–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é\n",
    "        \n",
    "        Returns:\n",
    "            –°–ø–∏—Å–æ–∫ ID –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
    "        \"\"\"\n",
    "        if self.storage is None:\n",
    "            self.initialize_storage()\n",
    "        \n",
    "        if df.empty:\n",
    "            self.logger.error(\"‚ùå DataFrame –ø—É—Å—Ç\")\n",
    "            return []\n",
    "        \n",
    "        # –û—á–∏—â–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "        if clear_existing:\n",
    "            self.logger.info(\"üßπ –û—á–∏—Å—Ç–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏...\")\n",
    "            self.storage.clear_collection()\n",
    "        \n",
    "        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "        texts = df[\"text\"].tolist()\n",
    "        ids = df[\"id\"].tolist()\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n",
    "        metadatas = []\n",
    "        for _, row in df.iterrows():\n",
    "            metadata = {k: v for k, v in row.items() if k not in [\"id\", \"text\"]}\n",
    "            metadata[\"id\"] = row[\"id\"]\n",
    "            metadatas.append(metadata)\n",
    "        \n",
    "        self.logger.info(f\"üöÄ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ {len(texts)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ...\")\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ\n",
    "        added_ids = self.storage.add_texts(\n",
    "            texts=texts,\n",
    "            metadatas=metadatas,\n",
    "            ids=ids,\n",
    "            batch_size=self.config.BATCH_SIZE\n",
    "        )\n",
    "        \n",
    "        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏\n",
    "        info = self.storage.get_collection_info()\n",
    "        self.logger.info(f\"‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–æ: {info}\")\n",
    "        \n",
    "        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
    "        html = f\"\"\"\n",
    "        <div style=\"border: 2px solid #4CAF50; border-radius: 8px; padding: 15px; margin: 10px 0; background-color: #e8f5e9;\">\n",
    "            <h3 style=\"color: #4CAF50; margin-top: 0;\">‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —É—Å–ø–µ—à–Ω–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–æ!</h3>\n",
    "            <ul style=\"line-height: 1.6;\">\n",
    "                <li><strong>–î–æ–±–∞–≤–ª–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:</strong> {len(added_ids)}</li>\n",
    "                <li><strong>–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏:</strong> {info['document_count']}</li>\n",
    "                <li><strong>–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤:</strong> {info['embedding_dimension']}</li>\n",
    "                <li><strong>–ú–æ–¥–µ–ª—å:</strong> {info['model']}</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(html))\n",
    "        \n",
    "        return added_ids\n",
    "    \n",
    "    # ========== –ú–ï–¢–û–î–´ –ü–û–ò–°–ö–ê ==========\n",
    "    \n",
    "    def search(self,\n",
    "              query: str,\n",
    "              top_k: int = None,\n",
    "              score_threshold: float = None,\n",
    "              return_df: bool = False) -> Union[List[SearchResult], pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.\n",
    "        \n",
    "        Args:\n",
    "            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å\n",
    "            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "            score_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞\n",
    "            return_df: –í–µ—Ä–Ω—É—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –≤–∏–¥–µ DataFrame\n",
    "        \n",
    "        Returns:\n",
    "            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –∫–∞–∫ —Å–ø–∏—Å–æ–∫ SearchResult –∏–ª–∏ DataFrame\n",
    "        \"\"\"\n",
    "        if self.storage is None:\n",
    "            self.logger.error(\"‚ùå –•—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ\")\n",
    "            return [] if not return_df else pd.DataFrame()\n",
    "        \n",
    "        top_k = top_k or self.config.DEFAULT_TOP_K\n",
    "        score_threshold = score_threshold or self.config.SIMILARITY_THRESHOLD\n",
    "        \n",
    "        self.logger.info(f\"üîç –ü–æ–∏—Å–∫ –∑–∞–ø—Ä–æ—Å–∞: '{query}'\")\n",
    "        \n",
    "        # ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ search –∏–∑ ChromaStorage\n",
    "        results = self.storage.search(\n",
    "            query=query,\n",
    "            top_k=top_k,\n",
    "            score_threshold=score_threshold\n",
    "        )\n",
    "        \n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "        if results:\n",
    "            self.logger.info(f\"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\")\n",
    "            for i, result in enumerate(results[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3\n",
    "                self.logger.info(f\"  {i+1}. Score: {result.similarity_score:.4f}, Source: {result.metadata.get('source_file', 'unknown')}\")\n",
    "        else:\n",
    "            self.logger.info(\"‚ö†Ô∏è –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")\n",
    "        \n",
    "        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ\n",
    "        if results:\n",
    "            self._display_search_results(query, results, score_threshold)\n",
    "        \n",
    "        if return_df:\n",
    "            return self.results_to_dataframe(results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _display_search_results(self, query: str, results: List[SearchResult], score_threshold: float):\n",
    "        \"\"\"–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.\"\"\"\n",
    "        html = f\"\"\"\n",
    "        <div style=\"border: 1px solid #2196F3; border-radius: 8px; padding: 15px; margin: 10px 0;\">\n",
    "            <h3 style=\"color: #2196F3; margin-top: 0;\">üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è: \"{query}\"</h3>\n",
    "            <p style=\"color: #666;\"><strong>–ù–∞–π–¥–µ–Ω–æ:</strong> {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ | <strong>–ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞:</strong> {score_threshold}</p>\n",
    "        \"\"\"\n",
    "        \n",
    "        for i, result in enumerate(results):\n",
    "            color = '#e8f5e9' if result.similarity_score > 0.8 else '#fff8e1' if result.similarity_score > 0.6 else '#ffebee'\n",
    "            border_color = '#4CAF50' if result.similarity_score > 0.8 else '#FFA726' if result.similarity_score > 0.6 else '#EF5350'\n",
    "            \n",
    "            html += f\"\"\"\n",
    "            <div style=\"border: 2px solid {border_color}; border-radius: 8px; padding: 15px; margin: 10px 0; background-color: {color};\">\n",
    "                <div style=\"display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;\">\n",
    "                    <strong style=\"font-size: 1.1em; color: #1a237e;\">–†–µ–∑—É–ª—å—Ç–∞—Ç #{i+1}</strong>\n",
    "                    <span style=\"background-color: {border_color}; color: white; padding: 3px 8px; border-radius: 12px; font-weight: bold;\">\n",
    "                        Score: {result.similarity_score:.4f}\n",
    "                    </span>\n",
    "                </div>\n",
    "                <div style=\"background-color: white; padding: 10px; border-radius: 5px; margin: 5px 0; border-left: 3px solid {border_color};\">\n",
    "                    {result.content[:300]}...\n",
    "                </div>\n",
    "                <div style=\"color: #666; font-size: 0.9em; margin-top: 8px;\">\n",
    "                    <strong>–ò—Å—Ç–æ—á–Ω–∏–∫:</strong> {result.metadata.get('source_file', 'unknown')} | \n",
    "                    <strong>–ß–∞–Ω–∫:</strong> {result.metadata.get('chunk_index', 'N/A')}/{result.metadata.get('total_chunks', 'N/A')}\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        html += \"</div>\"\n",
    "        display(HTML(html))\n",
    "    \n",
    "    def results_to_dataframe(self, results: List[SearchResult]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ DataFrame.\n",
    "        \n",
    "        Args:\n",
    "            results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏\n",
    "        \"\"\"\n",
    "        if not results:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        data = []\n",
    "        for result in results:\n",
    "            row = {\n",
    "                'id': result.id,\n",
    "                'content': result.content,\n",
    "                'similarity_score': result.similarity_score,\n",
    "                'source_file': result.metadata.get('source_file', ''),\n",
    "                'chunk_index': result.metadata.get('chunk_index', ''),\n",
    "                'total_chunks': result.metadata.get('total_chunks', ''),\n",
    "            }\n",
    "            data.append(row)\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    \n",
    "    # ========== LLM –ì–ï–ù–ï–†–ê–¶–ò–Ø ==========\n",
    "    \n",
    "    def set_llm_generator(self, llm_generator: LLMGenerator):\n",
    "        \"\"\"–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç LLM –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä.\"\"\"\n",
    "        self.llm_generator = llm_generator\n",
    "        self.logger.info(\"‚úÖ LLM –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "    \n",
    "    def query(self,\n",
    "             query: str,\n",
    "             top_k: int = None,\n",
    "             score_threshold: float = None,\n",
    "             return_details: bool = False,\n",
    "             display_result: bool = True) -> Union[str, Dict]:\n",
    "        \"\"\"\n",
    "        ‚ú® –ü–æ–ª–Ω—ã–π RAG –∑–∞–ø—Ä–æ—Å: –ø–æ–∏—Å–∫ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞.\n",
    "        \n",
    "        Args:\n",
    "            query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞\n",
    "            score_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞\n",
    "            return_details: –í–æ–∑–≤—Ä–∞—â–∞—Ç—å –¥–µ—Ç–∞–ª–∏ (–∫–æ–Ω—Ç–µ–∫—Å—Ç—ã, –∏—Å—Ç–æ—á–Ω–∏–∫–∏)\n",
    "            display_result: –û—Ç–æ–±—Ä–∞–∂–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ\n",
    "        \n",
    "        Returns:\n",
    "            –û—Ç–≤–µ—Ç –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å —Å –¥–µ—Ç–∞–ª—è–º–∏\n",
    "        \"\"\"\n",
    "        if self.llm_generator is None:\n",
    "            raise ValueError(\"‚ùå LLM –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ set_llm_generator()\")\n",
    "        \n",
    "        if self.storage is None:\n",
    "            raise ValueError(\"‚ùå –•—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ initialize_storage()\")\n",
    "        \n",
    "        top_k = top_k or self.config.DEFAULT_TOP_K\n",
    "        score_threshold = score_threshold or self.config.SIMILARITY_THRESHOLD\n",
    "        \n",
    "        self.logger.info(f\"üí¨ RAG –∑–∞–ø—Ä–æ—Å: '{query}'\")\n",
    "        \n",
    "        # 1. –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤\n",
    "        search_results = self.search(query, top_k=top_k, score_threshold=score_threshold)\n",
    "        \n",
    "        if not search_results:\n",
    "            answer = \"–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å.\"\n",
    "            if display_result:\n",
    "                self._display_query_result(query, answer, [], [], [])\n",
    "            if return_details:\n",
    "                return {\"answer\": answer, \"contexts\": [], \"sources\": [], \"scores\": []}\n",
    "            return answer\n",
    "        \n",
    "        # 2. –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã\n",
    "        contexts = [r.content for r in search_results]\n",
    "        sources = [r.metadata.get('source_file', 'unknown') for r in search_results]\n",
    "        scores = [r.similarity_score for r in search_results]\n",
    "        \n",
    "        # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞\n",
    "        self.logger.info(\"ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...\")\n",
    "        answer = self.llm_generator.generate_answer(query, contexts)\n",
    "        \n",
    "        # 4. –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "        if display_result:\n",
    "            self._display_query_result(query, answer, contexts, sources, scores)\n",
    "        \n",
    "        if return_details:\n",
    "            return {\n",
    "                \"answer\": answer,\n",
    "                \"contexts\": contexts,\n",
    "                \"sources\": sources,\n",
    "                \"scores\": scores,\n",
    "                \"search_results\": search_results\n",
    "            }\n",
    "        \n",
    "        return answer\n",
    "    \n",
    "    def _display_query_result(self, query: str, answer: str, contexts: List[str], \n",
    "                             sources: List[str], scores: List[float]):\n",
    "        \"\"\"–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç RAG –∑–∞–ø—Ä–æ—Å–∞ –≤ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.\"\"\"\n",
    "        html = f\"\"\"\n",
    "        <div style=\"border: 2px solid #673AB7; border-radius: 12px; padding: 20px; margin: 15px 0; background: linear-gradient(135deg, #f3e5f5 0%, #e1bee7 100%);\">\n",
    "            <h2 style=\"color: #4A148C; margin-top: 0;\">üí¨ RAG –û—Ç–≤–µ—Ç</h2>\n",
    "            \n",
    "            <div style=\"background: white; padding: 15px; border-radius: 8px; margin: 15px 0; border-left: 5px solid #673AB7;\">\n",
    "                <strong style=\"color: #666; display: block; margin-bottom: 8px;\">‚ùì –í–æ–ø—Ä–æ—Å:</strong>\n",
    "                <div style=\"color: #1a237e; font-size: 1.1em;\">{query}</div>\n",
    "            </div>\n",
    "            \n",
    "            <div style=\"background: #e8f5e9; padding: 15px; border-radius: 8px; margin: 15px 0; border-left: 5px solid #4CAF50;\">\n",
    "                <strong style=\"color: #666; display: block; margin-bottom: 8px;\">‚úÖ –û—Ç–≤–µ—Ç:</strong>\n",
    "                <div style=\"color: #1b5e20; line-height: 1.6;\">{answer}</div>\n",
    "            </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        if contexts:\n",
    "            html += f\"\"\"\n",
    "            <div style=\"margin-top: 20px;\">\n",
    "                <h3 style=\"color: #4A148C;\">üìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã ({len(contexts)}):</h3>\n",
    "            \"\"\"\n",
    "            \n",
    "            for i, (ctx, src, score) in enumerate(zip(contexts, sources, scores)):\n",
    "                color = '#4CAF50' if score > 0.8 else '#FFA726' if score > 0.6 else '#EF5350'\n",
    "                html += f\"\"\"\n",
    "                <div style=\"background: white; padding: 12px; margin: 8px 0; border-radius: 6px; border-left: 4px solid {color};\">\n",
    "                    <div style=\"display: flex; justify-content: space-between; margin-bottom: 5px;\">\n",
    "                        <strong style=\"color: #666;\">–ö–æ–Ω—Ç–µ–∫—Å—Ç #{i+1}</strong>\n",
    "                        <span style=\"background: {color}; color: white; padding: 2px 8px; border-radius: 10px; font-size: 0.9em;\">\n",
    "                            Score: {score:.4f}\n",
    "                        </span>\n",
    "                    </div>\n",
    "                    <div style=\"color: #333; font-size: 0.95em; margin: 8px 0;\">{ctx[:200]}...</div>\n",
    "                    <div style=\"color: #999; font-size: 0.85em;\">üìÑ –ò—Å—Ç–æ—á–Ω–∏–∫: {src}</div>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "            \n",
    "            html += \"</div>\"\n",
    "        \n",
    "        html += \"</div>\"\n",
    "        display(HTML(html))\n",
    "    \n",
    "    # ========== –û–¶–ï–ù–ö–ê –ö–ê–ß–ï–°–¢–í–ê ==========\n",
    "    \n",
    "    def evaluate_search(self,\n",
    "                       test_queries: List[str],\n",
    "                       expected_results: List[List[str]] = None,\n",
    "                       display_results: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞.\n",
    "        \n",
    "        Args:\n",
    "            test_queries: –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã\n",
    "            expected_results: –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "            display_results: –û—Ç–æ–±—Ä–∞–∂–∞—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ\n",
    "        \n",
    "        Returns:\n",
    "            –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"üß™ –û—Ü–µ–Ω–∫–∞ –ø–æ–∏—Å–∫–∞ –Ω–∞ {len(test_queries)} –∑–∞–ø—Ä–æ—Å–∞—Ö...\")\n",
    "        \n",
    "        metrics = {\n",
    "            \"total_queries\": len(test_queries),\n",
    "            \"results_per_query\": [],\n",
    "            \"avg_similarity_score\": [],\n",
    "            \"execution_times\": [],\n",
    "            \"successful_queries\": 0\n",
    "        }\n",
    "        \n",
    "        evaluation_results = []\n",
    "        \n",
    "        for query in tqdm(test_queries, desc=\"–û—Ü–µ–Ω–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤\"):\n",
    "            start_time = datetime.now()\n",
    "            try:\n",
    "                results = self.search(query, top_k=5, return_df=False)\n",
    "                execution_time = (datetime.now() - start_time).total_seconds()\n",
    "                \n",
    "                metrics[\"results_per_query\"].append(len(results))\n",
    "                metrics[\"execution_times\"].append(execution_time)\n",
    "                \n",
    "                if results:\n",
    "                    metrics[\"successful_queries\"] += 1\n",
    "                    avg_similarity = np.mean([r.similarity_score for r in results])\n",
    "                    metrics[\"avg_similarity_score\"].append(avg_similarity)\n",
    "                    \n",
    "                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\n",
    "                    eval_result = {\n",
    "                        'query': query,\n",
    "                        'results_count': len(results),\n",
    "                        'avg_similarity': avg_similarity,\n",
    "                        'execution_time': execution_time,\n",
    "                        'top_result': results[0].content[:100] + '...' if results else None\n",
    "                    }\n",
    "                    evaluation_results.append(eval_result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ '{query}': {e}\")\n",
    "                metrics[\"results_per_query\"].append(0)\n",
    "                metrics[\"execution_times\"].append(0)\n",
    "        \n",
    "        # –í—ã—á–∏—Å–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "        metrics[\"avg_results_per_query\"] = np.mean(metrics[\"results_per_query\"]) if metrics[\"results_per_query\"] else 0\n",
    "        metrics[\"avg_execution_time\"] = np.mean(metrics[\"execution_times\"]) if metrics[\"execution_times\"] else 0\n",
    "        metrics[\"success_rate\"] = metrics[\"successful_queries\"] / metrics[\"total_queries\"] if metrics[\"total_queries\"] > 0 else 0\n",
    "        \n",
    "        if metrics[\"avg_similarity_score\"]:\n",
    "            metrics[\"avg_similarity\"] = np.mean(metrics[\"avg_similarity_score\"])\n",
    "        \n",
    "        self.logger.info(f\"‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {metrics}\")\n",
    "        \n",
    "        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ\n",
    "        if display_results:\n",
    "            self.display_evaluation_metrics(metrics, evaluation_results)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def display_evaluation_metrics(self, metrics: Dict[str, Any], evaluation_results: List[Dict]):\n",
    "        \"\"\"–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –≤ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.\"\"\"\n",
    "        html = f\"\"\"\n",
    "        <div style=\"border: 2px solid #2196F3; border-radius: 8px; padding: 20px; margin: 15px 0; background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);\">\n",
    "            <h2 style=\"color: #1565C0; margin-top: 0; text-align: center;\">üìä –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –ø–æ–∏—Å–∫–∞</h2>\n",
    "            \n",
    "            <div style=\"display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 20px 0;\">\n",
    "        \"\"\"\n",
    "        \n",
    "        metric_items = [\n",
    "            ('–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤', metrics['total_queries'], '#1565C0'),\n",
    "            ('–£—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤', metrics['successful_queries'], '#4CAF50'),\n",
    "            ('–°–∫–æ—Ä–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞', f\"{metrics['success_rate']:.1%}\", '#FFA726'),\n",
    "            ('–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è', f\"{metrics['avg_execution_time']:.3f} —Å–µ–∫\", '#9C27B0'),\n",
    "            ('–†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –∑–∞–ø—Ä–æ—Å', f\"{metrics['avg_results_per_query']:.1f}\", '#009688'),\n",
    "            ('–°—Ä–µ–¥–Ω–µ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ', f\"{metrics.get('avg_similarity', 0):.4f}\", '#E91E63')\n",
    "        ]\n",
    "        \n",
    "        for title, value, color in metric_items:\n",
    "            html += f\"\"\"\n",
    "            <div style=\"text-align: center; padding: 15px; background: {color}15; border-radius: 8px; border: 1px solid {color}50;\">\n",
    "                <div style=\"font-size: 2.5em; color: {color}; margin-bottom: 8px;\">{value}</div>\n",
    "                <div style=\"font-weight: 500; color: #333;\">{title}</div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "            </div>\n",
    "            \n",
    "            <h3 style=\"color: #1565C0; margin-top: 25px;\">üìà –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º:</h3>\n",
    "            <div style=\"margin-top: 15px;\">\n",
    "        \"\"\"\n",
    "        \n",
    "        for i, result in enumerate(evaluation_results[:10]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10\n",
    "            success_color = '#4CAF50' if result['results_count'] > 0 else '#EF5350'\n",
    "            html += f\"\"\"\n",
    "            <div style=\"background: white; padding: 12px; margin: 8px 0; border-radius: 6px; border-left: 4px solid {success_color};\">\n",
    "                <div style=\"display: flex; justify-content: space-between;\">\n",
    "                    <strong style=\"color: #1a237e;\">–ó–∞–ø—Ä–æ—Å #{i+1}:</strong>\n",
    "                    <span style=\"color: {success_color}; font-weight: bold;\">{result['results_count']} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤</span>\n",
    "                </div>\n",
    "                <div style=\"color: #666; margin: 5px 0; font-style: italic;\">\"{result['query']}\"</div>\n",
    "                <div style=\"display: flex; justify-content: space-between; font-size: 0.9em; color: #666;\">\n",
    "                    <span>‚è∞ –í—Ä–µ–º—è: {result['execution_time']:.3f} —Å–µ–∫</span>\n",
    "                    <span>‚≠ê –°—Ö–æ–¥—Å—Ç–≤–æ: {result['avg_similarity']:.4f}</span>\n",
    "                </div>\n",
    "                <div style=\"color: #666; margin-top: 5px; font-size: 0.9em;\">\n",
    "                    <strong>–¢–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç:</strong> {result['top_result'] or '–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤'}\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        display(HTML(html))\n",
    "    \n",
    "    # ========== –≠–ö–°–ü–û–†–¢ –ò –°–û–•–†–ê–ù–ï–ù–ò–ï ==========\n",
    "    \n",
    "    def save_pipeline_state(self, filename: str = None):\n",
    "        \"\"\"\n",
    "        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞.\n",
    "        \n",
    "        Args:\n",
    "            filename: –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n",
    "        \"\"\"\n",
    "        if not filename:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"rag_pipeline_state_{timestamp}.pkl\"\n",
    "        \n",
    "        filepath = Path(JupyterConfig.RESULTS_DIR) / filename\n",
    "        \n",
    "        state = {\n",
    "            'config': asdict(self.config),\n",
    "            'data_dir': str(self.data_dir),\n",
    "            'db_path': str(self.db_path),\n",
    "            'collection_info': self.storage.get_collection_info() if self.storage else None,\n",
    "            'has_llm': self.llm_generator is not None,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(state, f)\n",
    "        \n",
    "        print(f\"üíæ –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath}\")\n",
    "        return filepath\n",
    "    \n",
    "    def export_results(self,\n",
    "                     results: List[SearchResult],\n",
    "                     output_format: str = \"json\",\n",
    "                     filename: str = None) -> str:\n",
    "        \"\"\"\n",
    "        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞.\n",
    "        \n",
    "        Args:\n",
    "            results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞\n",
    "            output_format: –§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞ (json/csv/html)\n",
    "            filename: –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n",
    "        \n",
    "        Returns:\n",
    "            –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É\n",
    "        \"\"\"\n",
    "        if not results:\n",
    "            self.logger.warning(\"‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞\")\n",
    "            return \"\"\n",
    "        \n",
    "        if not filename:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"search_results_{timestamp}\"\n",
    "        \n",
    "        filepath = Path(JupyterConfig.RESULTS_DIR) / filename\n",
    "        \n",
    "        if output_format == \"json\":\n",
    "            result_dicts = [r.to_dict() for r in results]\n",
    "            filepath = filepath.with_suffix('.json')\n",
    "            with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                json.dump(result_dicts, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ JSON: {filepath}\")\n",
    "            return str(filepath)\n",
    "            \n",
    "        elif output_format == \"csv\":\n",
    "            df = self.results_to_dataframe(results)\n",
    "            filepath = filepath.with_suffix('.csv')\n",
    "            df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "            print(f\"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV: {filepath}\")\n",
    "            return str(filepath)\n",
    "            \n",
    "        elif output_format == \"html\":\n",
    "            html_content = self.generate_html_report(results)\n",
    "            filepath = filepath.with_suffix('.html')\n",
    "            with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                f.write(html_content)\n",
    "            print(f\"üíæ HTML –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filepath}\")\n",
    "            return str(filepath)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {output_format}\")\n",
    "    \n",
    "    def generate_html_report(self, results: List[SearchResult]) -> str:\n",
    "        \"\"\"–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML –æ—Ç—á–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–∏—Å–∫–∞.\"\"\"\n",
    "        html = \"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <head>\n",
    "            <meta charset=\"utf-8\">\n",
    "            <title>RAG Search Results</title>\n",
    "            <style>\n",
    "                body { font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }\n",
    "                .container { max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 10px; box-shadow: 0 1px 3px rgba(0,0,0,0.12); }\n",
    "                .header { text-align: center; color: #1a237e; margin-bottom: 30px; }\n",
    "                .result { border: 1px solid #ddd; border-radius: 8px; padding: 15px; margin: 15px 0; background: #f8f9fa; }\n",
    "                .score { background: #4CAF50; color: white; padding: 3px 8px; border-radius: 12px; font-weight: bold; float: right; }\n",
    "                .content { background: white; padding: 10px; margin: 10px 0; border-left: 3px solid #2196F3; }\n",
    "                .metadata { color: #666; font-size: 0.9em; margin-top: 8px; }\n",
    "                .source { color: #1565C0; font-weight: bold; }\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <div class=\"container\">\n",
    "                <div class=\"header\">\n",
    "                    <h1>üîç RAG Search Results</h1>\n",
    "                    <p>Generated on \"\"\" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \"\"\"</p>\n",
    "                </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        for i, result in enumerate(results):\n",
    "            html += f\"\"\"\n",
    "                <div class=\"result\">\n",
    "                    <div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "                        <h3>Result #{i+1}</h3>\n",
    "                        <span class=\"score\">Score: {result.similarity_score:.4f}</span>\n",
    "                    </div>\n",
    "                    <div class=\"content\">\n",
    "                        {result.content.replace('\\n', '<br>')}\n",
    "                    </div>\n",
    "                    <div class=\"metadata\">\n",
    "                        <span class=\"source\">Source: {result.metadata.get('source_file', 'unknown')}</span> | \n",
    "                        Chunk: {result.metadata.get('chunk_index', 'N/A')}/{result.metadata.get('total_chunks', 'N/A')} |\n",
    "                        ID: {result.id[:12]}...\n",
    "                    </div>\n",
    "                </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "            </div>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccca3887-c4e5-4baa-b7dd-dcd67e489f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device_info():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ.\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    return {\n",
    "        \"device\": device,\n",
    "        \"gpu_available\": torch.cuda.is_available(),\n",
    "        \"gpu_name\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,\n",
    "        \"gpu_memory\": torch.cuda.get_device_properties(0).total_memory / 1e9 if torch.cuda.is_available() else 0,\n",
    "        \"cuda_version\": torch.version.cuda if torch.cuda.is_available() else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68347a61-d8e6-4b51-b09e-0a0903f31702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_rag_pipeline(\n",
    "    data_dir: str = \"data/chunks\",\n",
    "    db_path: str = \"vector_db\",\n",
    "    device: str = None,\n",
    "    setup_llm: bool = True,\n",
    "    max_files: int = 1000,\n",
    "    build_store: bool = False,\n",
    "    reset_db: bool = False\n",
    ") -> RAGPipeline:\n",
    "    \"\"\"\n",
    "    –ü–æ–ª–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG –ø–∞–π–ø–ª–∞–π–Ω–∞.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏\n",
    "        db_path: –ü—É—Ç—å –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ\n",
    "        device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (auto –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)\n",
    "        setup_llm: –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ª–∏ LLM –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä\n",
    "        max_files: –ú–∞–∫—Å–∏–º—É–º —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏\n",
    "        reset_db: –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö (—Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω–æ–π –ë–î)\n",
    "    \n",
    "    Returns:\n",
    "        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π RAG –ø–∞–π–ø–ª–∞–π–Ω\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "        if device is None:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        print(f\"üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG –ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {device}\")\n",
    "        \n",
    "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ\n",
    "        device_info = get_device_info()\n",
    "        print(f\"\\n‚ÑπÔ∏è  –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ:\")\n",
    "        print(f\"   ‚Ä¢ –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device_info['device']}\")\n",
    "        if device_info['gpu_available']:\n",
    "            print(f\"   ‚Ä¢ GPU: {device_info['gpu_name']}\")\n",
    "            print(f\"   ‚Ä¢ –ü–∞–º—è—Ç—å GPU: {device_info['gpu_memory']:.2f} GB\")\n",
    "            print(f\"   ‚Ä¢ CUDA –≤–µ—Ä—Å–∏—è: {device_info['cuda_version']}\")\n",
    "        \n",
    "        # ‚úÖ –ï—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è - —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –±–∞–∑—É\n",
    "        if reset_db:\n",
    "            db_path_obj = Path(db_path)\n",
    "            if db_path_obj.exists():\n",
    "                print(f\"\\nüóëÔ∏è –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {db_path}\")\n",
    "                shutil.rmtree(db_path_obj)\n",
    "                print(\"‚úÖ –°—Ç–∞—Ä–∞—è –±–∞–∑–∞ —É–¥–∞–ª–µ–Ω–∞\")\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω\n",
    "        pipeline = RAGPipeline(\n",
    "            data_dir=data_dir,\n",
    "            db_path=db_path,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º LLM –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä\n",
    "        if setup_llm:\n",
    "            print(\"\\nü§ñ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LLM –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞...\")\n",
    "            generation_client = UniversalLLMClient(\n",
    "                model=Config.GENERATION_MODEL,\n",
    "                api_key=Config.LLM_API_KEY,\n",
    "                api_base=Config.LLM_API_BASE,\n",
    "                temperature=Config.GENERATION_TEMPERATURE,\n",
    "                max_tokens=Config.GENERATION_MAX_TOKENS\n",
    "            )\n",
    "            llm_generator = LLMGenerator(llm_client=generation_client)\n",
    "            pipeline.set_llm_generator(llm_generator)\n",
    "        \n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "        print(\"\\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "        df = pipeline.load_and_process_data(\n",
    "            file_pattern=\"*.txt\",\n",
    "            max_files=max_files,\n",
    "            save_intermediate=True\n",
    "        )\n",
    "        \n",
    "        if not df.empty:\n",
    "            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ\n",
    "            print(\"\\nüì¶ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞...\")\n",
    "            pipeline.initialize_storage()\n",
    "\n",
    "            if build_store:\n",
    "                # –°—Ç—Ä–æ–∏–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ\n",
    "                print(\"\\nüöÄ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞...\")\n",
    "                pipeline.build_vector_store(df, clear_existing=True)\n",
    "            \n",
    "            print(\"\\n‚úÖ –ü–∞–π–ø–ª–∞–π–Ω —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!\")\n",
    "            print(\"\\nüìù –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Ç–æ–¥—ã:\")\n",
    "            print(\"   ‚Ä¢ pipeline.search(query) - –ø–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ\")\n",
    "            print(\"   ‚Ä¢ pipeline.query(query) - –ø–æ–ª–Ω—ã–π RAG –∑–∞–ø—Ä–æ—Å —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –æ—Ç–≤–µ—Ç–∞\")\n",
    "            print(\"   ‚Ä¢ pipeline.evaluate_search(queries) - –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞\")\n",
    "            \n",
    "            return pipeline\n",
    "        else:\n",
    "            print(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3feb3-d126-4068-bee8-bc5a298190b1",
   "metadata": {},
   "source": [
    "## –ü—Ä–æ—Ö–æ–¥ –ø–æ –∫–æ–Ω–≤–µ–π–µ—Ä—É"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70dc64-bddd-4af1-b623-1dc2fd91aa9d",
   "metadata": {},
   "source": [
    "### –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb206196-89ad-403e-bbf8-043d32c62114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c02090-2917-4435-aee8-8cc6ce09107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = initialize_rag_pipeline(\n",
    "    data_dir=\"data/chunks\",\n",
    "    db_path=\"vector_db\",\n",
    "    setup_llm=True,\n",
    "    max_files=1000,\n",
    "    # build_store=True,\n",
    "    # reset_db=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1db849a-d412-41a6-80be-5d3e3d6f044b",
   "metadata": {},
   "source": [
    "### –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cde634d2-0654-4de8-b653-0a441e031058",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"Tell me all about I101 and its relations in Attempto Controlled English\",\n",
    "        \"ground_truth\": \"\"\"i101 is a length_measure_with_unit. It represents a measurement involving \n",
    "        a length and a unit. i101 has two key components: i101_value_component (the numerical value) \n",
    "        and i17 (the unit component). i101 also serves as a conversion factor for i103.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is i103 and how does it relate to i101?\",\n",
    "        \"ground_truth\": \"\"\"i103 is a conversion_based_unit that uses i101 as its conversion factor. \n",
    "        This means i101 provides the necessary factor for converting between i103 and other units.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Explain the relationship between i101, i17, and i101_value_component\",\n",
    "        \"ground_truth\": \"\"\"i101 is a length_measure_with_unit that consists of two parts: \n",
    "        i17 (unit component) and i101_value_component (value component). The measure i101 \n",
    "        combines these two to represent a complete length measurement.\"\"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cd5f378-88f7-4064-bcf5-edf2718e2e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tell me all about I101 and its relations in Attempto Controlled English',\n",
       " 'What is i103 and how does it relate to i101?',\n",
       " 'Explain the relationship between i101, i17, and i101_value_component']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_queries = [test_cases[0]['query'], test_cases[1]['query'], test_cases[2]['query']]\n",
    "test_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e03d8e-23ed-4812-969a-e8a522d00661",
   "metadata": {},
   "source": [
    "### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ —á–µ—Ä–µ–∑ RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71b07587-8c30-452b-a5cd-9ded36fa1a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me all about I101 and its relations in Attempto Controlled English\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a742b5-44e7-435f-b4aa-8bb70436b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pipeline:\n",
    "    # 1. –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫\n",
    "    results = pipeline.search(question, \n",
    "                              top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690ccb4-b67d-4d09-bf4b-34b7161712b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. –ü–æ–ª–Ω—ã–π RAG –∑–∞–ø—Ä–æ—Å\n",
    "answer = pipeline.query(question, display_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3875bf-6261-4bba-9cfa-6bb9b03d783f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "metrics = pipeline.evaluate_search(test_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad395fb2-f94b-46c2-aa24-a7794e3e1542",
   "metadata": {},
   "source": [
    "## –ú–µ—Ç—Ä–∏–∫–∏ RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e76fb7b0-1aa5-4349-a2aa-68807f6ae89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rag_evaluation_dataset(\n",
    "    pipeline,  # RAGPipeline\n",
    "    test_cases: List[Dict[str, str]],\n",
    "    top_k: int = 5\n",
    ") -> Tuple[List[str], List[str], List[List[str]], List[str]]:\n",
    "    \"\"\"\n",
    "    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ RAGAS, –ø–æ–ª—É—á–∞—è –æ—Ç–≤–µ—Ç—ã –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã –æ—Ç RAG —Å–∏—Å—Ç–µ–º—ã.\n",
    "    \n",
    "    Args:\n",
    "        pipeline: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π RAG –ø–∞–π–ø–ª–∞–π–Ω\n",
    "        test_cases: –°–ø–∏—Å–æ–∫ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤ —Å query –∏ ground_truth\n",
    "        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è\n",
    "    \n",
    "    Returns:\n",
    "        –ö–æ—Ä—Ç–µ–∂ (queries, answers, contexts_list, ground_truths)\n",
    "    \"\"\"\n",
    "    queries = []\n",
    "    answers = []\n",
    "    contexts_list = []\n",
    "    ground_truths = []\n",
    "    \n",
    "    print(f\"üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è {len(test_cases)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤...\")\n",
    "    \n",
    "    for test_case in tqdm(test_cases, desc=\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤\"):\n",
    "        query = test_case[\"query\"]\n",
    "        ground_truth = test_case.get(\"ground_truth\", \"\")\n",
    "        \n",
    "        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã –æ—Ç RAG —Å–∏—Å—Ç–µ–º—ã\n",
    "        try:\n",
    "            result = pipeline.query(\n",
    "                query=query,\n",
    "                top_k=top_k,\n",
    "                return_details=True,\n",
    "                display_result=False  # –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "            )\n",
    "            \n",
    "            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "            queries.append(query)\n",
    "            answers.append(result[\"answer\"])\n",
    "            contexts_list.append(result[\"contexts\"])\n",
    "            ground_truths.append(ground_truth)\n",
    "            \n",
    "            print(f\"‚úÖ –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {query[:50]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ '{query[:50]}...': {e}\")\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, —á—Ç–æ–±—ã –Ω–µ –Ω–∞—Ä—É—à–∏—Ç—å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é\n",
    "            queries.append(query)\n",
    "            answers.append(\"\")\n",
    "            contexts_list.append([])\n",
    "            ground_truths.append(ground_truth)\n",
    "    \n",
    "    print(f\"\\n‚úÖ –î–∞—Ç–∞—Å–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω:\")\n",
    "    print(f\"   ‚Ä¢ –ó–∞–ø—Ä–æ—Å–æ–≤: {len(queries)}\")\n",
    "    print(f\"   ‚Ä¢ –° –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞–º–∏: {sum(1 for c in contexts_list if c)}\")\n",
    "    print(f\"   ‚Ä¢ –° ground truth: {sum(1 for gt in ground_truths if gt)}\")\n",
    "    \n",
    "    return queries, answers, contexts_list, ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4f1366e-ebc5-4f05-a489-4d240095c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rag_with_ragas(\n",
    "    pipeline,  # RAGPipeline\n",
    "    test_cases: List[Dict[str, str]],\n",
    "    judge_model: str = \"openai/gpt-5-mini\",\n",
    "    judge_api_key: str = None,\n",
    "    judge_api_base: str = \"https://api.vsegpt.ru/v1\",\n",
    "    embedding_model: str = \"emb-openai/text-embedding-3-large\",\n",
    "    top_k: int = 5,\n",
    "    metrics: List[str] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    –ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ RAG —Å–∏—Å—Ç–µ–º—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAGAS 0.4+.\n",
    "    \n",
    "    Args:\n",
    "        pipeline: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π RAG –ø–∞–π–ø–ª–∞–π–Ω\n",
    "        test_cases: –¢–µ—Å—Ç–æ–≤—ã–µ –∫–µ–π—Å—ã\n",
    "        judge_model: –ú–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ (–±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞)\n",
    "        judge_api_key: API –∫–ª—é—á –¥–ª—è Judge LLM\n",
    "        judge_api_base: Base URL –¥–ª—è Judge LLM API\n",
    "        embedding_model: –ú–æ–¥–µ–ª—å embeddings\n",
    "        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤\n",
    "        metrics: –°–ø–∏—Å–æ–∫ –º–µ—Ç—Ä–∏–∫ (None = –±–∞–∑–æ–≤—ã–µ)\n",
    "    \n",
    "    Returns:\n",
    "        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏\n",
    "    \"\"\"\n",
    "    if not RAGAS_AVAILABLE:\n",
    "        raise ImportError(\"RAGAS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install ragas --upgrade\")\n",
    "    \n",
    "    # 1. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç (–ø–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç—ã –æ—Ç RAG)\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üìä –®–ê–ì 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\")\n",
    "    print(\"=\" * 80)\n",
    "    queries, answers, contexts_list, ground_truths = prepare_rag_evaluation_dataset(\n",
    "        pipeline, test_cases, top_k\n",
    "    )\n",
    "    \n",
    "    # 2. –°–æ–∑–¥–∞–µ–º –æ—Ü–µ–Ω—â–∏–∫–∞ (Judge LLM)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ü§ñ –®–ê–ì 2: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Judge LLM –¥–ª—è –æ—Ü–µ–Ω–∫–∏\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω API –∫–ª—é—á, –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "    if judge_api_key is None:\n",
    "        judge_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not judge_api_key:\n",
    "            raise ValueError(\"–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å judge_api_key –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å OPENAI_API_KEY\")\n",
    "    \n",
    "    evaluation_client = UniversalLLMClient(\n",
    "        model=judge_model,\n",
    "        api_key=judge_api_key,\n",
    "        api_base=judge_api_base,\n",
    "        temperature=0.0,  # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏\n",
    "        max_tokens=32000\n",
    "    )\n",
    "    \n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "    if metrics is None:\n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ ground truth\n",
    "        has_ground_truth = any(gt and gt.strip() for gt in ground_truths)\n",
    "        \n",
    "        if has_ground_truth:\n",
    "            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "            metrics = [\n",
    "                \"faithfulness\",\n",
    "                \"answer_relevancy\",\n",
    "                \"context_precision\",\n",
    "                \"context_recall\",\n",
    "                \"context_relevance\",\n",
    "                \"response_groundedness\",\n",
    "                \"answer_accuracy\"\n",
    "            ]\n",
    "        else:\n",
    "            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–±–µ–∑ ground truth)\n",
    "            metrics = [\n",
    "                \"faithfulness\",\n",
    "                \"context_relevance\",\n",
    "                \"response_groundedness\"\n",
    "            ]\n",
    "    \n",
    "    evaluator = UniversalRAGEvaluator(\n",
    "        judge_llm_client=evaluation_client,\n",
    "        embedding_model=embedding_model,\n",
    "        metrics=metrics\n",
    "    )\n",
    "    \n",
    "    # 3. –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üöÄ –®–ê–ì 3: –ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ RAGAS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"‚öôÔ∏è  –ú–µ—Ç—Ä–∏–∫–∏: {', '.join(metrics)}\")\n",
    "    print(f\"‚è∞ –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç (LLM –≤—ã–∑–æ–≤—ã –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–∏)...\\n\")\n",
    "    \n",
    "    # –í—ã–ø–æ–ª–Ω—è–µ–º –æ—Ü–µ–Ω–∫—É\n",
    "    results = evaluator.evaluate(\n",
    "        queries=queries,\n",
    "        answers=answers,\n",
    "        contexts=contexts_list,\n",
    "        ground_truths=ground_truths,\n",
    "        show_progress=True\n",
    "    )\n",
    "    \n",
    "    # 4. –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìä –®–ê–ì 4: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    evaluator.display_results(max_examples=len(test_cases))\n",
    "    \n",
    "    # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üíæ –®–ê–ì 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    results_path = evaluator.save_results()\n",
    "    print(f\"‚úÖ –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_path}\")\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∞–∫–∂–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    metrics_path = Path(\"results\") / f\"ragas_metrics_{timestamp}.json\"\n",
    "    metrics_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(metrics_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"‚úÖ –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metrics_path}\")\n",
    "    \n",
    "    return {\n",
    "        \"aggregated_metrics\": results,\n",
    "        \"detailed_results\": evaluator.get_detailed_results(),\n",
    "        \"evaluator\": evaluator\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ac839b2-fc8a-4715-b58c-5eef64f3385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"Tell me all about I101 and its relations in Attempto Controlled English\",\n",
    "        \"ground_truth\": \"\"\"Okay, let's break down the information about i101 and its relationships as expressed in Attempto Controlled English (ACE) using the provided axioms.\n",
    "\n",
    "Here's a description, presented in a structured way:\n",
    "\n",
    "1. What is i101?\n",
    "According to the axioms, i101 is a length_measure_with_unit. This means i101 represents a measurement involving a length and a unit.\n",
    "\n",
    "2. Components of i101:\n",
    "i101 has two key components:\n",
    "- Value Component: i101_value_component is a length_measure\n",
    "- Unit Component: i17 is the unit associated with i101\n",
    "\n",
    "3. i101's Role in Unit Conversion:\n",
    "i101 serves as a conversion factor for conversion_based_unit i103.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the relationship between i101 and i103?\",\n",
    "        \"ground_truth\": \"i101 serves as a conversion factor for i103, where i103 is a conversion_based_unit.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What type of measurement is i101?\",\n",
    "        \"ground_truth\": \"i101 is a length_measure_with_unit, which means it represents a length measurement with an associated unit.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is i101_value_component?\",\n",
    "        \"ground_truth\": \"i101_value_component is a length_measure that represents the numerical value component of the i101 measurement.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What unit is associated with i101?\",\n",
    "        \"ground_truth\": \"The unit i17 is associated with i101 through the measure_with_unit_has_unit_component relationship.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9471f6-2fa3-4a96-a592-077d7214d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = evaluate_rag_with_ragas(\n",
    "    pipeline=pipeline,\n",
    "    test_cases=test_cases,\n",
    "    judge_model=\"openai/gpt-5-mini\",\n",
    "    judge_api_key=\"sk-or-vv-xxx\",\n",
    "    judge_api_base=\"https://api.vsegpt.ru/v1\",\n",
    "    embedding_model=\"emb-openai/text-embedding-3-large\",\n",
    "    top_k=5,\n",
    "    metrics=None  # None = –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ ground truth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1228d750-c71b-492d-a6b8-456e1a5be7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã –≤:\n",
    "# - evaluation_results[\"aggregated_metrics\"] - –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "# - evaluation_results[\"detailed_results\"] - –¥–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞\n",
    "# - evaluation_results[\"evaluator\"] - –æ–±—ä–µ–∫—Ç evaluator –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf53146c-82f8-4116-a012-868ba728a467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ä¢ faithfulness_mean: 1.0000\n",
      "  ‚Ä¢ faithfulness_std: 0.0000\n",
      "  ‚Ä¢ faithfulness_min: 1.0000\n",
      "  ‚Ä¢ faithfulness_max: 1.0000\n",
      "  ‚Ä¢ faithfulness_count: 5.0000\n",
      "  ‚Ä¢ answer_relevancy_mean: 0.4306\n",
      "  ‚Ä¢ answer_relevancy_std: 0.3782\n",
      "  ‚Ä¢ answer_relevancy_min: 0.0000\n",
      "  ‚Ä¢ answer_relevancy_max: 0.9426\n",
      "  ‚Ä¢ answer_relevancy_count: 5.0000\n",
      "  ‚Ä¢ context_precision_mean: 0.1000\n",
      "  ‚Ä¢ context_precision_std: 0.1225\n",
      "  ‚Ä¢ context_precision_min: 0.0000\n",
      "  ‚Ä¢ context_precision_max: 0.2500\n",
      "  ‚Ä¢ context_precision_count: 5.0000\n",
      "  ‚Ä¢ context_recall_mean: 0.2500\n",
      "  ‚Ä¢ context_recall_std: 0.2500\n",
      "  ‚Ä¢ context_recall_min: 0.0000\n",
      "  ‚Ä¢ context_recall_max: 0.5000\n",
      "  ‚Ä¢ context_recall_count: 4.0000\n",
      "  ‚Ä¢ context_relevance_mean: 0.6000\n",
      "  ‚Ä¢ context_relevance_std: 0.4062\n",
      "  ‚Ä¢ context_relevance_min: 0.0000\n",
      "  ‚Ä¢ context_relevance_max: 1.0000\n",
      "  ‚Ä¢ context_relevance_count: 5.0000\n",
      "  ‚Ä¢ response_groundedness_mean: 1.0000\n",
      "  ‚Ä¢ response_groundedness_std: 0.0000\n",
      "  ‚Ä¢ response_groundedness_min: 1.0000\n",
      "  ‚Ä¢ response_groundedness_max: 1.0000\n",
      "  ‚Ä¢ response_groundedness_count: 5.0000\n",
      "  ‚Ä¢ answer_accuracy_mean: 0.4000\n",
      "  ‚Ä¢ answer_accuracy_std: 0.3391\n",
      "  ‚Ä¢ answer_accuracy_min: 0.0000\n",
      "  ‚Ä¢ answer_accuracy_max: 0.7500\n",
      "  ‚Ä¢ answer_accuracy_count: 5.0000\n",
      "  ‚Ä¢ overall_mean: 0.5401\n"
     ]
    }
   ],
   "source": [
    "for metric, value in evaluation_results[\"aggregated_metrics\"].items():\n",
    "    print(f\"  ‚Ä¢ {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "194a0cf5-28f1-494f-b385-c9c9c9374cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness_mean': 1.0,\n",
       " 'faithfulness_std': 0.0,\n",
       " 'faithfulness_min': 1.0,\n",
       " 'faithfulness_max': 1.0,\n",
       " 'faithfulness_count': 5,\n",
       " 'answer_relevancy_mean': 0.43056041541699397,\n",
       " 'answer_relevancy_std': 0.3781564037159313,\n",
       " 'answer_relevancy_min': 0.0,\n",
       " 'answer_relevancy_max': 0.9426166505197333,\n",
       " 'answer_relevancy_count': 5,\n",
       " 'context_precision_mean': 0.09999999999,\n",
       " 'context_precision_std': 0.12247448712691146,\n",
       " 'context_precision_min': 0.0,\n",
       " 'context_precision_max': 0.249999999975,\n",
       " 'context_precision_count': 5,\n",
       " 'context_recall_mean': 0.25,\n",
       " 'context_recall_std': 0.25,\n",
       " 'context_recall_min': 0.0,\n",
       " 'context_recall_max': 0.5,\n",
       " 'context_recall_count': 4,\n",
       " 'context_relevance_mean': 0.6,\n",
       " 'context_relevance_std': 0.406201920231798,\n",
       " 'context_relevance_min': 0.0,\n",
       " 'context_relevance_max': 1.0,\n",
       " 'context_relevance_count': 5,\n",
       " 'response_groundedness_mean': 1.0,\n",
       " 'response_groundedness_std': 0.0,\n",
       " 'response_groundedness_min': 1.0,\n",
       " 'response_groundedness_max': 1.0,\n",
       " 'response_groundedness_count': 5,\n",
       " 'answer_accuracy_mean': 0.4,\n",
       " 'answer_accuracy_std': 0.33911649915626346,\n",
       " 'answer_accuracy_min': 0.0,\n",
       " 'answer_accuracy_max': 0.75,\n",
       " 'answer_accuracy_count': 5,\n",
       " 'overall_mean': 0.5400800593438563}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[\"aggregated_metrics\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb77111-6c3e-4374-8eb8-49c8b1df7533",
   "metadata": {},
   "source": [
    "## –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –æ—Ü–µ–Ω–∫—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d8074015-7cea-4781-9aed-1397934ed9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rag_evaluation_dataset(\n",
    "    pipeline,  \n",
    "    test_cases: List[Dict[str, str]],\n",
    "    top_k: int = 5,\n",
    "    save_path: Optional[str] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ RAGAS.\n",
    "    \n",
    "    Args:\n",
    "        pipeline: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π RAG –ø–∞–π–ø–ª–∞–π–Ω\n",
    "        test_cases: –°–ø–∏—Å–æ–∫ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤ —Å query –∏ ground_truth\n",
    "        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è\n",
    "        save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ (optional)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    print(f\"üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è {len(test_cases)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤...\")\n",
    "    \n",
    "    for idx, test_case in enumerate(tqdm(test_cases, desc=\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤\")):\n",
    "        query = test_case[\"query\"]\n",
    "        ground_truth = test_case.get(\"ground_truth\", \"\")\n",
    "        metadata = test_case.get(\"metadata\", {})\n",
    "        \n",
    "        try:\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã –æ—Ç RAG —Å–∏—Å—Ç–µ–º—ã\n",
    "            result = pipeline.query(\n",
    "                query=query,\n",
    "                top_k=top_k,\n",
    "                return_details=True,\n",
    "                display_result=False\n",
    "            )\n",
    "            \n",
    "            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø–∏—Å—å\n",
    "            row = {\n",
    "                'idx': idx,\n",
    "                'query': query,\n",
    "                'answer': result[\"answer\"],\n",
    "                'contexts': '|||'.join(result[\"contexts\"]),  # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã\n",
    "                'ground_truth': ground_truth,\n",
    "                'num_contexts': len(result[\"contexts\"]),\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "            }\n",
    "            \n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n",
    "            row.update(metadata)\n",
    "            \n",
    "            data.append(row)\n",
    "            \n",
    "            print(f\"‚úÖ [{idx+1}/{len(test_cases)}] –û–±—Ä–∞–±–æ—Ç–∞–Ω: {query[:50]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ '{query[:50]}...': {e}\")\n",
    "            \n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é –∑–∞–ø–∏—Å—å\n",
    "            data.append({\n",
    "                'idx': idx,\n",
    "                'query': query,\n",
    "                'answer': \"\",\n",
    "                'contexts': \"\",\n",
    "                'ground_truth': ground_truth,\n",
    "                'num_contexts': 0,\n",
    "                'error': str(e),\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "            })\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å\n",
    "    if save_path:\n",
    "        save_path = Path(save_path)\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Parquet (—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö)\n",
    "        if save_path.suffix == '.parquet':\n",
    "            df.to_parquet(save_path, index=False, compression='gzip')\n",
    "        # –ò–ª–∏ –≤ CSV\n",
    "        elif save_path.suffix == '.csv':\n",
    "            df.to_csv(save_path, index=False, encoding='utf-8')\n",
    "        # JSON\n",
    "        elif save_path.suffix == '.json':\n",
    "            df.to_json(save_path, orient='records', lines=True, force_ascii=False)\n",
    "        else:\n",
    "            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é Parquet\n",
    "            save_path = save_path.with_suffix('.parquet')\n",
    "            df.to_parquet(save_path, index=False, compression='gzip')\n",
    "        \n",
    "        print(f\"\\nüíæ –î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}\")\n",
    "        print(f\"   –§–æ—Ä–º–∞—Ç: {save_path.suffix}\")\n",
    "        print(f\"   –†–∞–∑–º–µ—Ä: {save_path.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ –î–∞—Ç–∞—Å–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω:\")\n",
    "    print(f\"   ‚Ä¢ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}\")\n",
    "    print(f\"   ‚Ä¢ –£—Å–ø–µ—à–Ω—ã—Ö: {df['answer'].notna().sum()}\")\n",
    "    print(f\"   ‚Ä¢ –° ground truth: {df['ground_truth'].notna().sum()}\")\n",
    "    print(f\"   ‚Ä¢ –° –æ—à–∏–±–∫–∞–º–∏: {df.get('error', pd.Series()).notna().sum()}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "493c3a03-5980-42f6-a60b-df19963efd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_evaluation_dataset(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞.\n",
    "    \n",
    "    Args:\n",
    "        filepath: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏\n",
    "    \"\"\"\n",
    "    filepath = Path(filepath)\n",
    "    \n",
    "    if not filepath.exists():\n",
    "        raise FileNotFoundError(f\"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}\")\n",
    "    \n",
    "    print(f\"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: {filepath}\")\n",
    "    \n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º\n",
    "    if filepath.suffix == '.parquet':\n",
    "        df = pd.read_parquet(filepath)\n",
    "    elif filepath.suffix == '.csv':\n",
    "        df = pd.read_csv(filepath, encoding='utf-8')\n",
    "    elif filepath.suffix == '.json':\n",
    "        df = pd.read_json(filepath, orient='records', lines=True)\n",
    "    else:\n",
    "        raise ValueError(f\"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {filepath.suffix}\")\n",
    "    \n",
    "    print(f\"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω:\")\n",
    "    print(f\"   ‚Ä¢ –ó–∞–ø–∏—Å–µ–π: {len(df)}\")\n",
    "    print(f\"   ‚Ä¢ –ö–æ–ª–æ–Ω–æ–∫: {len(df.columns)}\")\n",
    "    print(f\"   ‚Ä¢ –†–∞–∑–º–µ—Ä: {filepath.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c91e3668-d9a9-4e1e-981f-c62503174e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_ragas_format(df: pd.DataFrame) -> Tuple[List[str], List[str], List[List[str]], List[str]]:\n",
    "    \"\"\"\n",
    "    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç DataFrame –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è RAGAS –æ—Ü–µ–Ω–∫–∏.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏\n",
    "    \n",
    "    Returns:\n",
    "        –ö–æ—Ä—Ç–µ–∂ (queries, answers, contexts_list, ground_truths)\n",
    "    \"\"\"\n",
    "    queries = df['query'].tolist()\n",
    "    answers = df['answer'].tolist()\n",
    "    \n",
    "    # –†–∞–∑–¥–µ–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã\n",
    "    contexts_list = []\n",
    "    for contexts_str in df['contexts']:\n",
    "        if pd.notna(contexts_str) and contexts_str:\n",
    "            contexts = contexts_str.split('|||')\n",
    "            contexts_list.append(contexts)\n",
    "        else:\n",
    "            contexts_list.append([])\n",
    "    \n",
    "    ground_truths = df['ground_truth'].fillna(\"\").tolist()\n",
    "    \n",
    "    return queries, answers, contexts_list, ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9bfb072c-1413-4d72-aebf-22139a487b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rag_with_ragas(\n",
    "    dataset: Optional[Union[pd.DataFrame, str]] = None,\n",
    "    pipeline = None,\n",
    "    test_cases: List[Dict[str, str]] = None,\n",
    "    judge_model: str = \"openai/gpt-5-mini\",\n",
    "    judge_api_key: str = None,\n",
    "    judge_api_base: str = \"https://api.vsegpt.ru/v1\",\n",
    "    embedding_model: str = \"emb-openai/text-embedding-3-large\",\n",
    "    top_k: int = 5,\n",
    "    metrics: List[str] = None,\n",
    "    max_tokens: int = 32000,  # ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä\n",
    "    save_dataset_path: Optional[str] = None,\n",
    "    enable_timing: bool = True,  # ‚úÖ –ù–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä\n",
    "    exclude_slow_metrics: bool = False,  # ‚úÖ –ù–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä\n",
    "    max_metric_time: float = 15.0  # ‚úÖ –ù–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    –ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ RAG —Å–∏—Å—Ç–µ–º—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAGAS 0.4+.\n",
    "    \n",
    "    Args:\n",
    "        dataset: DataFrame –∏–ª–∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –≥–æ—Ç–æ–≤—ã–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º\n",
    "        pipeline: RAG –ø–∞–π–ø–ª–∞–π–Ω (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç)\n",
    "        test_cases: –¢–µ—Å—Ç–æ–≤—ã–µ –∫–µ–π—Å—ã (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç)\n",
    "        judge_model: –ú–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏\n",
    "        judge_api_key: API –∫–ª—é—á –¥–ª—è Judge LLM\n",
    "        judge_api_base: Base URL –¥–ª—è Judge LLM API\n",
    "        embedding_model: –ú–æ–¥–µ–ª—å embeddings\n",
    "        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤\n",
    "        metrics: –°–ø–∏—Å–æ–∫ –º–µ—Ç—Ä–∏–∫ (None = –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)\n",
    "        max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è LLM\n",
    "        save_dataset_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "        enable_timing: –í–∫–ª—é—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n",
    "        exclude_slow_metrics: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–∫–ª—é—á–∏—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "        max_metric_time: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏ (–µ—Å–ª–∏ exclude_slow_metrics=True)\n",
    "    \n",
    "    Returns:\n",
    "        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏\n",
    "    \"\"\"\n",
    "    if not RAGAS_AVAILABLE:\n",
    "        raise ImportError(\"RAGAS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install ragas --upgrade\")\n",
    "    \n",
    "    # 1. –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üìä –®–ê–ì 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if dataset is not None:\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç\n",
    "        if isinstance(dataset, str):\n",
    "            df = load_evaluation_dataset(dataset)\n",
    "        else:\n",
    "            df = dataset\n",
    "            print(f\"‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π DataFrame ({len(df)} –∑–∞–ø–∏—Å–µ–π)\")\n",
    "    else:\n",
    "        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç\n",
    "        if pipeline is None or test_cases is None:\n",
    "            raise ValueError(\"–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –ª–∏–±–æ dataset, –ª–∏–±–æ pipeline+test_cases\")\n",
    "        \n",
    "        df = prepare_rag_evaluation_dataset(\n",
    "            pipeline=pipeline,\n",
    "            test_cases=test_cases,\n",
    "            top_k=top_k,\n",
    "            save_path=save_dataset_path\n",
    "        )\n",
    "    \n",
    "    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç RAGAS\n",
    "    queries, answers, contexts_list, ground_truths = dataset_to_ragas_format(df)\n",
    "    \n",
    "    # 2. –°–æ–∑–¥–∞–µ–º –æ—Ü–µ–Ω—â–∏–∫–∞ (Judge LLM)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ü§ñ –®–ê–ì 2: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Judge LLM –¥–ª—è –æ—Ü–µ–Ω–∫–∏\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if judge_api_key is None:\n",
    "        judge_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not judge_api_key:\n",
    "            raise ValueError(\"–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å judge_api_key –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å OPENAI_API_KEY\")\n",
    "    \n",
    "    # ‚úÖ –ü–µ—Ä–µ–¥–∞–µ–º max_tokens\n",
    "    evaluation_client = UniversalLLMClient(\n",
    "        model=judge_model,\n",
    "        api_key=judge_api_key,\n",
    "        api_base=judge_api_base,\n",
    "        temperature=0.0,\n",
    "        max_tokens=max_tokens  # ‚úÖ –¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è\n",
    "    )\n",
    "    \n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "    if metrics is None:\n",
    "        has_ground_truth = any(gt and gt.strip() for gt in ground_truths)\n",
    "        \n",
    "        if has_ground_truth:\n",
    "            metrics = [\n",
    "                \"faithfulness\",\n",
    "                \"answer_relevancy\",\n",
    "                \"context_precision\",\n",
    "                \"context_recall\",\n",
    "                \"context_relevance\",\n",
    "                \"response_groundedness\",\n",
    "                \"answer_accuracy\"\n",
    "            ]\n",
    "        else:\n",
    "            metrics = [\n",
    "                \"faithfulness\",\n",
    "                \"context_relevance\",\n",
    "                \"response_groundedness\"\n",
    "            ]\n",
    "    \n",
    "    # ‚úÖ –°–æ–∑–¥–∞–µ–º evaluator —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π timing\n",
    "    evaluator = UniversalRAGEvaluator(\n",
    "        judge_llm_client=evaluation_client,\n",
    "        embedding_model=embedding_model,\n",
    "        metrics=metrics,\n",
    "        enable_timing=enable_timing  # ‚úÖ –í–∫–ª—é—á–∞–µ–º –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏\n",
    "    )\n",
    "    \n",
    "    # 3. –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üöÄ –®–ê–ì 3: –ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ RAGAS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"‚öôÔ∏è  –ú–µ—Ç—Ä–∏–∫–∏: {', '.join(metrics)}\")\n",
    "    print(f\"‚öôÔ∏è  max_tokens: {max_tokens}\")\n",
    "    print(f\"‚è∞ –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç (LLM –≤—ã–∑–æ–≤—ã –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–∏)...\\n\")\n",
    "    \n",
    "    # –í—ã–ø–æ–ª–Ω—è–µ–º –æ—Ü–µ–Ω–∫—É\n",
    "    results = evaluator.evaluate(\n",
    "        queries=queries,\n",
    "        answers=answers,\n",
    "        contexts=contexts_list,\n",
    "        ground_truths=ground_truths,\n",
    "        show_progress=True\n",
    "    )\n",
    "    \n",
    "    # 4. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "    if enable_timing:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"‚è±Ô∏è –®–ê–ì 3.5: –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–µ—Ç—Ä–∏–∫\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        evaluator.display_timing_analysis()\n",
    "        \n",
    "        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "        if exclude_slow_metrics:\n",
    "            recommended_metrics = evaluator.get_recommended_metrics(\n",
    "                max_avg_time=max_metric_time,\n",
    "                exclude_redundant=True\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ {recommended_metrics}\")\n",
    "            print(f\"   –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ—Ü–µ–Ω–∫–∏ –≤ {len(metrics)/len(recommended_metrics):.1f}x —Ä–∞–∑\")\n",
    "    \n",
    "    # 5. –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìä –®–ê–ì 4: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    evaluator.display_results(max_examples=len(queries))\n",
    "    \n",
    "    # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üíæ –®–ê–ì 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    results_path = evaluator.save_results()\n",
    "    print(f\"‚úÖ –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_path}\")\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    metrics_path = Path(\"results\") / f\"ragas_metrics_{timestamp}.json\"\n",
    "    metrics_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(metrics_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"‚úÖ –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metrics_path}\")\n",
    "    \n",
    "    # ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Ä–µ–º–µ–Ω–∏\n",
    "    if enable_timing:\n",
    "        timing_df = evaluator.get_timing_statistics()\n",
    "        timing_path = Path(\"results\") / f\"ragas_timing_{timestamp}.csv\"\n",
    "        timing_df.to_csv(timing_path, index=False)\n",
    "        print(f\"‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {timing_path}\")\n",
    "    \n",
    "    return {\n",
    "        \"aggregated_metrics\": results,\n",
    "        \"detailed_results\": evaluator.get_detailed_results(),\n",
    "        \"evaluator\": evaluator,\n",
    "        \"dataset\": df,\n",
    "        \"timing_statistics\": evaluator.get_timing_statistics() if enable_timing else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbba35c-14c8-4efd-b745-f80ada6e94f5",
   "metadata": {},
   "source": [
    "### –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6878cba1-bdbb-4889-81fe-5f3c5aec94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = prepare_rag_evaluation_dataset(\n",
    "    pipeline=pipeline,\n",
    "    test_cases=test_cases,\n",
    "    top_k=5,\n",
    "    save_path=\"datasets/rag_evaluation_dataset.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c254b0-512d-474c-a889-2b0a0c462757",
   "metadata": {},
   "source": [
    "### –û—Ü–µ–Ω–∫–∞ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f6d7f-75b0-41ec-8ebb-4451cbff0995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = evaluate_rag_with_ragas(\n",
    "    dataset=\"datasets/rag_evaluation_dataset.parquet\",  # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "    judge_model=\"openai/gpt-5-mini\",\n",
    "    judge_api_key=\"sk-or-vv-xxx\",\n",
    "    judge_api_base=\"https://api.vsegpt.ru/v1\",\n",
    "    embedding_model=\"emb-openai/text-embedding-3-large\",\n",
    "    max_tokens=32000,\n",
    "    enable_timing=True,  # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "    exclude_slow_metrics=False,  # –ü–æ–∫–∞ –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    metrics=None  # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2363f934-14a0-450e-a4c6-39d406d2a14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 19:49:33,506 - __main__ - INFO - ‚úÖ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏: \n"
     ]
    }
   ],
   "source": [
    "recommended = results['evaluator'].get_recommended_metrics(\n",
    "    max_avg_time=10.0,\n",
    "    exclude_redundant=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a987682c-b0bb-467a-9baf-d8252354bd55",
   "metadata": {},
   "source": [
    "### –ë—ã—Å—Ç—Ä–∞—è –æ—Ü–µ–Ω–∫–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "276c579d-d0d9-4b18-9485-8d8a247cf690",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    # \"faithfulness\",\n",
    "    \"answer_relevancy\",\n",
    "    # \"context_precision\",\n",
    "    \"context_recall\",\n",
    "    \"context_relevance\",\n",
    "    # \"response_groundedness\",\n",
    "    \"answer_accuracy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bc4055-1227-4cd5-83a7-fa04aebc53c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "results_fast = evaluate_rag_with_ragas(\n",
    "    dataset=\"datasets/rag_evaluation_dataset.parquet\",\n",
    "    judge_model=\"openai/gpt-5-mini\",\n",
    "    judge_api_key=\"sk-or-vv-xxx\",\n",
    "    max_tokens=32000,\n",
    "    metrics=metrics, #recommended,  # –¢–æ–ª—å–∫–æ –±—ã—Å—Ç—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    enable_timing=True\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"–í—Ä–µ–º—è –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed_time} —Å–µ–∫.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae82536-70cc-4c80-81d1-85bb91f6c222",
   "metadata": {},
   "source": [
    "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b7f590c8-c637-4445-8a4b-dbe0cad0e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_cases_from_file(filepath: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –∫–µ–π—Å—ã –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.\n",
    "    \n",
    "    Args:\n",
    "        filepath: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É (CSV, Parquet –∏–ª–∏ JSON)\n",
    "    \n",
    "    Returns:\n",
    "        –°–ø–∏—Å–æ–∫ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤\n",
    "    \"\"\"\n",
    "    filepath = Path(filepath)\n",
    "    \n",
    "    if not filepath.exists():\n",
    "        raise FileNotFoundError(f\"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}\")\n",
    "    \n",
    "    print(f\"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤: {filepath}\")\n",
    "    \n",
    "    # JSON - –ø—Ä—è–º–∞—è –∑–∞–≥—Ä—É–∑–∫–∞\n",
    "    if filepath.suffix == '.json':\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            test_cases = json.load(f)\n",
    "        print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(test_cases)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤ –∏–∑ JSON\")\n",
    "        return test_cases\n",
    "    \n",
    "    # CSV –∏–ª–∏ Parquet - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ DataFrame\n",
    "    if filepath.suffix == '.csv':\n",
    "        df = pd.read_csv(filepath, encoding='utf-8')\n",
    "    elif filepath.suffix == '.parquet':\n",
    "        df = pd.read_parquet(filepath)\n",
    "    else:\n",
    "        raise ValueError(f\"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {filepath.suffix}\")\n",
    "    \n",
    "    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π\n",
    "    test_cases = []\n",
    "    for _, row in df.iterrows():\n",
    "        test_case = {\n",
    "            \"query\": row[\"query\"],\n",
    "            \"ground_truth\": row[\"ground_truth\"],\n",
    "            \"metadata\": {\n",
    "                \"object_id\": row.get(\"object_id\", \"\"),\n",
    "                \"num_axioms\": int(row.get(\"num_axioms\", 0)),\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –∞–∫—Å–∏–æ–º—ã –µ—Å–ª–∏ –µ—Å—Ç—å\n",
    "        if \"axioms\" in row and pd.notna(row[\"axioms\"]):\n",
    "            axioms_str = str(row[\"axioms\"])\n",
    "            test_case[\"metadata\"][\"axioms\"] = axioms_str.split(\"\\n\") if axioms_str else []\n",
    "        \n",
    "        test_cases.append(test_case)\n",
    "    \n",
    "    print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(test_cases)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤\")\n",
    "    return test_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "99d101d0-a65e-4938-925c-690ac1a95678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤: datasets\\rag_test_cases_20260109_222314.json\n",
      "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 198 —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤ –∏–∑ JSON\n",
      "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 198 —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤\n"
     ]
    }
   ],
   "source": [
    "loaded_test_cases = load_test_cases_from_file(\"./datasets/rag_test_cases_20260109_222314.json\")\n",
    "\n",
    "print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(loaded_test_cases)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64ab60-3205-4b77-b7a8-2aeba339b9f5",
   "metadata": {},
   "source": [
    "### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏ RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c0995-6ecd-49a6-99ff-ae9e9fddcc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ test_cases –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç RAG —Å–∏—Å—Ç–µ–º—ã\n",
    "dataset_df = prepare_rag_evaluation_dataset(\n",
    "    pipeline=pipeline,  # –í–∞—à RAG pipeline\n",
    "    test_cases=loaded_test_cases,\n",
    "    top_k=5,\n",
    "    save_path=\"./datasets/rag_evaluation_dataset_full.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdb0c0e-bdc3-4420-8ff6-bd0e901a2997",
   "metadata": {},
   "source": [
    "### –û—Ü–µ–Ω–∫–∞ RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3cd5da2a-bd09-4ad8-87db-84e9ceab1a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    # \"faithfulness\",\n",
    "    \"answer_relevancy\",\n",
    "    # \"context_precision\",\n",
    "    \"context_recall\",\n",
    "    \"context_relevance\",\n",
    "    # \"response_groundedness\",\n",
    "    \"answer_accuracy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c73011d-c952-448a-9431-a5b56d392586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation_results = evaluate_rag_with_ragas(\n",
    "    dataset=dataset_df,\n",
    "    judge_model=\"openai/gpt-5-mini\",\n",
    "    judge_api_key=\"sk-or-vv-xxx\",\n",
    "    judge_api_base=\"https://api.vsegpt.ru/v1\",\n",
    "    max_tokens=32000,\n",
    "    enable_timing=True,\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42723ec4-95b9-4ce8-a260-c11f21a53afe",
   "metadata": {},
   "source": [
    "# RAGAS –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è GraphRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df46efd9-fc4f-40de-9349-9f8f42b2725e",
   "metadata": {},
   "source": [
    "### –ê–¥–∞–ø—Ç–µ—Ä GraphRAG –¥–ª—è RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "29784196-bea2-4a4f-886a-5cbb18959571",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphRAGAdapter:\n",
    "    \"\"\"\n",
    "    –ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Microsoft GraphRAG —Å RAGAS.\n",
    "    \n",
    "    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ GraphRAG (—Å—É—â–Ω–æ—Å—Ç–∏, —Å–≤—è–∑–∏)\n",
    "    –≤ —Ñ–æ—Ä–º–∞—Ç, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ RAGAS.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, search_engine):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            search_engine: –≠–∫–∑–µ–º–ø–ª—è—Ä LocalSearch –∏–∑ GraphRAG\n",
    "        \"\"\"\n",
    "        self.search_engine = search_engine\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    async def query(self, \n",
    "                   question: str,\n",
    "                   return_details: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        –í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ GraphRAG –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è RAGAS.\n",
    "        \n",
    "        Args:\n",
    "            question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "            return_details: –í–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏ –¥–µ—Ç–∞–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
    "        \n",
    "        Returns:\n",
    "            –°–ª–æ–≤–∞—Ä—å —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –≤ GraphRAG\n",
    "        result = await self.search_engine.search(question)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç\n",
    "        answer = result.response\n",
    "        \n",
    "        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç\n",
    "        contexts = []\n",
    "        context_data = {}\n",
    "        \n",
    "        if return_details and hasattr(result, 'context_data'):\n",
    "            contexts, context_data = self._extract_contexts(result.context_data)\n",
    "        \n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"contexts\": contexts,\n",
    "            \"context_data\": context_data,\n",
    "            \"elapsed_time\": elapsed_time,\n",
    "            \"raw_result\": result\n",
    "        }\n",
    "    \n",
    "    def _extract_contexts(self, context_data: Dict) -> Tuple[List[str], Dict]:\n",
    "        \"\"\"\n",
    "        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ GraphRAG context_data.\n",
    "        \n",
    "        GraphRAG –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç:\n",
    "        - entities: DataFrame —Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º–∏ —Å—É—â–Ω–æ—Å—Ç—è–º–∏\n",
    "        - relationships: DataFrame —Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º–∏ —Å–≤—è–∑—è–º–∏\n",
    "        - reports: –û—Ç—á–µ—Ç—ã —Å–æ–æ–±—â–µ—Å—Ç–≤\n",
    "        - sources: –¢–µ–∫—Å—Ç–æ–≤—ã–µ –µ–¥–∏–Ω–∏—Ü—ã\n",
    "        \n",
    "        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏—Ö –≤ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ (contexts) –¥–ª—è RAGAS.\n",
    "        \n",
    "        Args:\n",
    "            context_data: –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç GraphRAG\n",
    "        \n",
    "        Returns:\n",
    "            –ö–æ—Ä—Ç–µ–∂ (—Å–ø–∏—Å–æ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —Å—Ç—Ä–æ–∫, —Å–ª–æ–≤–∞—Ä—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö)\n",
    "        \"\"\"\n",
    "        contexts = []\n",
    "        metadata = {\n",
    "            \"num_entities\": 0,\n",
    "            \"num_relationships\": 0,\n",
    "            \"num_reports\": 0,\n",
    "            \"num_sources\": 0\n",
    "        }\n",
    "        \n",
    "        # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É—â–Ω–æ—Å—Ç–∏\n",
    "        if \"entities\" in context_data and context_data[\"entities\"] is not None:\n",
    "            entities_df = context_data[\"entities\"]\n",
    "            \n",
    "            if not entities_df.empty:\n",
    "                metadata[\"num_entities\"] = len(entities_df)\n",
    "                \n",
    "                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Å—É—â–Ω–æ—Å—Ç—å\n",
    "                for _, entity in entities_df.iterrows():\n",
    "                    entity_context = self._format_entity(entity)\n",
    "                    if entity_context:\n",
    "                        contexts.append(entity_context)\n",
    "        \n",
    "        # 2. –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–≤—è–∑–∏\n",
    "        if \"relationships\" in context_data and context_data[\"relationships\"] is not None:\n",
    "            relationships_df = context_data[\"relationships\"]\n",
    "            \n",
    "            if not relationships_df.empty:\n",
    "                metadata[\"num_relationships\"] = len(relationships_df)\n",
    "                \n",
    "                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–≤—è–∑–∏\n",
    "                for _, rel in relationships_df.iterrows():\n",
    "                    rel_context = self._format_relationship(rel)\n",
    "                    if rel_context:\n",
    "                        contexts.append(rel_context)\n",
    "        \n",
    "        # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç—á–µ—Ç—ã —Å–æ–æ–±—â–µ—Å—Ç–≤\n",
    "        if \"reports\" in context_data and context_data[\"reports\"] is not None:\n",
    "            reports_df = context_data[\"reports\"]\n",
    "            \n",
    "            if not reports_df.empty:\n",
    "                metadata[\"num_reports\"] = len(reports_df)\n",
    "                \n",
    "                for _, report in reports_df.iterrows():\n",
    "                    report_context = self._format_report(report)\n",
    "                    if report_context:\n",
    "                        contexts.append(report_context)\n",
    "        \n",
    "        # 4. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –µ–¥–∏–Ω–∏—Ü—ã (sources)\n",
    "        if \"sources\" in context_data and context_data[\"sources\"] is not None:\n",
    "            sources_df = context_data[\"sources\"]\n",
    "            \n",
    "            if not sources_df.empty:\n",
    "                metadata[\"num_sources\"] = len(sources_df)\n",
    "                \n",
    "                for _, source in sources_df.iterrows():\n",
    "                    source_context = self._format_source(source)\n",
    "                    if source_context:\n",
    "                        contexts.append(source_context)\n",
    "        \n",
    "        self.logger.info(\n",
    "            f\"üìä –ò–∑–≤–ª–µ—á–µ–Ω–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤: {len(contexts)} \"\n",
    "            f\"(entities: {metadata['num_entities']}, \"\n",
    "            f\"relationships: {metadata['num_relationships']}, \"\n",
    "            f\"reports: {metadata['num_reports']}, \"\n",
    "            f\"sources: {metadata['num_sources']})\"\n",
    "        )\n",
    "        \n",
    "        return contexts, metadata\n",
    "    \n",
    "    def _format_entity(self, entity: pd.Series) -> str:\n",
    "        \"\"\"\n",
    "        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å—É—â–Ω–æ—Å—Ç—å –≤ —Ç–µ–∫—Å—Ç–æ–≤—É—é —Å—Ç—Ä–æ–∫—É.\n",
    "        \n",
    "        –¢–∏–ø–∏—á–Ω—ã–µ –ø–æ–ª—è –≤ GraphRAG entity:\n",
    "        - title/name: –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏\n",
    "        - type: —Ç–∏–ø —Å—É—â–Ω–æ—Å—Ç–∏\n",
    "        - description: –æ–ø–∏—Å–∞–Ω–∏–µ\n",
    "        - rank: –≤–∞–∂–Ω–æ—Å—Ç—å\n",
    "        \"\"\"\n",
    "        parts = []\n",
    "        \n",
    "        # –ù–∞–∑–≤–∞–Ω–∏–µ\n",
    "        title = entity.get('title') or entity.get('name', 'Unknown Entity')\n",
    "        parts.append(f\"Entity: {title}\")\n",
    "        \n",
    "        # –¢–∏–ø\n",
    "        if 'type' in entity and pd.notna(entity['type']):\n",
    "            parts.append(f\"Type: {entity['type']}\")\n",
    "        \n",
    "        # –û–ø–∏—Å–∞–Ω–∏–µ\n",
    "        if 'description' in entity and pd.notna(entity['description']):\n",
    "            desc = str(entity['description']).strip()\n",
    "            if desc:\n",
    "                parts.append(f\"Description: {desc}\")\n",
    "        \n",
    "        # –†–∞–Ω–≥/–≤–∞–∂–Ω–æ—Å—Ç—å\n",
    "        if 'rank' in entity and pd.notna(entity['rank']):\n",
    "            parts.append(f\"Rank: {entity['rank']}\")\n",
    "        \n",
    "        return \" | \".join(parts) if parts else \"\"\n",
    "    \n",
    "    def _format_relationship(self, relationship: pd.Series) -> str:\n",
    "        \"\"\"\n",
    "        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–≤—è–∑—å –≤ —Ç–µ–∫—Å—Ç–æ–≤—É—é —Å—Ç—Ä–æ–∫—É.\n",
    "        \n",
    "        –¢–∏–ø–∏—á–Ω—ã–µ –ø–æ–ª—è:\n",
    "        - source: –∏—Å—Ö–æ–¥–Ω–∞—è —Å—É—â–Ω–æ—Å—Ç—å\n",
    "        - target: —Ü–µ–ª–µ–≤–∞—è —Å—É—â–Ω–æ—Å—Ç—å\n",
    "        - description: –æ–ø–∏—Å–∞–Ω–∏–µ —Å–≤—è–∑–∏\n",
    "        - weight: –≤–µ—Å —Å–≤—è–∑–∏\n",
    "        \"\"\"\n",
    "        parts = []\n",
    "        \n",
    "        source = relationship.get('source', 'Unknown')\n",
    "        target = relationship.get('target', 'Unknown')\n",
    "        \n",
    "        parts.append(f\"Relationship: {source} -> {target}\")\n",
    "        \n",
    "        # –û–ø–∏—Å–∞–Ω–∏–µ —Å–≤—è–∑–∏\n",
    "        if 'description' in relationship and pd.notna(relationship['description']):\n",
    "            desc = str(relationship['description']).strip()\n",
    "            if desc:\n",
    "                parts.append(f\"Description: {desc}\")\n",
    "        \n",
    "        # –í–µ—Å\n",
    "        if 'weight' in relationship and pd.notna(relationship['weight']):\n",
    "            parts.append(f\"Weight: {relationship['weight']}\")\n",
    "        \n",
    "        return \" | \".join(parts) if parts else \"\"\n",
    "    \n",
    "    def _format_report(self, report: pd.Series) -> str:\n",
    "        \"\"\"\n",
    "        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç —Å–æ–æ–±—â–µ—Å—Ç–≤–∞.\n",
    "        \n",
    "        –¢–∏–ø–∏—á–Ω—ã–µ –ø–æ–ª—è:\n",
    "        - title: –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞\n",
    "        - summary: –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ\n",
    "        - full_content: –ø–æ–ª–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ\n",
    "        - rank: –≤–∞–∂–Ω–æ—Å—Ç—å\n",
    "        \"\"\"\n",
    "        parts = []\n",
    "        \n",
    "        # –ó–∞–≥–æ–ª–æ–≤–æ–∫\n",
    "        if 'title' in report and pd.notna(report['title']):\n",
    "            parts.append(f\"Community Report: {report['title']}\")\n",
    "        \n",
    "        # –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ (–∏—Å–ø–æ–ª—å–∑—É–µ–º summary –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ full_content)\n",
    "        content = None\n",
    "        if 'summary' in report and pd.notna(report['summary']):\n",
    "            content = str(report['summary']).strip()\n",
    "        elif 'full_content' in report and pd.notna(report['full_content']):\n",
    "            content = str(report['full_content']).strip()\n",
    "        \n",
    "        if content:\n",
    "            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "            if len(content) > 500:\n",
    "                content = content[:497] + \"...\"\n",
    "            parts.append(f\"Content: {content}\")\n",
    "        \n",
    "        return \" | \".join(parts) if parts else \"\"\n",
    "    \n",
    "    def _format_source(self, source: pd.Series) -> str:\n",
    "        \"\"\"\n",
    "        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é –µ–¥–∏–Ω–∏—Ü—É (source).\n",
    "        \n",
    "        –¢–∏–ø–∏—á–Ω—ã–µ –ø–æ–ª—è:\n",
    "        - text: —Ç–µ–∫—Å—Ç\n",
    "        - id: –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
    "        \"\"\"\n",
    "        if 'text' in source and pd.notna(source['text']):\n",
    "            text = str(source['text']).strip()\n",
    "            \n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º ID –µ—Å–ª–∏ –µ—Å—Ç—å\n",
    "            if 'id' in source and pd.notna(source['id']):\n",
    "                return f\"Source [{source['id']}]: {text}\"\n",
    "            else:\n",
    "                return f\"Source: {text}\"\n",
    "        \n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "db9f313c-03d9-4c7c-8938-3371e0d94fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_query_graphrag(adapter: GraphRAGAdapter, question: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ query GraphRAG.\n",
    "    \n",
    "    Args:\n",
    "        adapter: GraphRAGAdapter —ç–∫–∑–µ–º–ø–ª—è—Ä\n",
    "        question: –í–æ–ø—Ä–æ—Å\n",
    "    \n",
    "    Returns:\n",
    "        –†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø—Ä–æ—Å–∞\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # –ü—Ä–∏–º–µ–Ω—è–µ–º nest_asyncio –µ—Å–ª–∏ –Ω—É–∂–Ω–æ (–¥–ª—è Jupyter)\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # –í—ã–ø–æ–ª–Ω—è–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        result = loop.run_until_complete(adapter.query(question))\n",
    "    except RuntimeError:\n",
    "        result = asyncio.run(adapter.query(question))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a449e9-b7f9-497e-bc70-5000afda9413",
   "metadata": {},
   "source": [
    "### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è GraphRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f9423c5a-9344-4eee-bbc3-769df368e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_graphrag_evaluation_dataset(\n",
    "    graphrag_adapter: GraphRAGAdapter,\n",
    "    test_cases: List[Dict[str, str]],\n",
    "    save_path: Optional[str] = None,\n",
    "    verbose: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ GraphRAG —Å RAGAS.\n",
    "    \n",
    "    Args:\n",
    "        graphrag_adapter: –ê–¥–∞–ø—Ç–µ—Ä GraphRAG\n",
    "        test_cases: –°–ø–∏—Å–æ–∫ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤ —Å query –∏ ground_truth\n",
    "        save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "        verbose: –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    print(f\"üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ GraphRAG –¥–ª—è {len(test_cases)} –∑–∞–ø—Ä–æ—Å–æ–≤...\")\n",
    "    \n",
    "    iterator = tqdm(test_cases, desc=\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤\") if verbose else test_cases\n",
    "    \n",
    "    for idx, test_case in enumerate(iterator):\n",
    "        query = test_case[\"query\"]\n",
    "        ground_truth = test_case.get(\"ground_truth\", \"\")\n",
    "        metadata = test_case.get(\"metadata\", {})\n",
    "        \n",
    "        try:\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç GraphRAG\n",
    "            result = sync_query_graphrag(graphrag_adapter, query)\n",
    "            \n",
    "            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø–∏—Å—å\n",
    "            row = {\n",
    "                'idx': idx,\n",
    "                'query': query,\n",
    "                'answer': result[\"answer\"],\n",
    "                'contexts': '|||'.join(result[\"contexts\"]),  # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã\n",
    "                'ground_truth': ground_truth,\n",
    "                'num_contexts': len(result[\"contexts\"]),\n",
    "                'num_entities': result[\"context_data\"].get(\"num_entities\", 0),\n",
    "                'num_relationships': result[\"context_data\"].get(\"num_relationships\", 0),\n",
    "                'num_reports': result[\"context_data\"].get(\"num_reports\", 0),\n",
    "                'num_sources': result[\"context_data\"].get(\"num_sources\", 0),\n",
    "                'elapsed_time': result[\"elapsed_time\"],\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "            }\n",
    "            \n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n",
    "            row.update(metadata)\n",
    "            \n",
    "            data.append(row)\n",
    "            \n",
    "            if verbose:\n",
    "                tqdm.write(\n",
    "                    f\"‚úÖ [{idx+1}/{len(test_cases)}] {query[:50]}... \"\n",
    "                    f\"(–∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤: {row['num_contexts']}, –≤—Ä–µ–º—è: {row['elapsed_time']:.1f}—Å)\"\n",
    "                )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ '{query[:50]}...': {e}\")\n",
    "            \n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é –∑–∞–ø–∏—Å—å\n",
    "            data.append({\n",
    "                'idx': idx,\n",
    "                'query': query,\n",
    "                'answer': \"\",\n",
    "                'contexts': \"\",\n",
    "                'ground_truth': ground_truth,\n",
    "                'num_contexts': 0,\n",
    "                'num_entities': 0,\n",
    "                'num_relationships': 0,\n",
    "                'num_reports': 0,\n",
    "                'num_sources': 0,\n",
    "                'elapsed_time': 0,\n",
    "                'error': str(e),\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "            })\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å\n",
    "    if save_path:\n",
    "        save_path = Path(save_path)\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        if save_path.suffix == '.parquet':\n",
    "            df.to_parquet(save_path, index=False, compression='gzip')\n",
    "        elif save_path.suffix == '.csv':\n",
    "            df.to_csv(save_path, index=False, encoding='utf-8')\n",
    "        else:\n",
    "            save_path = save_path.with_suffix('.parquet')\n",
    "            df.to_parquet(save_path, index=False, compression='gzip')\n",
    "        \n",
    "        print(f\"\\nüíæ –î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}\")\n",
    "        print(f\"   –†–∞–∑–º–µ—Ä: {save_path.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "    print(f\"\\n‚úÖ –î–∞—Ç–∞—Å–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω:\")\n",
    "    print(f\"   ‚Ä¢ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}\")\n",
    "    print(f\"   ‚Ä¢ –£—Å–ø–µ—à–Ω—ã—Ö: {df['answer'].notna().sum()}\")\n",
    "    print(f\"   ‚Ä¢ –° ground truth: {df['ground_truth'].notna().sum()}\")\n",
    "    print(f\"   ‚Ä¢ –° –æ—à–∏–±–∫–∞–º–∏: {df.get('error', pd.Series()).notna().sum()}\")\n",
    "    print(f\"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤: {df['num_contexts'].mean():.1f}\")\n",
    "    print(f\"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {df['elapsed_time'].mean():.1f}—Å\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e159a-9336-44c7-bc19-e852ccb6ace9",
   "metadata": {},
   "source": [
    "### –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –º–µ—Ç—Ä–∏–∫ RAGAS —Å GraphRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "17d1d5c4-f9cf-46e3-a500-e0a32141cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_graphrag_ragas_compatibility(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –º–µ—Ç—Ä–∏–∫ RAGAS —Å –¥–∞–Ω–Ω—ã–º–∏ GraphRAG.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ GraphRAG\n",
    "    \n",
    "    Returns:\n",
    "        –û—Ç—á–µ—Ç –æ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏\n",
    "    \"\"\"\n",
    "    from IPython.display import display, HTML\n",
    "    \n",
    "    compatibility = {\n",
    "        \"faithfulness\": {\n",
    "            \"compatible\": True,\n",
    "            \"required_fields\": [\"answer\", \"contexts\"],\n",
    "            \"notes\": \"‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã –∏–∑ —Å—É—â–Ω–æ—Å—Ç–µ–π/—Å–≤—è–∑–µ–π/–æ—Ç—á–µ—Ç–æ–≤.\"\n",
    "        },\n",
    "        \"answer_relevancy\": {\n",
    "            \"compatible\": True,\n",
    "            \"required_fields\": [\"query\", \"answer\"],\n",
    "            \"notes\": \"‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º–∞. –ù–µ —Ç—Ä–µ–±—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç embeddings.\"\n",
    "        },\n",
    "        \"context_precision\": {\n",
    "            \"compatible\": True,\n",
    "            \"required_fields\": [\"query\", \"contexts\", \"ground_truth\"],\n",
    "            \"notes\": \"‚úÖ –°–æ–≤–º–µ—Å—Ç–∏–º–∞ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ ground_truth. –û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤.\"\n",
    "        },\n",
    "        \"context_recall\": {\n",
    "            \"compatible\": True,\n",
    "            \"required_fields\": [\"contexts\", \"ground_truth\"],\n",
    "            \"notes\": \"‚úÖ –°–æ–≤–º–µ—Å—Ç–∏–º–∞ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ ground_truth. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω–æ—Ç—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\"\n",
    "        },\n",
    "        \"context_relevance\": {\n",
    "            \"compatible\": True,\n",
    "            \"required_fields\": [\"query\", \"contexts\"],\n",
    "            \"notes\": \"‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º–∞. –û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å—É.\"\n",
    "        },\n",
    "        \"response_groundedness\": {\n",
    "            \"compatible\": True,\n",
    "            \"required_fields\": [\"answer\", \"contexts\"],\n",
    "            \"notes\": \"‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º–∞. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º.\"\n",
    "        },\n",
    "        \"answer_accuracy\": {\n",
    "            \"compatible\": True,\n",
    "            \"required_fields\": [\"query\", \"answer\", \"ground_truth\"],\n",
    "            \"notes\": \"‚úÖ –°–æ–≤–º–µ—Å—Ç–∏–º–∞ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ ground_truth. –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç —Å —ç—Ç–∞–ª–æ–Ω–æ–º.\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö\n",
    "    has_contexts = df['contexts'].notna().sum() > 0\n",
    "    has_ground_truth = df['ground_truth'].notna().sum() > 0\n",
    "    avg_contexts = df['num_contexts'].mean()\n",
    "    \n",
    "    # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    recommended_metrics = []\n",
    "    \n",
    "    if has_contexts:\n",
    "        recommended_metrics.extend([\n",
    "            \"faithfulness\",\n",
    "            \"context_relevance\",\n",
    "            \"response_groundedness\"\n",
    "        ])\n",
    "    \n",
    "    if has_contexts and has_ground_truth:\n",
    "        recommended_metrics.extend([\n",
    "            \"context_precision\",\n",
    "            \"context_recall\"\n",
    "        ])\n",
    "    \n",
    "    if has_ground_truth:\n",
    "        recommended_metrics.append(\"answer_accuracy\")\n",
    "    \n",
    "    # Always available\n",
    "    recommended_metrics.append(\"answer_relevancy\")\n",
    "    \n",
    "    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã\n",
    "    recommended_metrics = list(dict.fromkeys(recommended_metrics))\n",
    "    \n",
    "    # HTML –æ—Ç—á–µ—Ç\n",
    "    html = f\"\"\"\n",
    "    <div style=\"border: 2px solid #2196F3; border-radius: 12px; padding: 20px; margin: 15px 0;\n",
    "                background: linear-gradient(135deg, #E3F2FD 0%, #BBDEFB 100%);\">\n",
    "        <h2 style=\"color: #1565C0; margin-top: 0;\">üîç –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ RAGAS —Å GraphRAG</h2>\n",
    "        \n",
    "        <div style=\"background: white; padding: 15px; border-radius: 8px; margin: 15px 0;\">\n",
    "            <h3 style=\"color: #1565C0;\">üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö</h3>\n",
    "            <ul style=\"line-height: 1.8;\">\n",
    "                <li>üìù –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: <strong>{len(df)}</strong></li>\n",
    "                <li>üì¶ –ó–∞–ø–∏—Å–µ–π —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞–º–∏: <strong>{df['contexts'].notna().sum()}</strong> ({df['contexts'].notna().sum()/len(df)*100:.1f}%)</li>\n",
    "                <li>‚úÖ –ó–∞–ø–∏—Å–µ–π —Å ground truth: <strong>{df['ground_truth'].notna().sum()}</strong> ({df['ground_truth'].notna().sum()/len(df)*100:.1f}%)</li>\n",
    "                <li>üìä –°—Ä–µ–¥–Ω–µ–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ –∑–∞–ø—Ä–æ—Å: <strong>{avg_contexts:.1f}</strong></li>\n",
    "                <li>üîó –°—Ä–µ–¥–Ω–µ–µ —Å—É—â–Ω–æ—Å—Ç–µ–π: <strong>{df['num_entities'].mean():.1f}</strong></li>\n",
    "                <li>üîó –°—Ä–µ–¥–Ω–µ–µ —Å–≤—è–∑–µ–π: <strong>{df['num_relationships'].mean():.1f}</strong></li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"background: white; padding: 15px; border-radius: 8px; margin: 15px 0;\">\n",
    "            <h3 style=\"color: #1565C0;\">‚úÖ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏ RAGAS</h3>\n",
    "            <div style=\"display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 10px;\">\n",
    "    \"\"\"\n",
    "    \n",
    "    for metric in recommended_metrics:\n",
    "        info = compatibility.get(metric, {})\n",
    "        html += f\"\"\"\n",
    "                <div style=\"background: #E8F5E9; padding: 10px; border-radius: 5px; border-left: 4px solid #4CAF50;\">\n",
    "                    <strong style=\"color: #2E7D32;\">{metric}</strong>\n",
    "                    <div style=\"font-size: 0.85em; color: #666; margin-top: 5px;\">\n",
    "                        {info.get('notes', '')}\n",
    "                    </div>\n",
    "                </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    html += \"\"\"\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"background: #FFF9C4; padding: 15px; border-radius: 8px; margin: 15px 0;\">\n",
    "            <h3 style=\"color: #F57F17;\">‚ö†Ô∏è –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ GraphRAG</h3>\n",
    "            <ul style=\"line-height: 1.8; color: #666;\">\n",
    "                <li>GraphRAG –∏—Å–ø–æ–ª—å–∑—É–µ—Ç <strong>—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç</strong> (—Å—É—â–Ω–æ—Å—Ç–∏ + —Å–≤—è–∑–∏ + –æ—Ç—á–µ—Ç—ã)</li>\n",
    "                <li>–ö–æ–Ω—Ç–µ–∫—Å—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å <strong>–±–æ–ª–µ–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –±–æ–≥–∞—Ç—ã–º–∏</strong>, —á–µ–º –ø—Ä–æ—Å—Ç—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —á–∞–Ω–∫–∏</li>\n",
    "                <li>–ú–µ—Ç—Ä–∏–∫–∏ <strong>context_precision</strong> –∏ <strong>context_recall</strong> –æ—Ü–µ–Ω–∏–≤–∞—é—Ç –∫–∞—á–µ—Å—Ç–≤–æ –≥—Ä–∞—Ñ–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã</li>\n",
    "                <li><strong>answer_relevancy</strong> –∏—Å–ø–æ–ª—å–∑—É–µ—Ç embeddings –∏ –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–∏–ø–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(html))\n",
    "    \n",
    "    return {\n",
    "        \"compatibility\": compatibility,\n",
    "        \"recommended_metrics\": recommended_metrics,\n",
    "        \"has_contexts\": has_contexts,\n",
    "        \"has_ground_truth\": has_ground_truth,\n",
    "        \"stats\": {\n",
    "            \"total_records\": len(df),\n",
    "            \"avg_contexts\": avg_contexts,\n",
    "            \"avg_entities\": df['num_entities'].mean(),\n",
    "            \"avg_relationships\": df['num_relationships'].mean()\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966c40fc-27c4-4a4c-9130-a45fe16782d6",
   "metadata": {},
   "source": [
    "### –û—Ü–µ–Ω–∫–∞ GraphRAG —Å RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "33210e62-0782-4530-b2b1-d03ca50ef4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_graphrag_with_ragas(\n",
    "    dataset: Optional[Union[pd.DataFrame, str]] = None,\n",
    "    graphrag_adapter: GraphRAGAdapter = None,\n",
    "    test_cases: List[Dict[str, str]] = None,\n",
    "    judge_model: str = \"openai/gpt-5-mini\",\n",
    "    judge_api_key: str = None,\n",
    "    judge_api_base: str = \"https://api.vsegpt.ru/v1\",\n",
    "    embedding_model: str = \"emb-openai/text-embedding-3-large\",\n",
    "    metrics: List[str] = None,\n",
    "    max_tokens: int = 32000,\n",
    "    save_dataset_path: Optional[str] = None,\n",
    "    enable_timing: bool = True,\n",
    "    analyze_compatibility: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    –ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ GraphRAG —Å–∏—Å—Ç–µ–º—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAGAS 0.4+.\n",
    "    \n",
    "    Args:\n",
    "        dataset: DataFrame –∏–ª–∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –≥–æ—Ç–æ–≤—ã–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º\n",
    "        graphrag_adapter: GraphRAGAdapter (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç)\n",
    "        test_cases: –¢–µ—Å—Ç–æ–≤—ã–µ –∫–µ–π—Å—ã (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç)\n",
    "        judge_model: –ú–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏\n",
    "        judge_api_key: API –∫–ª—é—á –¥–ª—è Judge LLM\n",
    "        judge_api_base: Base URL –¥–ª—è Judge LLM API\n",
    "        embedding_model: –ú–æ–¥–µ–ª—å embeddings\n",
    "        metrics: –°–ø–∏—Å–æ–∫ –º–µ—Ç—Ä–∏–∫ (None = –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)\n",
    "        max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è LLM\n",
    "        save_dataset_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "        enable_timing: –í–∫–ª—é—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n",
    "        analyze_compatibility: –ü—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏\n",
    "    \n",
    "    Returns:\n",
    "        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏\n",
    "    \"\"\"\n",
    "    if not RAGAS_AVAILABLE:\n",
    "        raise ImportError(\"RAGAS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install ragas --upgrade\")\n",
    "    \n",
    "    # 1. –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üìä –®–ê–ì 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ GraphRAG\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if dataset is not None:\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç\n",
    "        if isinstance(dataset, str):\n",
    "            df = load_evaluation_dataset(dataset)\n",
    "        else:\n",
    "            df = dataset\n",
    "            print(f\"‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π DataFrame ({len(df)} –∑–∞–ø–∏—Å–µ–π)\")\n",
    "    else:\n",
    "        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç\n",
    "        if graphrag_adapter is None or test_cases is None:\n",
    "            raise ValueError(\"–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –ª–∏–±–æ dataset, –ª–∏–±–æ graphrag_adapter+test_cases\")\n",
    "        \n",
    "        df = prepare_graphrag_evaluation_dataset(\n",
    "            graphrag_adapter=graphrag_adapter,\n",
    "            test_cases=test_cases,\n",
    "            save_path=save_dataset_path,\n",
    "            verbose=True\n",
    "        )\n",
    "    \n",
    "    # –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏\n",
    "    if analyze_compatibility:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üîç –®–ê–ì 1.5: –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ RAGAS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        compatibility_result = analyze_graphrag_ragas_compatibility(df)\n",
    "        \n",
    "        # –ï—Å–ª–∏ –º–µ—Ç—Ä–∏–∫–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ\n",
    "        if metrics is None:\n",
    "            metrics = compatibility_result[\"recommended_metrics\"]\n",
    "            print(f\"\\n‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω—ã –º–µ—Ç—Ä–∏–∫–∏: {', '.join(metrics)}\")\n",
    "    \n",
    "    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç RAGAS\n",
    "    queries, answers, contexts_list, ground_truths = dataset_to_ragas_format(df)\n",
    "    \n",
    "    # 2. –°–æ–∑–¥–∞–µ–º –æ—Ü–µ–Ω—â–∏–∫–∞ (Judge LLM)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ü§ñ –®–ê–ì 2: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Judge LLM –¥–ª—è –æ—Ü–µ–Ω–∫–∏\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if judge_api_key is None:\n",
    "        judge_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not judge_api_key:\n",
    "            raise ValueError(\"–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å judge_api_key –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å OPENAI_API_KEY\")\n",
    "    \n",
    "    evaluation_client = UniversalLLMClient(\n",
    "        model=judge_model,\n",
    "        api_key=judge_api_key,\n",
    "        api_base=judge_api_base,\n",
    "        temperature=0.0,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    \n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã\n",
    "    if metrics is None:\n",
    "        has_ground_truth = any(gt and gt.strip() for gt in ground_truths)\n",
    "        \n",
    "        if has_ground_truth:\n",
    "            metrics = [\n",
    "                \"faithfulness\",\n",
    "                \"answer_relevancy\",\n",
    "                \"context_precision\",\n",
    "                \"context_recall\",\n",
    "                \"context_relevance\",\n",
    "                \"response_groundedness\",\n",
    "                \"answer_accuracy\"\n",
    "            ]\n",
    "        else:\n",
    "            metrics = [\n",
    "                \"faithfulness\",\n",
    "                \"context_relevance\",\n",
    "                \"response_groundedness\",\n",
    "                \"answer_relevancy\"\n",
    "            ]\n",
    "    \n",
    "    evaluator = UniversalRAGEvaluator(\n",
    "        judge_llm_client=evaluation_client,\n",
    "        embedding_model=embedding_model,\n",
    "        metrics=metrics,\n",
    "        enable_timing=enable_timing\n",
    "    )\n",
    "    \n",
    "    # 3. –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üöÄ –®–ê–ì 3: –ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ RAGAS –¥–ª—è GraphRAG\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"‚öôÔ∏è  –ú–µ—Ç—Ä–∏–∫–∏: {', '.join(metrics)}\")\n",
    "    print(f\"‚öôÔ∏è  max_tokens: {max_tokens}\")\n",
    "    print(f\"‚è∞ –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...\\n\")\n",
    "    \n",
    "    results = evaluator.evaluate(\n",
    "        queries=queries,\n",
    "        answers=answers,\n",
    "        contexts=contexts_list,\n",
    "        ground_truths=ground_truths,\n",
    "        show_progress=True\n",
    "    )\n",
    "    \n",
    "    # 4. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "    if enable_timing:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"‚è±Ô∏è –®–ê–ì 3.5: –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–µ—Ç—Ä–∏–∫\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        evaluator.display_timing_analysis()\n",
    "    \n",
    "    # 5. –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìä –®–ê–ì 4: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ GraphRAG\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    evaluator.display_results(max_examples=min(10, len(queries)))\n",
    "    \n",
    "    # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üíæ –®–ê–ì 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    results_path = evaluator.save_results()\n",
    "    print(f\"‚úÖ –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_path}\")\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    metrics_path = Path(\"results\") / f\"graphrag_ragas_metrics_{timestamp}.json\"\n",
    "    metrics_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(metrics_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"‚úÖ –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏: {metrics_path}\")\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Ä–µ–º–µ–Ω–∏\n",
    "    if enable_timing:\n",
    "        timing_df = evaluator.get_timing_statistics()\n",
    "        timing_path = Path(\"results\") / f\"graphrag_ragas_timing_{timestamp}.csv\"\n",
    "        timing_df.to_csv(timing_path, index=False)\n",
    "        print(f\"‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {timing_path}\")\n",
    "    \n",
    "    # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ GraphRAG\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ GraphRAG\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ –∑–∞–ø—Ä–æ—Å: {df['num_contexts'].mean():.1f}\")\n",
    "    print(f\"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ —Å—É—â–Ω–æ—Å—Ç–µ–π: {df['num_entities'].mean():.1f}\")\n",
    "    print(f\"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ —Å–≤—è–∑–µ–π: {df['num_relationships'].mean():.1f}\")\n",
    "    print(f\"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –æ—Ç—á–µ—Ç–æ–≤: {df['num_reports'].mean():.1f}\")\n",
    "    print(f\"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞: {df['elapsed_time'].mean():.1f}—Å\")\n",
    "    \n",
    "    return {\n",
    "        \"aggregated_metrics\": results,\n",
    "        \"detailed_results\": evaluator.get_detailed_results(),\n",
    "        \"evaluator\": evaluator,\n",
    "        \"dataset\": df,\n",
    "        \"timing_statistics\": evaluator.get_timing_statistics() if enable_timing else None,\n",
    "        \"graphrag_stats\": {\n",
    "            \"avg_contexts\": df['num_contexts'].mean(),\n",
    "            \"avg_entities\": df['num_entities'].mean(),\n",
    "            \"avg_relationships\": df['num_relationships'].mean(),\n",
    "            \"avg_reports\": df['num_reports'].mean(),\n",
    "            \"avg_query_time\": df['elapsed_time'].mean()\n",
    "        }\n",
    "    }\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cfa19d-1103-4bc5-a863-6294154a996b",
   "metadata": {},
   "source": [
    "### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ RAG vs GraphRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "12ea9730-754b-494f-b378-76604037a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_rag_vs_graphrag(\n",
    "    rag_results: Dict[str, Any],\n",
    "    graphrag_results: Dict[str, Any],\n",
    "    save_path: Optional[str] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ –æ–±—ã—á–Ω–æ–≥–æ RAG –∏ GraphRAG.\n",
    "    \n",
    "    Args:\n",
    "        rag_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ RAG\n",
    "        graphrag_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ GraphRAG\n",
    "        save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame —Å–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º\n",
    "    \"\"\"\n",
    "    from IPython.display import display, HTML\n",
    "    \n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "    rag_metrics = rag_results[\"aggregated_metrics\"]\n",
    "    graphrag_metrics = graphrag_results[\"aggregated_metrics\"]\n",
    "    \n",
    "    # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    common_metrics = set(\n",
    "        [k.replace('_mean', '') for k in rag_metrics.keys() if k.endswith('_mean')]\n",
    "    ) & set(\n",
    "        [k.replace('_mean', '') for k in graphrag_metrics.keys() if k.endswith('_mean')]\n",
    "    )\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É\n",
    "    comparison_data = []\n",
    "    \n",
    "    for metric in sorted(common_metrics):\n",
    "        rag_mean = rag_metrics.get(f\"{metric}_mean\", 0)\n",
    "        graphrag_mean = graphrag_metrics.get(f\"{metric}_mean\", 0)\n",
    "        \n",
    "        difference = graphrag_mean - rag_mean\n",
    "        improvement = (difference / rag_mean * 100) if rag_mean > 0 else 0\n",
    "        \n",
    "        comparison_data.append({\n",
    "            \"Metric\": metric,\n",
    "            \"RAG\": f\"{rag_mean:.3f}\",\n",
    "            \"GraphRAG\": f\"{graphrag_mean:.3f}\",\n",
    "            \"Difference\": f\"{difference:+.3f}\",\n",
    "            \"Improvement %\": f\"{improvement:+.1f}%\",\n",
    "            \"Winner\": \"GraphRAG\" if graphrag_mean > rag_mean else (\"RAG\" if rag_mean > graphrag_mean else \"Tie\")\n",
    "        })\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º\n",
    "    if save_path:\n",
    "        save_path = Path(save_path)\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df_comparison.to_csv(save_path, index=False)\n",
    "        print(f\"üíæ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {save_path}\")\n",
    "    \n",
    "    # HTML –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    html = f\"\"\"\n",
    "    <div style=\"border: 2px solid #9C27B0; border-radius: 12px; padding: 20px; margin: 15px 0;\n",
    "                background: linear-gradient(135deg, #F3E5F5 0%, #E1BEE7 100%);\">\n",
    "        <h2 style=\"color: #6A1B9A; margin-top: 0;\">‚öñÔ∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ RAG vs GraphRAG</h2>\n",
    "        \n",
    "        <table style=\"width: 100%; border-collapse: collapse; background: white; margin: 15px 0;\">\n",
    "            <thead>\n",
    "                <tr style=\"background: #9C27B0; color: white;\">\n",
    "                    <th style=\"padding: 12px; text-align: left;\">–ú–µ—Ç—Ä–∏–∫–∞</th>\n",
    "                    <th style=\"padding: 12px; text-align: center;\">RAG</th>\n",
    "                    <th style=\"padding: 12px; text-align: center;\">GraphRAG</th>\n",
    "                    <th style=\"padding: 12px; text-align: center;\">–†–∞–∑–Ω–∏—Ü–∞</th>\n",
    "                    <th style=\"padding: 12px; text-align: center;\">–£–ª—É—á—à–µ–Ω–∏–µ</th>\n",
    "                    <th style=\"padding: 12px; text-align: center;\">–ü–æ–±–µ–¥–∏—Ç–µ–ª—å</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            <tbody>\n",
    "    \"\"\"\n",
    "    \n",
    "    for _, row in df_comparison.iterrows():\n",
    "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç —Å—Ç—Ä–æ–∫–∏\n",
    "        if row['Winner'] == 'GraphRAG':\n",
    "            bg_color = \"#C8E6C9\"\n",
    "            winner_badge = \"üèÜ GraphRAG\"\n",
    "            winner_color = \"#2E7D32\"\n",
    "        elif row['Winner'] == 'RAG':\n",
    "            bg_color = \"#FFE0B2\"\n",
    "            winner_badge = \"üèÜ RAG\"\n",
    "            winner_color = \"#E65100\"\n",
    "        else:\n",
    "            bg_color = \"#E0E0E0\"\n",
    "            winner_badge = \"ü§ù Tie\"\n",
    "            winner_color = \"#666\"\n",
    "        \n",
    "        html += f\"\"\"\n",
    "            <tr style=\"background: {bg_color};\">\n",
    "                <td style=\"padding: 10px; font-weight: bold;\">{row['Metric']}</td>\n",
    "                <td style=\"padding: 10px; text-align: center;\">{row['RAG']}</td>\n",
    "                <td style=\"padding: 10px; text-align: center;\">{row['GraphRAG']}</td>\n",
    "                <td style=\"padding: 10px; text-align: center; font-weight: bold;\">{row['Difference']}</td>\n",
    "                <td style=\"padding: 10px; text-align: center; font-weight: bold;\">{row['Improvement %']}</td>\n",
    "                <td style=\"padding: 10px; text-align: center;\">\n",
    "                    <span style=\"background: {winner_color}; color: white; padding: 4px 8px; border-radius: 12px; font-size: 0.9em;\">\n",
    "                        {winner_badge}\n",
    "                    </span>\n",
    "                </td>\n",
    "            </tr>\n",
    "        \"\"\"\n",
    "    \n",
    "    html += \"\"\"\n",
    "            </tbody>\n",
    "        </table>\n",
    "        \n",
    "        <div style=\"margin-top: 20px; padding: 15px; background: white; border-radius: 8px;\">\n",
    "            <h3 style=\"color: #6A1B9A;\">üìà –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç</h3>\n",
    "    \"\"\"\n",
    "    \n",
    "    # –ü–æ–¥—Å—á–µ—Ç –ø–æ–±–µ–¥\n",
    "    graphrag_wins = len(df_comparison[df_comparison['Winner'] == 'GraphRAG'])\n",
    "    rag_wins = len(df_comparison[df_comparison['Winner'] == 'RAG'])\n",
    "    ties = len(df_comparison[df_comparison['Winner'] == 'Tie'])\n",
    "    \n",
    "    html += f\"\"\"\n",
    "            <div style=\"display: grid; grid-template-columns: repeat(3, 1fr); gap: 15px; margin-top: 15px;\">\n",
    "                <div style=\"text-align: center; padding: 15px; background: #C8E6C9; border-radius: 8px;\">\n",
    "                    <div style=\"font-size: 2em; font-weight: bold; color: #2E7D32;\">{graphrag_wins}</div>\n",
    "                    <div style=\"color: #666;\">GraphRAG –ø–æ–±–µ–¥</div>\n",
    "                </div>\n",
    "                <div style=\"text-align: center; padding: 15px; background: #FFE0B2; border-radius: 8px;\">\n",
    "                    <div style=\"font-size: 2em; font-weight: bold; color: #E65100;\">{rag_wins}</div>\n",
    "                    <div style=\"color: #666;\">RAG –ø–æ–±–µ–¥</div>\n",
    "                </div>\n",
    "                <div style=\"text-align: center; padding: 15px; background: #E0E0E0; border-radius: 8px;\">\n",
    "                    <div style=\"font-size: 2em; font-weight: bold; color: #666;\">{ties}</div>\n",
    "                    <div style=\"color: #666;\">–ù–∏—á—å–∏—Ö</div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(html))\n",
    "    \n",
    "    print(\"\\nüìä –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞:\")\n",
    "    display(df_comparison)\n",
    "    \n",
    "    return df_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c536a-c633-47e6-bab6-5b2e778065b2",
   "metadata": {},
   "source": [
    "## –†–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0fea9352-b175-47c6-8e7b-a4c2768f4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bb2902f3-6621-4d06-abc3-77b5249a3908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GraphRAG...\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GraphRAG...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e70f4bfd-a770-4110-a0f2-434c324a370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "from graphrag.config.models.vector_store_schema_config import VectorStoreSchemaConfig\n",
    "from graphrag.query.context_builder.entity_extraction import EntityVectorStoreKey\n",
    "from graphrag.query.indexer_adapters import (\n",
    "    read_indexer_covariates,\n",
    "    read_indexer_entities,\n",
    "    read_indexer_relationships,\n",
    "    read_indexer_reports,\n",
    "    read_indexer_text_units,\n",
    ")\n",
    "from graphrag.query.question_gen.local_gen import LocalQuestionGen\n",
    "from graphrag.query.structured_search.local_search.mixed_context import (\n",
    "    LocalSearchMixedContext,\n",
    ")\n",
    "from graphrag.query.structured_search.local_search.search import LocalSearch\n",
    "from graphrag.vector_stores.lancedb import LanceDBVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "86e2fd87-f780-4756-a71f-c829a97568b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphrag.config.enums import ModelType\n",
    "from graphrag.config.models.language_model_config import LanguageModelConfig\n",
    "from graphrag.language_model.manager import ModelManager\n",
    "from graphrag.tokenizer.get_tokenizer import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "05442dc6-f724-42f3-a0b8-8183cb8ddc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'C:\\\\Users\\\\glvv2\\\\vkr\\\\graph_local3' # os.getcwd()\n",
    "\n",
    "INPUT_DIR = os.path.join(directory, \"output\")\n",
    "LANCEDB_URI = os.path.join(INPUT_DIR, \"lancedb\")\n",
    "\n",
    "COMMUNITY_REPORT_TABLE = \"community_reports\"\n",
    "ENTITY_TABLE = \"entities\"\n",
    "COMMUNITY_TABLE = \"communities\"\n",
    "RELATIONSHIP_TABLE = \"relationships\"\n",
    "COVARIATE_TABLE = \"covariates\"\n",
    "TEXT_UNIT_TABLE = \"text_units\"\n",
    "COMMUNITY_LEVEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "77e4bf03-a3ec-4ec5-9986-f0ab7f9398b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"sk-or-vv-xxx\"\n",
    "\n",
    "llm_model = \"google/gemma-3-27b-it\"\n",
    "embedding_model = \"emb-openai/text-embedding-3-large\"\n",
    "\n",
    "chat_config = LanguageModelConfig(\n",
    "    api_key=api_key,\n",
    "    api_base=\"https://api.vsegpt.ru/v1\",\n",
    "    type=ModelType.Chat,\n",
    "    model_provider=\"openai\",\n",
    "    model=llm_model,\n",
    "    max_retries=20,\n",
    ")\n",
    "\n",
    "chat_model = ModelManager().get_or_create_chat_model(\n",
    "    name=\"local_search\",\n",
    "    model_type=ModelType.Chat,\n",
    "    config=chat_config,\n",
    ")\n",
    "\n",
    "embedding_config = LanguageModelConfig(\n",
    "    api_key=api_key,\n",
    "    api_base=\"https://api.vsegpt.ru/v1\",\n",
    "    type=ModelType.Embedding,\n",
    "    model_provider=\"openai\",\n",
    "    model=embedding_model,\n",
    "    max_retries=20,\n",
    ")\n",
    "\n",
    "text_embedder = ModelManager().get_or_create_embedding_model(\n",
    "    name=\"local_search_embedding\",\n",
    "    model_type=ModelType.Embedding,\n",
    "    config=embedding_config,\n",
    ")\n",
    "\n",
    "tokenizer = get_tokenizer(chat_config)\n",
    "\n",
    "description_embedding_store = LanceDBVectorStore(\n",
    "    vector_store_schema_config=VectorStoreSchemaConfig(\n",
    "        index_name=\"default-entity-description\"\n",
    "    )\n",
    ")\n",
    "description_embedding_store.connect(db_uri=LANCEDB_URI)\n",
    "\n",
    "entities = pd.read_parquet(f\"{directory}/output/entities.parquet\")\n",
    "communities = pd.read_parquet(f\"{directory}/output/communities.parquet\")\n",
    "community_reports = pd.read_parquet(f\"{directory}/output/community_reports.parquet\")\n",
    "text_units = pd.read_parquet(f\"{directory}/output/text_units.parquet\")\n",
    "relationships = pd.read_parquet(f\"{directory}/output/relationships.parquet\")\n",
    "\n",
    "entities_d = read_indexer_entities(entities, communities, None) #, COMMUNITY_LEVEL)\n",
    "relationships_d = read_indexer_relationships(relationships)\n",
    "reports_d = read_indexer_reports(community_reports, communities, None) # , COMMUNITY_LEVEL)\n",
    "text_units_d = read_indexer_text_units(text_units)\n",
    "\n",
    "context_builder = LocalSearchMixedContext(\n",
    "    community_reports=reports_d,\n",
    "    text_units=text_units_d,\n",
    "    entities=entities_d,\n",
    "    relationships=relationships_d,\n",
    "    covariates=None, #covariates,\n",
    "    entity_text_embeddings=description_embedding_store,\n",
    "    embedding_vectorstore_key=EntityVectorStoreKey.ID,\n",
    "    text_embedder=text_embedder,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "local_context_params = {\n",
    "    \"text_unit_prop\": 0.5,\n",
    "    \"community_prop\": 0.1,\n",
    "    \"conversation_history_max_turns\": 5,\n",
    "    \"conversation_history_user_turns_only\": True,\n",
    "    \"top_k_mapped_entities\": 10,\n",
    "    \"top_k_relationships\": 10,\n",
    "    \"include_entity_rank\": True,\n",
    "    \"include_relationship_weight\": True,\n",
    "    \"include_community_rank\": False,\n",
    "    \"return_candidate_context\": False, #True,\n",
    "    \"embedding_vectorstore_key\": EntityVectorStoreKey.ID,\n",
    "    \"max_tokens\": 24_000,\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "    \"max_tokens\": 3_000,\n",
    "    \"temperature\": 0.0,\n",
    "}\n",
    "\n",
    "search_engine = LocalSearch(\n",
    "    model=chat_model,\n",
    "    context_builder=context_builder,\n",
    "    tokenizer=tokenizer,\n",
    "    model_params=model_params,\n",
    "    context_builder_params=local_context_params,\n",
    "    response_type=\"multiple paragraphs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d060c54b-7d51-436f-81b4-732479d3304f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m08:23:06 - LiteLLM:INFO\u001b[0m: utils.py:1575 - Wrapper: Completed Call, calling success_handler\n",
      "2026-01-10 08:23:06,010 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m08:23:06 - LiteLLM:INFO\u001b[0m: utils.py:3749 - \n",
      "LiteLLM completion() model= google/gemma-3-27b-it; provider = openai\n",
      "2026-01-10 08:23:06,734 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-27b-it; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 14.509 —Å–µ–∫.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "result = await search_engine.search(\"Draw conclusions about the i101 object in Attempto Controlled English\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {(end - start):.3f} —Å–µ–∫.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3c219475-c561-4175-96dc-3dbc30accb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ –°–æ–∑–¥–∞–Ω–∏–µ –∞–¥–∞–ø—Ç–µ—Ä–∞ GraphRAG –¥–ª—è RAGAS...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüì¶ –°–æ–∑–¥–∞–Ω–∏–µ –∞–¥–∞–ø—Ç–µ—Ä–∞ GraphRAG –¥–ª—è RAGAS...\")\n",
    "\n",
    "graphrag_adapter = GraphRAGAdapter(search_engine=search_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d1776972-4269-4cb4-9d83-32e998e164d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤...\n",
      "üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤: datasets\\rag_test_cases_20260109_222314.json\n",
      "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 198 —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤ –∏–∑ JSON\n",
      "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 198 —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤...\")\n",
    "\n",
    "loaded_test_cases = load_test_cases_from_file(\"./datasets/rag_test_cases_20260109_222314.json\")\n",
    "\n",
    "print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(loaded_test_cases)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–µ–π—Å–æ–≤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d8de9-ea29-40ea-80cd-d55d9d067091",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ GraphRAG\")\n",
    "\n",
    "graphrag_dataset = prepare_graphrag_evaluation_dataset(\n",
    "    graphrag_adapter=graphrag_adapter,\n",
    "    test_cases=loaded_test_cases, #test_cases,\n",
    "    save_path=\"./datasets/graphrag_evaluation_dataset.parquet\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784cc487-d6e7-42fc-9427-d17e2e78c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏\")\n",
    "\n",
    "compatibility = analyze_graphrag_ragas_compatibility(graphrag_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6f632abe-405e-4faa-b39d-b4a8a689972f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Entity: Unknown Entity|||Entity: Unknown Entity | Description: I90 is a context-dependent shape representation and has a representation relation (i91)'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphrag_dataset.contexts[0][:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cf3a169c-8067-4eb6-a6e6-e65e7b9292a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_eq = [\n",
    "    # \"faithfulness\",\n",
    "    \"answer_relevancy\",\n",
    "    # \"context_precision\",\n",
    "    \"context_recall\",\n",
    "    \"context_relevance\",\n",
    "    # \"response_groundedness\",\n",
    "    \"answer_accuracy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d3b62-c2cd-43d4-aa27-719850ecd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ –†–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ RAGAS –¥–ª—è GraphRAG\")\n",
    "\n",
    "graphrag_evaluation_results_eq = evaluate_graphrag_with_ragas(\n",
    "    dataset=graphrag_dataset,\n",
    "    judge_model=\"openai/gpt-5-mini\",\n",
    "    judge_api_key=\"sk-or-vv-xxx\",\n",
    "    judge_api_base=\"https://api.vsegpt.ru/v1\",\n",
    "    embedding_model=\"emb-openai/text-embedding-3-large\",\n",
    "    max_tokens=32000,\n",
    "    enable_timing=True,\n",
    "    analyze_compatibility=True,\n",
    "    metrics=metrics_eq\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a19de250-829e-4857-b43d-b0a24469dc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ RAG vs. GraphRAG\n",
      "üíæ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: results\\rag_vs_graphrag_comparison_eq.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"border: 2px solid #9C27B0; border-radius: 12px; padding: 20px; margin: 15px 0;\n",
       "                background: linear-gradient(135deg, #F3E5F5 0%, #E1BEE7 100%);\">\n",
       "        <h2 style=\"color: #6A1B9A; margin-top: 0;\">‚öñÔ∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ RAG vs GraphRAG</h2>\n",
       "\n",
       "        <table style=\"width: 100%; border-collapse: collapse; background: white; margin: 15px 0;\">\n",
       "            <thead>\n",
       "                <tr style=\"background: #9C27B0; color: white;\">\n",
       "                    <th style=\"padding: 12px; text-align: left;\">–ú–µ—Ç—Ä–∏–∫–∞</th>\n",
       "                    <th style=\"padding: 12px; text-align: center;\">RAG</th>\n",
       "                    <th style=\"padding: 12px; text-align: center;\">GraphRAG</th>\n",
       "                    <th style=\"padding: 12px; text-align: center;\">–†–∞–∑–Ω–∏—Ü–∞</th>\n",
       "                    <th style=\"padding: 12px; text-align: center;\">–£–ª—É—á—à–µ–Ω–∏–µ</th>\n",
       "                    <th style=\"padding: 12px; text-align: center;\">–ü–æ–±–µ–¥–∏—Ç–µ–ª—å</th>\n",
       "                </tr>\n",
       "            </thead>\n",
       "            <tbody>\n",
       "    \n",
       "            <tr style=\"background: #C8E6C9;\">\n",
       "                <td style=\"padding: 10px; font-weight: bold;\">answer_accuracy</td>\n",
       "                <td style=\"padding: 10px; text-align: center;\">0.367</td>\n",
       "                <td style=\"padding: 10px; text-align: center;\">0.486</td>\n",
       "                <td style=\"padding: 10px; text-align: center; font-weight: bold;\">+0.119</td>\n",
       "                <td style=\"padding: 10px; text-align: center; font-weight: bold;\">+32.3%</td>\n",
       "                <td style=\"padding: 10px; text-align: center;\">\n",
       "                    <span style=\"background: #2E7D32; color: white; padding: 4px 8px; border-radius: 12px; font-size: 0.9em;\">\n",
       "                        üèÜ GraphRAG\n",
       "                    </span>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "            <tr style=\"background: #C8E6C9;\">\n",
       "                <td style=\"padding: 10px; font-weight: bold;\">answer_relevancy</td>\n",
       "                <td style=\"padding: 10px; text-align: center;\">0.359</td>\n",
       "                <td style=\"padding: 10px; text-align: center;\">0.483</td>\n",
       "                <td style=\"padding: 10px; text-align: center; font-weight: bold;\">+0.124</td>\n",
       "                <td style=\"padding: 10px; text-align: center; font-weight: bold;\">+34.7%</td>\n",
       "                <td style=\"padding: 10px; text-align: center;\">\n",
       "                    <span style=\"background: #2E7D32; color: white; padding: 4px 8px; border-radius: 12px; font-size: 0.9em;\">\n",
       "                        üèÜ GraphRAG\n",
       "                    </span>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "            <tr style=\"background: #C8E6C9;\">\n",
       "                <td style=\"padding: 10px; font-weight: bold;\">context_recall</td>\n",
       "                <td style=\"padding: 10px; text-align: center;\">0.116</td>\n",
       "                <td style=\"padding: 10px; text-align: center;\">0.727</td>\n",
       "                <td style=\"padding: 10px; text-align: center; font-weight: bold;\">+0.611</td>\n",
       "                <td style=\"padding: 10px; text-align: center; font-weight: bold;\">+525.8%</td>\n",
       "                <td style=\"padding: 10px; text-align: center;\">\n",
       "                    <span style=\"background: #2E7D32; color: white; padding: 4px 8px; border-radius: 12px; font-size: 0.9em;\">\n",
       "                        üèÜ GraphRAG\n",
       "                    </span>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "            <tr style=\"background: #C8E6C9;\">\n",
       "                <td style=\"padding: 10px; font-weight: bold;\">context_relevance</td>\n",
       "                <td style=\"padding: 10px; text-align: center;\">0.551</td>\n",
       "                <td style=\"padding: 10px; text-align: center;\">0.975</td>\n",
       "                <td style=\"padding: 10px; text-align: center; font-weight: bold;\">+0.424</td>\n",
       "                <td style=\"padding: 10px; text-align: center; font-weight: bold;\">+77.1%</td>\n",
       "                <td style=\"padding: 10px; text-align: center;\">\n",
       "                    <span style=\"background: #2E7D32; color: white; padding: 4px 8px; border-radius: 12px; font-size: 0.9em;\">\n",
       "                        üèÜ GraphRAG\n",
       "                    </span>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "            <tr style=\"background: #C8E6C9;\">\n",
       "                <td style=\"padding: 10px; font-weight: bold;\">overall</td>\n",
       "                <td style=\"padding: 10px; text-align: center;\">0.348</td>\n",
       "                <td style=\"padding: 10px; text-align: center;\">0.668</td>\n",
       "                <td style=\"padding: 10px; text-align: center; font-weight: bold;\">+0.320</td>\n",
       "                <td style=\"padding: 10px; text-align: center; font-weight: bold;\">+91.8%</td>\n",
       "                <td style=\"padding: 10px; text-align: center;\">\n",
       "                    <span style=\"background: #2E7D32; color: white; padding: 4px 8px; border-radius: 12px; font-size: 0.9em;\">\n",
       "                        üèÜ GraphRAG\n",
       "                    </span>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "            </tbody>\n",
       "        </table>\n",
       "\n",
       "        <div style=\"margin-top: 20px; padding: 15px; background: white; border-radius: 8px;\">\n",
       "            <h3 style=\"color: #6A1B9A;\">üìà –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç</h3>\n",
       "    \n",
       "            <div style=\"display: grid; grid-template-columns: repeat(3, 1fr); gap: 15px; margin-top: 15px;\">\n",
       "                <div style=\"text-align: center; padding: 15px; background: #C8E6C9; border-radius: 8px;\">\n",
       "                    <div style=\"font-size: 2em; font-weight: bold; color: #2E7D32;\">5</div>\n",
       "                    <div style=\"color: #666;\">GraphRAG –ø–æ–±–µ–¥</div>\n",
       "                </div>\n",
       "                <div style=\"text-align: center; padding: 15px; background: #FFE0B2; border-radius: 8px;\">\n",
       "                    <div style=\"font-size: 2em; font-weight: bold; color: #E65100;\">0</div>\n",
       "                    <div style=\"color: #666;\">RAG –ø–æ–±–µ–¥</div>\n",
       "                </div>\n",
       "                <div style=\"text-align: center; padding: 15px; background: #E0E0E0; border-radius: 8px;\">\n",
       "                    <div style=\"font-size: 2em; font-weight: bold; color: #666;\">0</div>\n",
       "                    <div style=\"color: #666;\">–ù–∏—á—å–∏—Ö</div>\n",
       "                </div>\n",
       "            </div>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>RAG</th>\n",
       "      <th>GraphRAG</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Improvement %</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>answer_accuracy</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.486</td>\n",
       "      <td>+0.119</td>\n",
       "      <td>+32.3%</td>\n",
       "      <td>GraphRAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.483</td>\n",
       "      <td>+0.124</td>\n",
       "      <td>+34.7%</td>\n",
       "      <td>GraphRAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context_recall</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.727</td>\n",
       "      <td>+0.611</td>\n",
       "      <td>+525.8%</td>\n",
       "      <td>GraphRAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>context_relevance</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.975</td>\n",
       "      <td>+0.424</td>\n",
       "      <td>+77.1%</td>\n",
       "      <td>GraphRAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>overall</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.668</td>\n",
       "      <td>+0.320</td>\n",
       "      <td>+91.8%</td>\n",
       "      <td>GraphRAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric    RAG GraphRAG Difference Improvement %    Winner\n",
       "0    answer_accuracy  0.367    0.486     +0.119        +32.3%  GraphRAG\n",
       "1   answer_relevancy  0.359    0.483     +0.124        +34.7%  GraphRAG\n",
       "2     context_recall  0.116    0.727     +0.611       +525.8%  GraphRAG\n",
       "3  context_relevance  0.551    0.975     +0.424        +77.1%  GraphRAG\n",
       "4            overall  0.348    0.668     +0.320        +91.8%  GraphRAG"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"‚öñÔ∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ RAG vs. GraphRAG\")\n",
    "\n",
    "try:\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ RAG\n",
    "    # with open(\"results/ragas_metrics_20260109_183330.json\", 'r') as f:\n",
    "    #     rag_aggregated = json.load(f)\n",
    "    # rag_results = {\"aggregated_metrics\": rag_aggregated}\n",
    "    \n",
    "    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ\n",
    "    comparison_df_eq = compare_rag_vs_graphrag(\n",
    "        rag_results=evaluation_results, # rag_results,\n",
    "        graphrag_results=graphrag_evaluation_results_eq,\n",
    "        save_path=\"./results/rag_vs_graphrag_comparison_eq.csv\"\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a1fe0698-af94-4c36-af3b-6af312fdf5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã GraphRAG:\n",
      "   ‚Ä¢ answer_relevancy: 0.483\n",
      "   ‚Ä¢ context_recall: 0.727\n",
      "   ‚Ä¢ context_relevance: 0.975\n",
      "   ‚Ä¢ answer_accuracy: 0.486\n",
      "   ‚Ä¢ overall: 0.668\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã GraphRAG:\")\n",
    "for metric, value in graphrag_evaluation_results_eq[\"aggregated_metrics\"].items():\n",
    "    if metric.endswith('_mean'):\n",
    "        metric_name = metric.replace('_mean', '')\n",
    "        print(f\"   ‚Ä¢ {metric_name}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3869cfcd-8f16-48fd-a63a-771a44689fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ GraphRAG:\n",
      "   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤: 80.7\n",
      "   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ —Å—É—â–Ω–æ—Å—Ç–µ–π: 20.0\n",
      "   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ —Å–≤—è–∑–µ–π: 45.9\n",
      "   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞: 14.4—Å\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ GraphRAG:\")\n",
    "stats = graphrag_evaluation_results_eq[\"graphrag_stats\"]\n",
    "print(f\"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤: {stats['avg_contexts']:.1f}\")\n",
    "print(f\"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ —Å—É—â–Ω–æ—Å—Ç–µ–π: {stats['avg_entities']:.1f}\")\n",
    "print(f\"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ —Å–≤—è–∑–µ–π: {stats['avg_relationships']:.1f}\")\n",
    "print(f\"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞: {stats['avg_query_time']:.1f}—Å\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a5a408be-6a07-43fe-a3e0-9c2ccddd699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ 'results/'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüíæ –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ 'results/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad0eb6c-3ac6-49a2-8df2-9ef029973de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
